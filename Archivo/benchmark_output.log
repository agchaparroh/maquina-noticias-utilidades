2025-04-21 15:13:19,740 - INFO - --- Iniciando Script de Benchmarking Groq ---
2025-04-21 15:13:19,887 - INFO - Cliente AsyncGroq inicializado.
2025-04-21 15:13:19,887 - INFO - Directorio de resultados: /home/ubuntu/benchmark_utils/benchmark_results
2025-04-21 15:13:19,887 - INFO - Archivo de m√©tricas: /home/ubuntu/benchmark_utils/benchmark_results/benchmark_metrics.csv
2025-04-21 15:13:19,889 - INFO - Encontrados 72 archivos de prueba en /home/ubuntu/data/benchmark_test_set
2025-04-21 15:13:19,889 - INFO - Iniciando procesamiento de 72 art√≠culos con concurrencia 5...
Progreso General Art√≠culos:   0%|          | 0/72 [00:00<?, ?it/s]2025-04-21 15:13:19,909 - INFO - --- Procesando Art√≠culo: test_011 ---
2025-04-21 15:13:19,911 - INFO - [test_011] Lanzando 25 llamadas a Groq...

[test_011] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A2025-04-21 15:13:19,912 - INFO - --- Procesando Art√≠culo: test_066 ---
2025-04-21 15:13:19,915 - INFO - [test_066] Lanzando 25 llamadas a Groq...


[test_066] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A2025-04-21 15:13:19,916 - INFO - --- Procesando Art√≠culo: test_048 ---
2025-04-21 15:13:19,917 - INFO - [test_048] Lanzando 25 llamadas a Groq...



[test_048] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A2025-04-21 15:13:19,918 - INFO - --- Procesando Art√≠culo: test_030 ---
2025-04-21 15:13:19,919 - INFO - [test_030] Lanzando 25 llamadas a Groq...




[test_030] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[A2025-04-21 15:13:19,919 - INFO - --- Procesando Art√≠culo: test_012 ---
2025-04-21 15:13:19,920 - INFO - [test_012] Lanzando 25 llamadas a Groq...





[test_012] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[A[A2025-04-21 15:13:20,977 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_011] Llamadas Groq:   4%|‚ñç         | 1/25 [00:01<00:25,  1.08s/it][A2025-04-21 15:13:21,013 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:21,028 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:21,031 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:13:21,042 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:21,046 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:13:21,051 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:21,055 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:13:21,058 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:21,061 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:13:21,062 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:21,065 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:13:21,066 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:21,073 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:13:21,074 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:21,078 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:21,079 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:13:21,082 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:13:21,118 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:21,121 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:13:21,235 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_011] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:01<00:08,  2.69it/s][A2025-04-21 15:13:21,297 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq:   4%|‚ñç         | 1/25 [00:01<00:33,  1.39s/it][A[A2025-04-21 15:13:21,328 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:21,357 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:21,359 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:13:21,384 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_011] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:04,  4.57it/s][A2025-04-21 15:13:21,399 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_030] Llamadas Groq:   4%|‚ñç         | 1/25 [00:01<00:35,  1.48s/it][A[A[A[A2025-04-21 15:13:21,419 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:21,510 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_048] Llamadas Groq:   4%|‚ñç         | 1/25 [00:01<00:38,  1.60s/it][A[A[A2025-04-21 15:13:21,515 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_011] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:03,  5.12it/s][A2025-04-21 15:13:21,530 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq:   8%|‚ñä         | 2/25 [00:01<00:16,  1.41it/s][A[A2025-04-21 15:13:21,553 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_012] Llamadas Groq:   4%|‚ñç         | 1/25 [00:01<00:39,  1.63s/it][A[A[A[A[A2025-04-21 15:13:21,649 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_011] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:03,  5.62it/s][A2025-04-21 15:13:21,675 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:21,681 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:01<00:09,  2.21it/s][A[A2025-04-21 15:13:21,733 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:21,770 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_011] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01,  9.70it/s][A2025-04-21 15:13:21,778 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_012] Llamadas Groq:   8%|‚ñä         | 2/25 [00:01<00:18,  1.24it/s][A[A[A[A[A2025-04-21 15:13:21,783 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:06,  3.19it/s][A[A2025-04-21 15:13:21,964 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_012] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:02<00:11,  1.92it/s][A[A[A[A[A2025-04-21 15:13:22,016 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:22,076 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_048] Llamadas Groq:   8%|‚ñä         | 2/25 [00:02<00:22,  1.01it/s][A[A[A2025-04-21 15:13:22,132 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:22,143 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_011] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:01,  7.58it/s][A2025-04-21 15:13:22,243 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:22,266 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_012] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:02<00:09,  2.29it/s][A[A[A[A[A2025-04-21 15:13:22,287 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:22,288 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:13:22,302 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:22,389 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:02<00:08,  2.38it/s][A[A2025-04-21 15:13:22,460 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:13:22,462 - ERROR - [test_066][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Sobre la conformaci√≥n de un gabinete de ministros, vuelvo a aclarar a la opini√≥n p√∫blica de que no existen m√°s √≥rdenes de aprehensi√≥n ni ampliaciones; pero s√≠ nosotros vamos, a fin de poder llegar a la verdad hist√≥rica del hecho, los vamos a convocar exclusivamente para que presten su declaraci√≥n, pero en calidad de testigos"",\n         "emisor_nombre": "Luis Carlos Torrez",\n         "contexto": "Conferencia de prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""El suscrito desconoc√≠a en relaci√≥n a la presentaci√≥n; vamos a suponer, posiblemente, que ha sido ya un hecho netamente de ministerio de Gobierno la publicaci√≥n, pero nosotros d√≠as antes ya hab√≠amos solicitado la emisi√≥n de esas √≥rdenes"",\n         "emisor_nombre": "Luis Carlos Torrez",\n         "contexto": "Justificaci√≥n de la Fiscal√≠a",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""La proyecci√≥n del documental, el suscrito desconoc√≠a en relaci√≥n a la presentaci√≥n"",\n         "emisor_nombre": "Luis Carlos Torrez",\n         "contexto": "Justificaci√≥n de la Fiscal√≠a",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""S√≠ nosotros vamos, a fin de poder llegar a la verdad hist√≥rica del hecho, los vamos a convocar exclusivamente para que presten su declaraci√≥n, pero en calidad de testigos"",\n         "emisor_nombre": "Luis Carlos Torrez",\n         "contexto": "Conferencia de prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""No existe ninguna otra orden de aprehensi√≥n"",\n         "emisor_nombre": "Luis Carlos Torrez",\n         "contexto": "Reiteraci√≥n de la Fiscal√≠a",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Los fiscales ya ten√≠an las ordenes de aprehensi√≥n, pero no supo explicar c√≥mo obtuvo e Gobierno los datos, nombres, lugares, fechas, mensajes, grabaciones exhibidas en el pol√©mico video"",\n         "emisor_nombre": "Luis Carlos Torrez",\n         "contexto": "Justificaci√≥n de la Fiscal√≠a",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Vamos a suponer, posiblemente, que ha sido ya un hecho netamente de ministerio de Gobierno la publicaci√≥n, pero nosotros d√≠as antes ya hab√≠amos solicitado la emisi√≥n de esas √≥rdenes"",\n         "emisor_nombre": "Luis Carlos Torrez",\n         "contexto": "Justificaci√≥n de la Fiscal√≠a",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Dijo que las √≥rdenes de aprehensi√≥n y el documental fueron una ‚Äòcoincidencia‚Äô"",\n         "emisor_nombre": "El fiscal Torrez",\n         "contexto": "Reacci√≥n a las acusaciones",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}
2025-04-21 15:13:22,532 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:02<00:04,  4.12it/s][A[A2025-04-21 15:13:22,580 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:22,667 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:13:22,669 - ERROR - [test_012][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Noboa, amigo, el pueblo est√° contigo"",\n         "emisor_nombre": "Simpatizantes del mandatario",\n         "contexto": "En la plaza de la Independencia de la ciudad, conocida tambi√©n como plaza Grande",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""Noboa, amigo, el pueblo est√° contigo"",\n         "emisor_nombre": "Simpatizantes del mandatario",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      }\n   ]\n}'}}





[test_012] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:02<00:05,  3.22it/s][A[A[A[A[A2025-04-21 15:13:22,779 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_030] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:02<00:19,  1.12it/s][A[A[A[A2025-04-21 15:13:22,821 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_012] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:02<00:04,  3.74it/s][A[A[A[A[A2025-04-21 15:13:22,834 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:22,950 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_048] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:03<00:13,  1.55it/s][A[A[A2025-04-21 15:13:22,956 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:03<00:03,  4.35it/s][A[A2025-04-21 15:13:22,991 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_012] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:03<00:02,  5.34it/s][A[A[A[A[A2025-04-21 15:13:23,061 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_011] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:03<00:02,  4.19it/s][A2025-04-21 15:13:23,197 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:23,198 - INFO - Retrying request to /openai/v1/chat/completions in 11.000000 seconds
2025-04-21 15:13:23,239 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_048] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:03<00:10,  1.87it/s][A[A[A2025-04-21 15:13:23,251 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:03<00:03,  4.08it/s][A[A2025-04-21 15:13:23,385 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_012] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:03<00:03,  4.22it/s][A[A[A[A[A2025-04-21 15:13:23,531 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:13:23,532 - ERROR - [test_048][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""no s√≥lo por su cabellera envidiable y su dentadura ejemplar"",\n         "emisor_nombre": "El autor del art√≠culo",\n         "contexto": "Declaraci√≥n de admiraci√≥n por Vargas Llosa al recibir el Premio Nobel",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un hombre que nunca dej√≥ de ser cadete"",\n         "emisor_nombre": "Una voz callada y sabia (no se menciona el nombre)",\n         "contexto": "Descripci√≥n de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""inelegante ni atrevido"",\n         "emisor_nombre": "El autor del art√≠culo",\n         "contexto": "Defensa de Vargas Llosa por su discusi√≥n sobre la dictadura en M√©xico",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""no tiene m√°s destino que colgarse de una hamaca en un lugar llamado La Chingada"",\n         "emisor_nombre": "Vargas Llosa",\n         "contexto": "Respuesta a una acusaci√≥n",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""muy lejos del somnoliento olvido que mece hamacas y dobla las l√°nguidas palmeras hay un infinito campo que se le extiende por delante a caballeros andantes"",\n         "emisor_nombre": "El autor del art√≠culo",\n         "contexto": "Descripci√≥n de la imaginaci√≥n de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}



[test_048] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:03<00:08,  2.18it/s][A[A[A2025-04-21 15:13:23,677 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:03<00:04,  3.45it/s][A[A2025-04-21 15:13:23,901 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_030] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:03<00:20,  1.03it/s][A[A[A[A2025-04-21 15:13:23,954 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_048] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:04<00:08,  2.23it/s][A[A[A2025-04-21 15:13:23,962 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:23,977 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_011] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:04<00:03,  2.72it/s][A2025-04-21 15:13:23,988 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:24,002 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_030] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:04<00:13,  1.46it/s][A[A[A[A2025-04-21 15:13:24,024 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:24,043 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:24,132 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_011] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:04<00:01,  5.09it/s][A2025-04-21 15:13:24,168 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:04<00:04,  2.92it/s][A[A2025-04-21 15:13:24,182 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_012] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:04<00:05,  2.64it/s][A[A[A[A[A2025-04-21 15:13:24,192 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_030] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:04<00:09,  1.90it/s][A[A[A[A2025-04-21 15:13:24,198 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:24,199 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:13:24,200 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:24,201 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:13:24,221 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:24,362 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_048] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:04<00:05,  2.99it/s][A[A[A2025-04-21 15:13:24,412 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:04<00:02,  4.03it/s][A[A2025-04-21 15:13:24,415 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:24,443 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_030] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:04<00:07,  2.28it/s][A[A[A[A2025-04-21 15:13:24,498 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_048] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:04<00:03,  4.38it/s][A[A[A2025-04-21 15:13:24,541 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:04<00:02,  4.54it/s][A[A2025-04-21 15:13:24,576 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:24,643 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_012] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:04<00:05,  2.49it/s][A[A[A[A[A2025-04-21 15:13:24,745 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_030] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:04<00:06,  2.52it/s][A[A[A[A2025-04-21 15:13:24,809 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:24,817 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:24,828 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_048] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:04<00:03,  3.99it/s][A[A[A2025-04-21 15:13:24,898 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_030] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:04<00:02,  5.01it/s][A[A[A[A2025-04-21 15:13:24,947 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:24,992 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:05<00:01,  4.50it/s][A[A2025-04-21 15:13:25,076 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_048] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:05<00:03,  4.00it/s][A[A[A2025-04-21 15:13:25,081 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:25,201 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:05<00:01,  4.55it/s][A[A2025-04-21 15:13:25,246 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:25,272 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_048] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:05<00:02,  4.23it/s][A[A[A2025-04-21 15:13:25,330 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_012] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:05<00:05,  2.08it/s][A[A[A[A[A2025-04-21 15:13:25,337 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_030] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:05<00:02,  4.84it/s][A[A[A[A2025-04-21 15:13:25,381 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_011] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:05<00:01,  3.20it/s][A2025-04-21 15:13:25,411 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:25,412 - ERROR - [test_048][relevancia][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 38468, Requested 996. Please try again in 18.928s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_048] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:05<00:02,  4.76it/s][A[A[A2025-04-21 15:13:25,557 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:05<00:01,  4.92it/s][A[A2025-04-21 15:13:25,596 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_011] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:05<00:00,  3.37it/s][A2025-04-21 15:13:25,689 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_048] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:05<00:02,  4.35it/s][A[A[A2025-04-21 15:13:25,742 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:13:25,743 - ERROR - [test_030][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""No es consciente de que muchas situaciones que ha vivido es por mi culpa"",\n         "emisor_nombre": "Un funcionario de la Polic√≠a Nacional",\n         "contexto": "Un ni√±o de 7 a√±os, hijo de un polic√≠a, ha estado en tres centros educativos y ha tenido un comportamiento ejemplar.",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Hay que sufrirlo y padecerlo"",\n         "emisor_nombre": "Fuentes policiales",\n         "contexto": "La Ley de Amnist√≠a no ha frenado el hostigamiento a los polic√≠as.",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""Parece que vivimos una cuenta atr√°s"",\n         "emisor_nombre": "Fuentes policiales",\n         "contexto": "La crispaci√≥n e incredulidad en Catalu√±a por los polic√≠as va en aumento.",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""La crispaci√≥n e incredulidad que se est√° viviendo en Catalu√±a por los polic√≠as va en aumento. El delirio independiente es cada vez m√°s palpable"",\n         "emisor_nombre": "El Sindicato Unificado de Polic√≠a (SUP)",\n         "contexto": "La crispaci√≥n e incredulidad en Catalu√±a por los polic√≠as va en aumento.",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""No hay nada que reparar"",\n         "emisor_nombre": "Representantes de los polic√≠as",\n         "contexto": "Se ha construido una \'leyenda negra\' en torno a Via Laietana para vincular a los polic√≠as con las torturas.",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""Hijo de madero, facha u opresor"",\n         "emisor_nombre": "Otros alumnos o personal docente",\n         "contexto": "Los ni√±os son el objetivo de vejaciones, incluyendo insultos y comentarios despectivos.",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Hemos tenido conocimiento de centros donde se blanquea o se justifica el proc√©s y se se√±ala a las Fuerzas y Cuerpos de Seguridad del Estado como enemigos del pueblo catal√°n"",\n         "emisor_nombre": "El Sindicato Unificado de Polic√≠a (SUP)",\n         "contexto": "Los profesores en algunos casos justifican o blanquean el proc√©s y se√±alan a las Fuerzas y Cuerpos de Seguridad del Estado como enemigos del pueblo catal√°n.",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Que un menor tenga que pagar el precio del uniforme de un progenitor. Reclamamos protecci√≥n real, respeto y tolerancia en todos los √°mbitos, incluido el educativo, y pedimos que las instituciones no miren hacia otro lado"",\n         "emisor_nombre": "El Sindicato Unificado de Polic√≠a (SUP)",\n         "contexto": "Se denuncia que la presi√≥n pol√≠tica se traslada al resto de esferas y que los menores pagan el precio del uniforme de sus progenitores.",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""No vamos a permitir que un pr√≥fugo de la Justicia y sus colegas m√°s radicales nos arrinconen"",\n         "emisor_nombre": "Polic√≠as",\n         "contexto": "Los polic√≠as temen que los independentistas no descansen hasta que vean como les expulsan de Catalu√±a.",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Es como una nube que tenemos encima que nos provoca estr√©s y ansiedad"",\n         "emisor_nombre": "Un funcionario de la Polic√≠a Nacional",\n         "contexto": "Los polic√≠as temen por su futuro y el de sus familias.",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Tendremos que comenzar de cero"",\n         "emisor_nombre": "Un funcionario de la Polic√≠a Nacional",\n         "contexto": "Los polic√≠as temen por su futuro y el de sus familias.",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}




[test_030] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:05<00:02,  4.06it/s][A[A[A[A2025-04-21 15:13:25,867 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_030] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:05<00:02,  4.56it/s][A[A[A[A2025-04-21 15:13:25,875 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:13:25,877 - ERROR - [test_030][extraccion_citas][gemma2-9b-it] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n  "resultados": [\n    {\n      "cita": "Hijo de madero, facha u opresor",\n      "emisor_nombre": "Alumnos",\n      "contexto": "Insultos que reciben los hijos de polic√≠as",\n      "fecha_cita": null,\n      "relevancia_cita": 4\n    },\n    {\n      "cita": "No es consciente de que muchas situaciones que ha vivido es por mi culpa",\n      "emisor_nombre": "Funcionario de la Polic√≠a Nacional",\n      "contexto": "Declaraciones a LA RAZ√ìN sobre el acoso sufrido por su hijo",\n      "fecha_cita": null,\n      "relevancia_cita": 3\n    },\n    {\n      "cita": "hay que sufrirlo y padecerlo",\n      "emisor_nombre": "Fuentes policiales",\n      "contexto": "Descripci√≥n del hostigamiento sufrido por los polic√≠as",\n      "fecha_cita": null,\n      "relevancia_cita": 4\n    },\n    {\n      "cita": "No hay nada que reparar",\n      "emisor_nombre": "Representantes de los polic√≠as",\n      "contexto": "Reacci√≥n a la "leyenda negra" construida en torno a Via Laietana",\n      "fecha_cita": null,\n      "relevancia_cita": 3\n    },\n    {\n      "cita": "degrade de forma paulatina el honor y la imagen",\n      "emisor_nombre": "Polic√≠as",\n      "contexto": "Descripci√≥n del impacto del acoso en su imagen",\n      "fecha_cita": null,\n      "relevancia_cita": 3\n    },\n    {\n      "cita": "Hijo de madero, facha u opresor",\n      "emisor_nombre": "Alumnos",\n      "contexto": "Insultos que reciben los hijos de polic√≠as",\n      "fecha_cita": null,\n      "relevancia_cita": 4\n    },\n    {\n      "cita": "Hemos tenido conocimiento de centros donde se blanquea o se justifica el proc√©s y se se√±ala a las Fuerzas y Cuerpos de Seguridad del Estado como enemigos del pueblo catal√°n, lo que alimenta a√∫n m√°s un clima hostil para estos menores",\n      "emisor_nombre": "Sindicato Unificado de Polic√≠a (SUP)",\n      "contexto": "Descripci√≥n del clima hostil en algunos centros educativos",\n      "fecha_cita": null,\n      "relevancia_cita": 4\n    },\n    {\n      "cita": "intolerable",\n      "emisor_nombre": "Sindicato Unificado de Polic√≠a (SUP)",\n      "contexto": "Descripci√≥n de la situaci√≥n de los hijos de polic√≠as",\n      "fecha_cita": null,\n      "relevancia_cita": 5\n    },\n    {\n      "cita": "no vamos a permitir que un pr√≥fugo de la Justicia y sus colegas m√°s radicales nos arrinconen",\n      "emisor_nombre": "Polic√≠as",\n      "contexto": "Reacci√≥n a la presi√≥n de los independentistas",\n      "fecha_cita": null,\n      "relevancia_cita": 4\n    },\n    {\n      "cita": "Acabar√°n cediendo. Es otro chantaje pol√≠tico",\n      "emisor_nombre": "Agente de la Polic√≠a Nacional",\n      "contexto": "Opini√≥n sobre la postura del Gobierno",\n      "fecha_cita": null,\n      "relevancia_cita": 3\n    },\n    {\n      "cita": "Es como una nube que tenemos encima que nos provoca estr√©s y ansiedad",\n      "emisor_nombre": "Funcionario de la Polic√≠a Nacional",\n      "contexto": "Descripci√≥n del impacto emocional del acoso",\n      "fecha_cita": null,\n      "relevancia_cita": 4\n    },\n    {\n      "cita": "Tendremos que comenzar de cero",\n      "emisor_nombre": "Funcionario de la Polic√≠a Nacional",\n      "contexto": "Preocupaci√≥n por el futuro",\n      "fecha_cita": null,\n      "relevancia_cita": 4\n    },\n    {\n      "cita": "Tendremos que comenzar de cero",\n      "emisor_nombre": "Funcionario de la Polic√≠a Nacional",\n      "contexto": "Preocupaci√≥n por el futuro",\n      "fecha_cita": null,\n      "relevancia_cita": 4\n    }\n  ]\n}'}}
2025-04-21 15:13:26,232 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_030] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:06<00:01,  4.87it/s][A[A[A[A2025-04-21 15:13:26,271 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:06<00:01,  3.18it/s][A[A2025-04-21 15:13:26,291 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_048] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:06<00:02,  2.99it/s][A[A[A2025-04-21 15:13:26,299 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_012] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:06<00:06,  1.62it/s][A[A[A[A[A2025-04-21 15:13:26,355 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:26,398 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:26,405 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_012] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:06<00:02,  3.35it/s][A[A[A[A[A2025-04-21 15:13:26,411 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_030] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:06<00:01,  5.02it/s][A[A[A[A2025-04-21 15:13:26,429 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:13:26,430 - ERROR - [test_030][extraccion_hechos][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "contenido": "El acoso a los hijos de polic√≠as en Barcelona aumenta, con docentes y otros padres que los hostigan.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-15",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Barcelona"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["acoso", "hijos de polic√≠as", "Barcelona"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La Ley de Amnist√≠a no ha frenado el hostigamiento a los hijos de polic√≠as.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Barcelona"],\n         "importancia": 7,\n         "confiabilidad": 5,\n         "etiquetas": ["Ley de Amnist√≠a", "hostigamiento", "hijos de polic√≠as"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "Los polic√≠as temen que los independentistas no descansen hasta que vean como les expulsan de Catalu√±a.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Catalu√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["independentistas", "expulsi√≥n", "Catalu√±a"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "Los ni√±os que son hijos de polic√≠as sufren burlas, se√±alamientos, exclusi√≥n social y comentarios despectivos en los centros educativos.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-15",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Barcelona"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["acoso", "hijos de polic√≠as", "centros educativos"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La presi√≥n pol√≠tica se traslada al resto de esferas, incluyendo la educaci√≥n, y vulnera los derechos de las familias de polic√≠as.",\n         "tipo_hecho": "EXPLICACI√ìN",\n         "fecha_ocurrencia_inicio": "2025-04-15",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Barcelona"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["presi√≥n pol√≠tica", "educaci√≥n", "derechos de las familias"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La Polic√≠a Nacional se siente hostigada y no se siente respaldada por el Gobierno.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Barcelona"],\n         "importancia": 7,\n         "confiabilidad": 5,\n         "etiquetas": ["Polic√≠a Nacional", "hostigamiento", "Gobierno"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "Los polic√≠as temen que los independentistas no descansen hasta que vean como les expulsan de Catalu√±a.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Catalu√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["independentistas", "expulsi√≥n", "Catalu√±a"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La "leyenda negra" de la Polic√≠a Nacional se ha construido de forma intencionada en torno a Via Laietana.",\n         "tipo_hecho": "EXPLICACI√ìN",\n         "fecha_ocurrencia_inicio": "2025-04-15",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Barcelona"],\n         "importancia": 7,\n         "confiabilidad": 5,\n         "etiquetas": ["leyenda negra", "Polic√≠a Nacional", "Via Laietana"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      }\n   ]\n}'}}
2025-04-21 15:13:26,445 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:06<00:00,  3.56it/s][A[A2025-04-21 15:13:26,498 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_048] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:06<00:02,  3.36it/s][A[A[A2025-04-21 15:13:26,512 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_030] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:06<00:00,  7.02it/s][A[A[A[A2025-04-21 15:13:26,548 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:13:26,549 - ERROR - [test_011][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""de impunidad y justicia selectiva"",\n         "emisor_nombre": "Instituto para las Mujeres en la Migraci√≥n (Imumi), Fundaci√≥n para la Justicia, entre otras organizaciones",\n         "contexto": "Rechazo a la resoluci√≥n del Tribunal Colegiado de Apelaci√≥n",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Notificaciones a altas horas de la noche (sin justificar la urgencia de las mismas), cambios repentinos en fechas de audiencias, anuncios que conciernen a las v√≠ctimas que no se notifican en tiempo y forma, como la disculpa p√∫blica, cuya fecha hab√≠a sido decidida unilateralmente por el comisionado sin previo acuerdo con todas las v√≠ctimas y sobrevivientes utilizando los medios y recursos del INM, entre otras ilicitudes"",\n         "emisor_nombre": "Instituto para las Mujeres en la Migraci√≥n (Imumi), Fundaci√≥n para la Justicia, entre otras organizaciones",\n         "contexto": "Cr√≠ticas al trato y ejercicio de derechos de las v√≠ctimas",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""De no realizarse en los t√©rminos se√±alados por el juez, la disculpa no deber√° ser tomada en cuenta como cumplida"",\n         "emisor_nombre": "Instituto para las Mujeres en la Migraci√≥n (Imumi), Fundaci√≥n para la Justicia, entre otras organizaciones",\n         "contexto": "Requisitos para la disculpa p√∫blica",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}

[test_011] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:06<00:00,  2.38it/s][A2025-04-21 15:13:26,599 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_048] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:06<00:01,  4.16it/s][A[A[A2025-04-21 15:13:26,711 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:26,718 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_012] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:06<00:01,  4.00it/s][A[A[A[A[A2025-04-21 15:13:26,879 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_011] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:06<00:00,  2.49it/s][A2025-04-21 15:13:27,213 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_048] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:07<00:01,  2.86it/s][A[A[A2025-04-21 15:13:27,356 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:27,356 - INFO - Retrying request to /openai/v1/chat/completions in 14.000000 seconds
2025-04-21 15:13:27,390 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_012] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:07<00:01,  3.00it/s][A[A[A[A[A2025-04-21 15:13:27,432 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:27,578 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_012] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:07<00:01,  3.32it/s][A[A[A[A[A2025-04-21 15:13:27,608 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_030] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:07<00:00,  3.50it/s][A[A[A[A2025-04-21 15:13:27,730 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_048] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:07<00:01,  2.50it/s][A[A[A2025-04-21 15:13:27,840 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_030] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:07<00:00,  3.64it/s][A[A[A[A2025-04-21 15:13:27,890 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_048] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:07<00:00,  3.04it/s][A[A[A2025-04-21 15:13:28,050 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_011] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:08<00:00,  1.73it/s][A
                                                                         [A2025-04-21 15:13:28,174 - INFO - --- Art√≠culo test_011 completado ---
2025-04-21 15:13:28,177 - INFO - --- Procesando Art√≠culo: test_067 ---
2025-04-21 15:13:28,187 - INFO - [test_067] Lanzando 25 llamadas a Groq...

[test_067] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][AProgreso General Art√≠culos:   1%|‚ñè         | 1/72 [00:08<10:02,  8.49s/it]2025-04-21 15:13:28,403 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_048] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:08<00:00,  2.60it/s][A[A[A2025-04-21 15:13:28,414 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_012] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:08<00:01,  2.33it/s][A[A[A[A[A2025-04-21 15:13:28,431 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:28,548 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:28,549 - INFO - Retrying request to /openai/v1/chat/completions in 19.000000 seconds
2025-04-21 15:13:28,582 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:28,583 - INFO - Retrying request to /openai/v1/chat/completions in 19.000000 seconds
2025-04-21 15:13:28,584 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:08<00:01,  1.33it/s][A[A2025-04-21 15:13:28,586 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:28,587 - INFO - Retrying request to /openai/v1/chat/completions in 20.000000 seconds
2025-04-21 15:13:28,587 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:28,588 - INFO - Retrying request to /openai/v1/chat/completions in 41.000000 seconds
2025-04-21 15:13:28,589 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:28,589 - INFO - Retrying request to /openai/v1/chat/completions in 41.000000 seconds
2025-04-21 15:13:28,639 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:28,639 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:13:28,674 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:28,675 - INFO - Retrying request to /openai/v1/chat/completions in 17.000000 seconds
2025-04-21 15:13:28,976 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_067] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:18,  1.30it/s][A2025-04-21 15:13:29,371 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_067] Llamadas Groq:   8%|‚ñä         | 2/25 [00:01<00:12,  1.82it/s][A2025-04-21 15:13:29,686 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_067] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:01<00:09,  2.26it/s][A2025-04-21 15:13:29,982 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:10<00:00,  1.08it/s][A[A2025-04-21 15:13:30,081 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_067] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:08,  2.36it/s][A2025-04-21 15:13:30,180 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:30,190 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_012] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:10<00:00,  1.63it/s][A[A[A[A[A2025-04-21 15:13:30,206 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_067] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:02<00:04,  4.30it/s][A2025-04-21 15:13:30,486 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:13:30,488 - ERROR - [test_067][extraccion_citas][llama3-8b-8192] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": "Es un honor tener aqu√≠ a un amigo m√≠o porque atravesamos esto juntos y nos llevamos muy bien durante todo mi mandato. Lo conoc√≠ siendo un hombre muy joven... Se√±or presidente es un honor tenerlo aqu√≠. Gracias. Usted est√° haciendo una labor incre√≠ble por su pa√≠s y apreciamos trabajar con usted, usted quiere combatir el crimen, nosotros tambi√©n. Quiero decir algo al pueblo de El Salvador, tienen a un fant√°stico presidente. Lo digo en serio, lo conozco bien",\n         "emisor_nombre": "El presidente de Estados Unidos",\n         "contexto": "Inici√≥ su discurso en la reuni√≥n con el presidente salvadore√±o Nayib Bukele",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "Es un honor estar aqu√≠ en la oficina oval con el presidente y l√≠der del mundo libre, estamos muy satisfechos, y estamos ansiosos de ayudar",\n         "emisor_nombre": "Nayib Bukele, presidente salvadore√±o",\n         "contexto": "Respondi√≥ a los elogios del presidente de Estados Unidos",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Dicen que hemos puesto en prisi√≥n a miles, en realidad hemos liberado a millones",\n         "emisor_nombre": "Nayib Bukele, presidente salvadore√±o",\n         "contexto": "Expres√≥ su punto de vista sobre la justicia en El Salvador",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "La realidad, se√±or presidente, es que usted tiene que liberar a 350 millones de personas, pero para hacer ese trabajo hay que poner a alguien en la c√°rcel, es inevitable, no se puede dejar a los criminales en libertad manteniendo en prisi√≥n a todos los dem√°s estadounidenses que claman por el fin del terrorismo y la criminalidad",\n         "emisor_nombre": "Nayib Bukele, presidente salvadore√±o",\n         "contexto": "Respondi√≥ a la cr√≠tica del presidente de Estados Unidos sobre la justicia en El Salvador",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "Somos un gran pa√≠s, pero tuvimos gente est√∫pida dirigi√©ndolo",\n         "emisor_nombre": "Donald Trump, presidente de Estados Unidos",\n         "contexto": "Despotric√≥ contra las administraciones anteriores",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": "Gracias por tener un lugar donde enviar a los peores de los peores. Queremos seguir con esa alianza porque es un mensaje muy potente de las consecuencias",\n         "emisor_nombre": "Kristi Noem, secretaria de seguridad nacional",\n         "contexto": "Intervino en la reuni√≥n con el presidente salvadore√±o",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": "Pens√≥ que lo liberar√≠an otra vez, ¬øqu√© hiciste?, le dispar√© a una pareja en la pierna pero no los mat√©... La √∫ltima vez dispar√≥ a un polic√≠a",\n         "emisor_nombre": "Nayib Bukele, presidente salvadore√±o",\n         "contexto": "Relat√≥ un caso de crimen en El Salvador",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "A tantos como sea posible. Justo le pregunt√© al presidente, ¬øsabe?, sobre este enorme complejo carcelario que construy√≥. Le dije: "¬øPodr√≠a construir m√°s, por favor?". Tantos como podamos sacar del pa√≠s, los que permiti√≥ el incompetente Joe Biden, a trav√©s de fronteras abiertas",\n         "emisor_nombre": "Donald Trump, presidente de Estados Unidos",\n         "contexto": "Respondi√≥ a una pregunta sobre la deportaci√≥n de delincuentes",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "Tenemos millones de personas que son asesinos, traficantes de drogas",\n         "emisor_nombre": "Donald Trump, presidente de Estados Unidos",\n         "contexto": "Respondi√≥ a una pregunta sobre la deportaci√≥n de delincuentes",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}

[test_067] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:02<00:04,  4.07it/s][A2025-04-21 15:13:30,555 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_012] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:10<00:00,  1.79it/s][A[A[A[A[A




                                                                         [A[A[A[A[A2025-04-21 15:13:30,570 - INFO - --- Art√≠culo test_012 completado ---
2025-04-21 15:13:30,572 - INFO - --- Procesando Art√≠culo: test_049 ---
2025-04-21 15:13:30,574 - INFO - [test_049] Lanzando 25 llamadas a Groq...





[test_049] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[A[AProgreso General Art√≠culos:   3%|‚ñé         | 2/72 [00:10<05:36,  4.81s/it]2025-04-21 15:13:30,720 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_067] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:02<00:04,  4.12it/s][A2025-04-21 15:13:30,732 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:30,733 - INFO - Retrying request to /openai/v1/chat/completions in 41.000000 seconds
2025-04-21 15:13:30,740 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:30,741 - INFO - Retrying request to /openai/v1/chat/completions in 14.000000 seconds
2025-04-21 15:13:30,809 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:30,810 - INFO - Retrying request to /openai/v1/chat/completions in 14.000000 seconds
2025-04-21 15:13:30,819 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:30,820 - INFO - Retrying request to /openai/v1/chat/completions in 40.000000 seconds
2025-04-21 15:13:30,823 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:30,823 - INFO - Retrying request to /openai/v1/chat/completions in 41.000000 seconds
2025-04-21 15:13:30,830 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:30,831 - INFO - Retrying request to /openai/v1/chat/completions in 40.000000 seconds
2025-04-21 15:13:30,927 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:30,927 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:13:30,939 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:30,940 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:13:30,964 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_067] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:02<00:03,  4.13it/s][A2025-04-21 15:13:31,105 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_049] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:12,  1.88it/s][A[A[A[A[A2025-04-21 15:13:31,155 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:31,203 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:13:31,205 - ERROR - [test_048][extraccion_hechos][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "contenido": "Falleci√≥ el escritor peruano Mario Vargas Llosa a la edad de 89 a√±os.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-13",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "d√≠a",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "fallecimiento", "escritor"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa gan√≥ el Premio Nobel de Literatura en 2010.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": "2010",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "a√±o",\n         "paises": ["SE", "PE"],\n         "ubicaciones_especificas": ["Estocolmo", "Per√∫"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "Premio Nobel", "literatura"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El Boom latinoamericano de literatura fue un movimiento literario que se desarroll√≥ en la d√©cada de 1960.",\n         "tipo_hecho": "CONCEPTO",\n         "fecha_ocurrencia_inicio": "1960",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "d√©cada",\n         "paises": ["LA"],\n         "ubicaciones_especificas": ["Am√©rica Latina"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["Boom latinoamericano", "literatura"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un defensor de la democracia y la libertad de expresi√≥n.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "democracia", "libertad de expresi√≥n"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un autor prol√≠fico que escribi√≥ numerosas obras de ficci√≥n y no ficci√≥n.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "literatura"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un defensor de la cultura y la literatura latinoamericanas.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "cultura", "literatura latinoamericana"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un autor influyente que dej√≥ una huella duradera en la literatura latinoamericana.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "literatura latinoamericana"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un defensor de la libertad de expresi√≥n y la democracia en Am√©rica Latina.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "democracia", "libertad de expresi√≥n"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un autor prol√≠fico que escribi√≥ numerosas obras de ficci√≥n y no ficci√≥n.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "literatura"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un defensor de la cultura y la literatura latinoamericanas.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "cultura", "literatura latinoamericana"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un autor influyente que dej√≥ una huella duradera en la literatura latinoamericana.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "literatura latinoamericana"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un defensor de la libertad de expresi√≥n y la democracia en Am√©rica Latina.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "democracia", "libertad de expresi√≥n"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un autor prol√≠fico que escribi√≥ numerosas obras de ficci√≥n y no ficci√≥n.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "literatura"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un defensor de la cultura y la literatura latinoamericanas.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "cultura", "literatura latinoamericana"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un autor influyente que dej√≥ una huella duradera en la literatura latinoamericana.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "literatura latinoamericana"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un defensor de la libertad de expresi√≥n y la democracia en Am√©rica Latina.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "democracia", "libertad de expresi√≥n"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un autor prol√≠fico que escribi√≥ numerosas obras de ficci√≥n y no ficci√≥n.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "literatura"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un defensor de la cultura y la literatura latinoamericanas.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "cultura", "literatura latinoamericana"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un autor influyente que dej√≥ una huella duradera en la literatura latinoamericana.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "literatura latinoamericana"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un defensor de la libertad de expresi√≥n y la democracia en Am√©rica Latina.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "democracia", "libertad de expresi√≥n"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un autor prol√≠fico que escribi√≥ numerosas obras de ficci√≥n y no ficci√≥n.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "literatura"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un defensor de la cultura y la literatura latinoamericanas.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "cultura", "literatura latinoamericana"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un autor influyente que dej√≥ una huella duradera en la literatura latinoamericana.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "literatura latinoamericana"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un defensor de la libertad de expresi√≥n y la democracia en Am√©rica Latina.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "democracia", "libertad de expresi√≥n"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El escritor peruano Mario Vargas Llosa fue un autor prol√≠fico que escribi√≥ numerosas obras de ficci√≥n y no ficci√≥n.",\n         "tipo_hecho": "BIOGRAFIA",\n         "fecha_ocurrencia_inicio": null,\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "no especificado",\n         "paises": ["PE"],\n         "ubicaciones_especificas": ["Per√∫"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Mario Vargas Llosa", "literatura"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      }}'}}



[test_048] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:11<00:01,  1.10s/it][A[A[A2025-04-21 15:13:31,215 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_049] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:03,  5.59it/s][A[A[A[A[A2025-04-21 15:13:31,238 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:31,279 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:31,281 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:13:31,283 - ERROR - [test_067][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Es un honor tener aqu√≠ a un amigo m√≠o porque atravesamos esto juntos y nos llevamos muy bien durante todo mi mandato. Lo conoc√≠ siendo un hombre muy joven... Se√±or presidente es un honor tenerlo aqu√≠. Gracias. Usted est√° haciendo una labor incre√≠ble por su pa√≠s y apreciamos trabajar con usted, usted quiere combatir el crimen, nosotros tambi√©n. Quiero decir algo al pueblo de El Salvador, tienen a un fant√°stico presidente. Lo digo en serio, lo conozco bien"",\n         "emisor_nombre": "El presidente de Estados Unidos",\n         "contexto": "Inici√≥ su discurso en la reuni√≥n con Bukele",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Es un honor estar aqu√≠ en la oficina oval con el presidente y l√≠der del mundo libre, estamos muy satisfechos, y estamos ansiosos de ayudar"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Respondi√≥ con elogios a Trump",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Dicen que hemos puesto en prisi√≥n a miles, en realidad hemos liberado a millones"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Expres√≥ su punto de vista sobre la pol√≠tica de prisi√≥n en El Salvador",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Me parece que puedo usar ese lema, es excelente"",\n         "emisor_nombre": "Donald Trump",\n         "contexto": "Respondi√≥ a Bukele sobre su pol√≠tica de prisi√≥n",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""La realidad, se√±or presidente, es que usted tiene que liberar a 350 millones de personas, pero para hacer ese trabajo hay que poner a alguien en la c√°rcel, es inevitable, no se puede dejar a los criminales en libertad manteniendo en prisi√≥n a todos los dem√°s estadounidenses que claman por el fin del terrorismo y la criminalidad"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Critic√≥ la pol√≠tica de prisi√≥n de Trump",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Estoy seguro que la gente ha notado un cambio en las calles, usted apenas est√° comenzando su segundo mandato, es evidente considerando las cifras en la frontera, incluso en las ciudades manejadas manejadas por dem√≥cratas se nota la diferencia, es un honor y encantado de poder ayudar"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Elogi√≥ a Trump",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Somos un gran pa√≠s, pero tuvimos gente est√∫pida dirigi√©ndolo"",\n         "emisor_nombre": "Donald Trump",\n         "contexto": "Despotric√≥ contra las administraciones anteriores",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""Gracias por tener un lugar donde enviar a los peores de los peores. Queremos seguir con esa alianza porque es un mensaje muy potente de las consecuencias"",\n         "emisor_nombre": "Kristi Noem",\n         "contexto": "Intervino en la reuni√≥n",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""Pens√≥ que lo liberar√≠an otra vez, ¬øqu√© hiciste?, le dispar√© a una pareja en la pierna pero no los mat√©... La √∫ltima vez dispar√≥ a un polic√≠a"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Relat√≥ un caso de un venezolano deportado a El Salvador",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Esta es la guerra de Biden y yo estoy tratando de detenerla"",\n         "emisor_nombre": "Donald Trump",\n         "contexto": "Respondi√≥ a preguntas sobre la guerra en Ucrania",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Con el presidente Bukele, tengo una excelente relaci√≥n con √©l. Nos conocemos. Lo conozco desde muy joven, como dije, muy joven y me impresion√≥. Le dije: "Miren a este tipo. De hecho, parece un adolescente. ¬øQu√© clase de pa√≠s es este? Creci√≥, creci√≥ bien en los √∫ltimos cinco a√±os"",\\n         "emisor_nombre": "Donald Trump",\\n         "contexto": "Respondi√≥ a preguntas sobre la extensi√≥n del TPS",\\n         "fecha_cita": null,\\n         "relevancia_cita": 4\\n      },\\n      {\\n         "cita": ""A tantos como sea posible. Justo le pregunt√© al presidente, ¬øsabe?, sobre este enorme complejo carcelario que construy√≥. Le dije: "¬øPodr√≠a construir m√°s, por favor?". Tantos como podamos sacar del pa√≠s, los que permiti√≥ el incompetente Joe Biden, a trav√©s de fronteras abiertas"",\\n         "emisor_nombre": "Donald Trump",\\n         "contexto": "Respondi√≥ a preguntas sobre la deportaci√≥n de delincuentes ilegales",\\n         "fecha_cita": null,\\n         "relevancia_cita": 5\\n      },\\n      {\\n         "cita": ""Tenemos millones de personas que son asesinos, traficantes de drogas"",\\n         "emisor_nombre": "Donald Trump",\\n         "contexto": "Respondi√≥ a preguntas sobre la deportaci√≥n de delincuentes ilegales",\\n         "fecha_cita": null,\\n         "relevancia_cita": 4\\n      },\\n      {\\n         "cita": ""Me gustar√≠a que fu√©ramos un paso m√°s all√°, por supuesto, tenemos que cumplir las leyes, me gustar√≠a incluir a esas personas en ese grupo de personas que vamos a echar del pa√≠s, pero tendremos que ver lo que dicen las leyes"",\\n         "emisor_nombre": "Donald Trump",\\n         "contexto": "Respondi√≥ a preguntas sobre la deportaci√≥n de criminales estadounidenses",\\n         "fecha_cita": null,\\n         "relevancia_cita": 4\\n      }\\n   ]\\n}'}}
2025-04-21 15:13:31,283 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_067] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:03<00:03,  3.78it/s][A2025-04-21 15:13:31,441 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_067] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:03<00:03,  4.28it/s][A2025-04-21 15:13:31,664 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_049] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:02,  7.48it/s][A[A[A[A[A2025-04-21 15:13:31,689 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:31,760 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:31,830 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_067] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:03<00:03,  3.58it/s][A2025-04-21 15:13:32,103 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_049] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:02,  7.20it/s][A[A[A[A[A2025-04-21 15:13:32,114 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:32,216 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_049] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:01<00:01,  8.67it/s][A[A[A[A[A2025-04-21 15:13:32,277 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:32,327 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_049] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:01<00:01, 10.21it/s][A[A[A[A[A2025-04-21 15:13:32,442 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_067] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:04<00:04,  2.64it/s][A2025-04-21 15:13:32,657 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:32,913 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_049] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:01,  6.44it/s][A[A[A[A[A2025-04-21 15:13:33,337 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_067] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:05<00:05,  1.88it/s][A2025-04-21 15:13:33,443 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:33,889 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_067] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:05<00:05,  1.86it/s][A2025-04-21 15:13:34,018 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_067] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:05<00:03,  2.41it/s][A2025-04-21 15:13:34,298 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:34,299 - ERROR - [test_030][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 34024, Requested 1720. Please try again in 11.489s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_030] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:14<00:01,  1.66s/it][A[A[A[A2025-04-21 15:13:34,685 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:13:34,688 - ERROR - [test_067][extraccion_entidades][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "nombre": "Casa Blanca",\n         "tipo": "LUGAR",\n         "alias": ["Casa Blanca"],\n         "descripcion_contextual": "Residencia oficial del presidente de Estados Unidos",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Washington",\n         "tipo": "LUGAR",\n         "alias": ["Washington D.C."],\n         "descripcion_contextual": "Capital de Estados Unidos",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Donald Trump",\n         "tipo": "PERSONA",\n         "alias": ["Trump"],\n         "descripcion_contextual": "Presidente de Estados Unidos",\n         "relevancia_articulo": 10\n      },\n      {\n         "nombre": "Nayib Bukele",\n         "tipo": "PERSONA",\n         "alias": ["Bukele"],\n         "descripcion_contextual": "Presidente de El Salvador",\n         "relevancia_articulo": 10\n      },\n      {\n         "nombre": "Marco Rubio",\n         "tipo": "PERSONA",\n         "alias": ["Rubio"],\n         "descripcion_contextual": "Secretario de Estado de Estados Unidos",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Kristi Noem",\n         "tipo": "PERSONA",\n         "alias": ["Noem"],\n         "descripcion_contextual": "Secretaria de Seguridad Nacional de Estados Unidos",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Pam Bondi",\n         "tipo": "PERSONA",\n         "alias": ["Bondi"],\n         "descripcion_contextual": "Fiscal de Estados Unidos",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Stephen Miller",\n         "tipo": "PERSONA",\n         "alias": ["Miller"],\n         "descripcion_contextual": "Subjefe de Gabinete de Pol√≠ticas de la Casa Blanca",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Joe Biden",\n         "tipo": "PERSONA",\n         "alias": ["Biden"],\n         "descripcion_contextual": "Presidente de Estados Unidos",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Kilmar √Åbrego",\n         "tipo": "PERSONA",\n         "alias": ["√Åbrego"],\n         "descripcion_contextual": "Salvadore√±o deportado por error",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "MS-13",\n         "tipo": "ORGANIZACION",\n         "alias": ["MS-13"],\n         "descripcion_contextual": "Pandilla criminal",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Casa Blanca",\n         "tipo": "INSTITUCION",\n         "alias": ["Casa Blanca"],\n         "descripcion_contextual": "Residencia oficial del presidente de Estados Unidos",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El Salvador",\n         "tipo": "LUGAR",\n         "alias": ["El Salvador"],\n         "descripcion_contextual": "Pa√≠s centroamericano",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Estados Unidos",\n         "tipo": "LUGAR",\n         "alias": ["EE.UU."],\n         "descripcion_contextual": "Pa√≠s norteamericano",\n         "relevancia_articulo": 10\n      },\n      {\n         "nombre": "Ucrania",\n         "tipo": "LUGAR",\n         "alias": ["Ucrania"],\n         "descripcion_contextual": "Pa√≠s europeo",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Venezuela",\n         "tipo": "LUGAR",\n         "alias": ["Venezuela"],\n         "descripcion_contextual": "Pa√≠s sudamericano",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Coney Island",\n         "tipo": "LUGAR",\n         "alias": ["Coney Island"],\n         "descripcion_contextual": "Barrio de Brooklyn, Nueva York",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Brooklyn",\n         "tipo": "LUGAR",\n         "alias": ["Brooklyn"],\n         "descripcion_contextual": "Barrio de Nueva York",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Tren de Aragua",\n         "tipo": "ORGANIZACION",\n         "alias": ["Tren de Aragua"],\n         "descripcion_contextual": "Pandilla criminal",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "CECOT",\n         "tipo": "LUGAR",\n         "alias": ["CECOT"],\n         "descripcion_contextual": "Centro de detenci√≥n en El Salvador",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "TPS",\n         "tipo": "NORMATIVA",\n         "alias": ["TPS"],\n         "descripcion_contextual": "Programa de Estatus de Protecci√≥n Temporal",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Casa Blanca",\n         "tipo": "INSTITUCION",\n         "alias": ["Casa Blanca"],\n         "descripcion_contextual": "Residencia oficial del presidente de Estados Unidos",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "MS-13",\n         "tipo": "ORGANIZACION",\n         "alias": ["MS-13"],\n         "descripcion_contextual": "Pandilla criminal",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El Salvador",\n         "tipo": "LUGAR",\n         "alias": ["El Salvador"],\n         "descripcion_contextual": "Pa√≠s centroamericano",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Estados Unidos",\n         "tipo": "LUGAR",\n         "alias": ["EE.UU."],\n         "descripcion_contextual": "Pa√≠s norteamericano",\n         "relevancia_articulo": 10\n      },\n      {\n         "nombre": "Ucrania",\n         "tipo": "LUGAR",\n         "alias": ["Ucrania"],\n         "descripcion_contextual": "Pa√≠s europeo",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Venezuela",\n         "tipo": "LUGAR",\n         "alias": ["Venezuela"],\n         "descripcion_contextual": "Pa√≠s sudamericano",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Coney Island",\n         "tipo": "LUGAR",\n         "alias": ["Coney Island"],\n         "descripcion_contextual": "Barrio de Brooklyn, Nueva York",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Brooklyn",\n         "tipo": "LUGAR",\n         "alias": ["Brooklyn"],\n         "descripcion_contextual": "Barrio de Nueva York",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Tren de Aragua",\n         "tipo": "ORGANIZACION",\n         "alias": ["Tren de Aragua"],\n         "descripcion_contextual": "Pandilla criminal",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "CECOT",\n         "tipo": "LUGAR",\n         "alias": ["CECOT"],\n         "descripcion_contextual": "Centro de detenci√≥n en El Salvador",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "TPS",\n         "tipo": "NORMATIVA",\n         "alias": ["TPS"],\n         "descripcion_contextual": "Programa de Estatus de Protecci√≥n Temporal",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Casa Blanca",\n         "tipo": "INSTITUCION",\n         "alias": ["Casa Blanca"],\n         "descripcion_contextual": "Residencia oficial del presidente de Estados Unidos",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "MS-13",\n         "tipo": "ORGANIZACION",\n         "alias": ["MS-13"],\n         "descripcion_contextual": "Pandilla criminal",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El Salvador",\n         "tipo": "LUGAR",\n         "alias": ["El Salvador"],\n         "descripcion_contextual": "Pa√≠s centroamericano",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Estados Unidos",\n         "tipo": "LUGAR",\n         "alias": ["EE.UU."],\n         "descripcion_contextual": "Pa√≠s norteamericano",\n         "relevancia_articulo": 10\n      },\n      {\n         "nombre": "Ucrania",\n         "tipo": "LUGAR",\n         "alias": ["Ucrania"],\n         "descripcion_contextual": "Pa√≠s europeo",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Venezuela",\n         "tipo": "LUGAR",\n         "alias": ["Venezuela"],\n         "descripcion_contextual": "Pa√≠s sudamericano",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Coney Island",\n         "tipo": "LUGAR",\n         "alias": ["Coney Island"],\n         "descripcion_contextual": "Barrio de Brooklyn, Nueva York",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Brooklyn",\n         "tipo": "LUGAR",\n         "alias": ["Brooklyn"],\n         "descripcion_contextual": "Barrio de Nueva York",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Tren de Aragua",\n         "tipo": "ORGANIZACION",\n         "alias": ["Tren de Aragua"],\n         "descripcion_contextual": "Pandilla criminal",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "CECOT",\n         "tipo": "LUGAR",\n         "alias": ["CECOT"],\n         "descripcion_contextual": "Centro de detenci√≥n en El Salvador",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "TPS",\n         "tipo": "NORMATIVA",\n         "alias": ["TPS"],\n         "descripcion_contextual": "Programa de Estatus de Protecci√≥n Temporal",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Casa Blanca",\n         "tipo": "INSTITUCION",\n         "alias": ["Casa Blanca"],\n         "descripcion_contextual": "Residencia oficial del presidente de Estados Unidos",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "MS-13",\n         "tipo": "ORGANIZACION",\n         "alias": ["MS-13"],\n         "descripcion_contextual": "Pandilla criminal",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El Salvador",\n         "tipo": "LUGAR",\n         "alias": ["El Salvador"],\n         "descripcion_contextual": "Pa√≠s centroamericano",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Estados Unidos",\n         "tipo": "LUGAR",\n         "alias": ["EE.UU."],\n         "descripcion_contextual": "Pa√≠s norteamericano",\n         "relevancia_articulo": 10\n      },\n      {\n         "nombre": "Ucrania",\n         "tipo": "LUGAR",\n         "alias": ["Ucrania"],\n         "descripcion_contextual": "Pa√≠s europeo",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Venezuela",\n         "tipo": "LUGAR",\n         "alias": ["Venezuela"],\n         "descripcion_contextual": "Pa√≠s sudamericano",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Coney Island",\n         "tipo": "LUGAR",\n         "alias": ["Coney Island"],\n         "descripcion_contextual": "Barrio de Brooklyn, Nueva York",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Brooklyn",\n         "tipo": "LUGAR",\n         "alias": ["Brooklyn"],\n         "descripcion_contextual": "Barrio de Nueva York",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Tren de Aragua",\n         "tipo": "ORGANIZACION",\n         "alias": ["Tren de Aragua"],\n         "descripcion_contextual": "Pandilla criminal",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "CECOT",\n         "tipo": "LUGAR",\n         "alias": ["CECOT"],\n         "descripcion_contextual": "Centro de detenci√≥n en El Salvador",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "TPS",\n         "tipo": "NORMATIVA",\n         "alias": ["TPS"],\n         "descripcion_contextual": "Programa de Estatus de Protecci√≥n Temporal",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Casa Blanca",\n         "tipo": "INSTITUCION",\n         "alias": ["Casa Blanca"],\n         "descripcion_contextual": "Residencia oficial del presidente de Estados Unidos",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "MS-13",\n         "tipo": "ORGANIZACION",\n         "alias": ["MS-13"],\n         "descripcion_contextual": "Pandilla criminal",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El Salvador",\n         "tipo": "LUGAR",\n         "alias": ["El Salvador"],\n         "descripcion_contextual": "Pa√≠s centroamericano",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Estados Unidos",\n         "tipo": "LUGAR",\n         "alias": ["EE.UU."],\n         "descripcion_contextual": "Pa√≠s norteamericano",\n         "relevancia_articulo": 10\n      },\n      {\n         "nombre": "Ucrania",\n         "tipo": "LUGAR",\n         "alias": ["Ucrania"],\n         "descripcion_contextual": "Pa√≠s europeo",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Venezuela",\n         "tipo": "LUGAR",\n         "alias": ["Venezuela"],\n         "descripcion_contextual": "Pa√≠s sudamericano",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Coney Island",\n         "tipo": "LUGAR",\n         "alias": ["Coney Island"],\n         "descripcion_contextual": "Barrio de Brooklyn, Nueva York",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Brooklyn",\n         "tipo": "LUGAR",\n         "alias": ["Brooklyn"],\n         "descripcion_contextual": "Barrio de Nueva York",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Tren de Aragua",\n         "tipo": "ORGANIZACION",\n         "alias": ["Tren de Aragua"],\n         "descripcion_contextual": "Pandilla criminal",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "CECOT",\n         "tipo": "LUGAR",\n         "alias": ["CECOT"],\n         "descripcion_contextual": "Centro de detenci√≥n en El Salvador",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "TPS",\n         "tipo": "NORMATIVA",\n         "alias": ["TPS"],\n         "descripcion_contextual": "Programa de Estatus de Protecci√≥n Temporal",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Casa Blanca",\n         "tipo": "INSTITUCION",\n         "alias": ["Casa Blanca"],\n         "descripcion_contextual": "Residencia oficial del presidente de Estados Unidos",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "MS-13",\n         "tipo": "ORGANIZACION",\n         "alias": ["MS-13"],\n         "descripcion_contextual": "Pandilla criminal",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El Salvador",\n         "tipo": "LUGAR",\n         "alias": ["El Salvador"],\n         "descripcion_contextual": "Pa√≠s centroamericano",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Estados Unidos",\n         "tipo": "LUGAR",\n         "alias": ["EE.UU."],\n         "descripcion_contextual": "Pa√≠s norteamericano",\n         "relevancia_articulo": 10\n      },\n      {\n         "nombre": "Ucrania",\n         "tipo": "LUGAR",\n         "alias": ["Ucrania"],\n         "descripcion_contextual": "Pa√≠s europeo",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Venezuela",\n         "tipo": "LUGAR",\n         "alias": ["Venezuela"],\n         "descripcion_contextual": "Pa√≠s sudamericano",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Coney Island",\n         "tipo": "LUGAR",\n         "alias": ["Coney Island"],\n         "descripcion_contextual": "Barrio de Brooklyn, Nueva York",\n         "relevancia_articulo": 4\n      }}'}}

[test_067] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:06<00:03,  2.04it/s][A2025-04-21 15:13:34,901 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:34,902 - ERROR - [test_030][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32259, Requested 1832. Please try again in 8.182s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_030] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:14<00:00,  1.40s/it][A[A[A[A



                                                                         [A[A[A[A2025-04-21 15:13:34,915 - INFO - --- Art√≠culo test_030 completado ---
2025-04-21 15:13:34,916 - INFO - --- Procesando Art√≠culo: test_031 ---
2025-04-21 15:13:34,917 - INFO - [test_031] Lanzando 25 llamadas a Groq...




[test_031] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[AProgreso General Art√≠culos:   4%|‚ñç         | 3/72 [00:15<05:17,  4.60s/it]2025-04-21 15:13:35,067 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:35,068 - INFO - Retrying request to /openai/v1/chat/completions in 11.000000 seconds
2025-04-21 15:13:35,087 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:35,088 - INFO - Retrying request to /openai/v1/chat/completions in 38.000000 seconds
2025-04-21 15:13:35,097 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:35,098 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:13:35,108 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:35,108 - INFO - Retrying request to /openai/v1/chat/completions in 11.000000 seconds
2025-04-21 15:13:35,113 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:35,114 - INFO - Retrying request to /openai/v1/chat/completions in 38.000000 seconds
2025-04-21 15:13:35,137 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:35,137 - INFO - Retrying request to /openai/v1/chat/completions in 11.000000 seconds
2025-04-21 15:13:35,153 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:35,154 - INFO - Retrying request to /openai/v1/chat/completions in 11.000000 seconds
2025-04-21 15:13:35,158 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:35,159 - INFO - Retrying request to /openai/v1/chat/completions in 38.000000 seconds
2025-04-21 15:13:35,585 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_031] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:16,  1.49it/s][A[A[A[A2025-04-21 15:13:35,722 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_031] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:08,  2.81it/s][A[A[A[A2025-04-21 15:13:35,730 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:35,924 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_031] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:04,  5.10it/s][A[A[A[A2025-04-21 15:13:36,019 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:13:36,020 - ERROR - [test_031][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Es una buena noticia, porque se trata de una integraci√≥n real y concreta"",\n         "emisor_nombre": "Gabriel Boric",\n         "contexto": "Presentaci√≥n del plan de obras de infraestructura del Corredor Bioce√°nico Vial",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""coincidieron en la importancia de hacer frente a los desaf√≠os que presenta el actual contexto internacional"",\n         "emisor_nombre": "Cancilleres del Mercosur",\n         "contexto": "Reuni√≥n de los cancilleres del Mercosur en Buenos Aires",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""en ese marco, coincidieron en la necesidad de ampliar temporariamente la Lista Nacional de Excepciones al Arancel Externo Com√∫n de cada Estado parte"",\n         "emisor_nombre": "Cancilleres del Mercosur",\n         "contexto": "Reuni√≥n de los cancilleres del Mercosur en Buenos Aires",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}
2025-04-21 15:13:36,080 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_067] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:07<00:05,  1.31it/s][A2025-04-21 15:13:36,155 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_031] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:03,  6.32it/s][A[A[A[A2025-04-21 15:13:36,231 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:36,532 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_031] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  5.87it/s][A[A[A[A2025-04-21 15:13:36,969 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_031] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:02<00:03,  4.35it/s][A[A[A[A2025-04-21 15:13:37,261 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_031] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:02<00:03,  4.08it/s][A[A[A[A2025-04-21 15:13:38,334 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_031] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:03<00:06,  2.18it/s][A[A[A[A2025-04-21 15:13:38,565 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_031] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:03<00:05,  2.52it/s][A[A[A[A2025-04-21 15:13:39,483 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_031] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:04<00:06,  1.85it/s][A[A[A[A2025-04-21 15:13:41,032 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:41,034 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:13:41,045 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:41,046 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:13:41,477 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:41,478 - ERROR - [test_048][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30431, Requested 3202. Please try again in 7.267s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_048] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:21<00:00,  3.85s/it][A[A[A


                                                                         [A[A[A2025-04-21 15:13:41,493 - INFO - --- Art√≠culo test_048 completado ---
2025-04-21 15:13:41,494 - INFO - --- Procesando Art√≠culo: test_013 ---
2025-04-21 15:13:41,494 - INFO - [test_013] Lanzando 25 llamadas a Groq...



[test_013] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[AProgreso General Art√≠culos:   6%|‚ñå         | 4/72 [00:21<06:05,  5.38s/it]2025-04-21 15:13:41,554 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_031] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:06<00:10,  1.03it/s][A[A[A[A2025-04-21 15:13:41,656 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:41,657 - INFO - Retrying request to /openai/v1/chat/completions in 31.000000 seconds
2025-04-21 15:13:41,724 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:41,725 - INFO - Retrying request to /openai/v1/chat/completions in 32.000000 seconds
2025-04-21 15:13:41,726 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:41,726 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:13:41,740 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:41,741 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:13:41,769 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:41,770 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:13:41,803 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:41,803 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:13:41,883 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:41,884 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:13:42,150 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_013] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:15,  1.52it/s][A[A[A2025-04-21 15:13:42,275 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_013] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:07,  2.91it/s][A[A[A2025-04-21 15:13:42,403 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_013] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:05,  4.08it/s][A[A[A2025-04-21 15:13:42,454 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:42,540 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:13:42,541 - ERROR - [test_013][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Informamos a la poblaci√≥n que este lunes, con base en an√°lisis de informaci√≥n penitenciaria, se realiz√≥ un recorrido minucioso en el Centro de Rehabilitaci√≥n de Puerto Barrios, en el departamento de Izabal"",\n         "emisor_nombre": "Sergio Vela",\n         "contexto": "Confirmaci√≥n de la inspecci√≥n en el Centro de Rehabilitaci√≥n de Puerto Barrios",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""La visi√≥n de Renovaci√≥n Penitenciaria contin√∫a avanzando en la restauraci√≥n del control en los centros de detenci√≥n del pa√≠s"",\n         "emisor_nombre": "Sergio Vela",\n         "contexto": "Mensaje de Sergio Vela sobre la visi√≥n de Renovaci√≥n Penitenciaria",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""Hoy nuevamente pretend√≠a fugarse usando el mismo m√©todo, se presume que es el l√≠der organizador t√∫neles para darse a la fuga"",\n         "emisor_nombre": "PNC",\n         "contexto": "Descripci√≥n de la intenci√≥n de fuga de Marcos Baudilio Godoy Trujillo",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Se presume que es el l√≠der organizador t√∫neles para darse a la fuga"",\n         "emisor_nombre": "PNC",\n         "contexto": "Descripci√≥n de la intenci√≥n de fuga de Marcos Baudilio Godoy Trujillo",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}



[test_013] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:02,  6.89it/s][A[A[A2025-04-21 15:13:42,671 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_013] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:02,  7.09it/s][A[A[A2025-04-21 15:13:42,715 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_031] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:07<00:10,  1.03s/it][A[A[A[A2025-04-21 15:13:42,743 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:42,746 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:42,825 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_066] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:22<00:00,  4.20s/it][A[A

                                                                         [A[A2025-04-21 15:13:42,846 - INFO - --- Art√≠culo test_066 completado ---
2025-04-21 15:13:42,847 - INFO - --- Procesando Art√≠culo: test_068 ---
2025-04-21 15:13:42,848 - INFO - [test_068] Lanzando 25 llamadas a Groq...


[test_068] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[AProgreso General Art√≠culos:   7%|‚ñã         | 5/72 [00:23<04:23,  3.93s/it]2025-04-21 15:13:43,006 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_031] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:08<00:07,  1.23it/s][A[A[A[A2025-04-21 15:13:43,013 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:43,014 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:13:43,036 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:43,037 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:13:43,076 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:43,077 - INFO - Retrying request to /openai/v1/chat/completions in 29.000000 seconds
2025-04-21 15:13:43,079 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:43,080 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:13:43,081 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:43,082 - INFO - Retrying request to /openai/v1/chat/completions in 29.000000 seconds
2025-04-21 15:13:43,087 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:43,088 - INFO - Retrying request to /openai/v1/chat/completions in 28.000000 seconds
2025-04-21 15:13:43,098 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:43,098 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:13:43,100 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_013] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:02,  7.03it/s][A[A[A2025-04-21 15:13:43,199 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:43,201 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_013] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:02,  7.49it/s][A[A[A2025-04-21 15:13:43,213 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:43,214 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:13:43,323 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_068] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:11,  2.10it/s][A[A2025-04-21 15:13:43,412 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:43,458 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_068] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:03,  5.76it/s][A[A2025-04-21 15:13:43,532 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:43,556 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:43,583 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_013] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:02,  6.45it/s][A[A[A2025-04-21 15:13:43,664 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:43,796 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_068] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:00<00:02,  7.35it/s][A[A2025-04-21 15:13:43,819 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:13:43,820 - ERROR - [test_068][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Gano la Presidencia, cierro el Congreso y convoco a una constituyente para resetear este pa√≠s, porque, as√≠ como est√°, el pa√≠s no funciona. No hay que tenerlo miedo a esta generaci√≥n. Esta generaci√≥n est√° lista para plantear una nueva institucionalidad"",\n         "emisor_nombre": "Daniel Quintero Calle",\n         "contexto": "Entrevista en la revista Cambio",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Puede gustarnos o no. Podemos criticarlo las veces que queramos y estar en desacuerdo con las pr√°cticas corruptas de muchos de sus miembros, pero el Congreso de la Rep√∫blica, pilar de la democracia, nunca se cierra. Nunca. Hacerlo es de dictadores"",\n         "emisor_nombre": "Gustavo Bol√≠var",\n         "contexto": "Respuesta a Daniel Quintero Calle en redes sociales",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}
2025-04-21 15:13:43,987 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:43,987 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:13:43,989 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_013] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:02<00:01,  5.82it/s][A[A[A2025-04-21 15:13:44,004 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_068] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  8.04it/s][A[A2025-04-21 15:13:44,076 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:44,119 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_068] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01,  9.87it/s][A[A2025-04-21 15:13:44,125 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:44,287 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_049] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:13<00:12,  1.79s/it][A[A[A[A[A2025-04-21 15:13:44,305 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:44,306 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:13:44,322 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_068] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:01<00:01,  9.86it/s][A[A2025-04-21 15:13:44,490 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:13:44,491 - ERROR - [test_068][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n  "resultados": [\n    {\n      "nombre": "Daniel Quintero Calle",\n      "tipo": "PERSONA",\n      "alias": [\n        "Quintero"\n      ],\n      "descripcion_contextual": "Exalcalde que propone cerrar el Congreso y convocar una constituyente.",\n      "relevancia_articulo": 9\n    },\n    {\n      "nombre": "Presidencia de Colombia",\n      "tipo": "ORGANIZACION",\n      "alias": [],\n      "descripcion_contextual": "Cargo al que aspira Quintero.",\n      "relevancia_articulo": 7\n    },\n    {\n      "nombre": "Congreso de la Rep√∫blica de Colombia",\n      "tipo": "INSTITUCION",\n      "alias": [\n        "Congreso"\n      ],\n      "descripcion_contextual": "Poder legislativo al que Quintero propone cerrar.",\n      "relevancia_articulo": 8\n    },\n    {\n      "nombre": "Constituyente",\n      "tipo": "EVENTO",\n      "alias": [],\n      "descripcion_contextual": "Propuesta de Quintero para reformar la institucionalidad.",\n      "relevancia_articulo": 7\n    },\n    {\n      "nombre": "Departamento de Prosperidad Social (DPS)",\n      "tipo": "INSTITUCION",\n      "alias": [],\n      "descripcion_contextual": "Instituci√≥n gubernamental a la que pertenece Bol√≠var.",\n      "relevancia_articulo": 6\n    },\n    {\n      "nombre": "Gustavo Bol√≠var",\n      "tipo": "PERSONA",\n      "alias": [],\n      "descripcion_contextual": "Director del DPS que critica la propuesta de Quintero.",\n      "relevancia_articulo": 6\n    },\n    {\n      "nombre": "Petrismo",\n      "tipo": "CONCEPTO",\n      "alias": [],\n      "descripcion_contextual": "Movimiento pol√≠tico al que se refiere Quintero.",\n      "relevancia_articulo": 5\n    },\n    {\n      "nombre": "Redes sociales",\n      "tipo": "CONCEPTO",\n      "alias": [],\n      "descripcion_contextual": "Plataformas donde se gener√≥ debate sobre la propuesta.",\n      "relevancia_articulo": 4\n    },\n    {\n      "nombre": "X",\n      "tipo": "ORGANIZACION",\n      "alias": [],\n      "descripcion_contextual": "Plataforma donde Bol√≠var public√≥ su respuesta.",\n      "relevancia_articulo": 3\n    },\n    {\n      "nombre": "Democracia",\n      "tipo": "CONCEPTO",\n      "alias": [],\n      "descripcion_contextual": Valor que Bol√≠var defiende al criticar la propuesta de Quintero.",\n      "relevancia_articulo": 4\n    }\n  ]\n}'}}
2025-04-21 15:13:44,540 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_068] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:01<00:01,  9.63it/s][A[A2025-04-21 15:13:44,547 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_013] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:03<00:02,  4.02it/s][A[A[A2025-04-21 15:13:44,664 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_013] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:03<00:01,  4.55it/s][A[A[A2025-04-21 15:13:44,826 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:44,847 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:44,848 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:13:45,141 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:45,142 - ERROR - [test_013][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29215, Requested 1515. Please try again in 1.459s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_013] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:03<00:02,  3.56it/s][A[A[A2025-04-21 15:13:45,168 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:45,169 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:13:45,192 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:45,193 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:13:45,292 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:45,293 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:13:45,364 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_067] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:17<00:19,  3.31s/it][A2025-04-21 15:13:45,412 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_031] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:10<00:10,  1.28s/it][A[A[A[A2025-04-21 15:13:45,518 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_049] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:14<00:10,  1.69s/it][A[A[A[A[A2025-04-21 15:13:45,541 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_068] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:02,  4.38it/s][A[A2025-04-21 15:13:45,773 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_068] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:02<00:01,  4.37it/s][A[A2025-04-21 15:13:45,795 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_013] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:04<00:02,  2.66it/s][A[A[A2025-04-21 15:13:45,924 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:45,925 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:13:45,961 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:45,962 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:13:46,298 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:46,299 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:13:46,305 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:46,306 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:13:46,378 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:46,379 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:13:46,487 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_068] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:03<00:02,  3.03it/s][A[A2025-04-21 15:13:46,573 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:46,577 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:13:46,613 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:13:46,615 - ERROR - [test_049][extraccion_datos][llama3-70b-8192] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados":[\n      {\n         "indicador":"Fecha del evento",\n         "categoria":"electoral",\n         "valor_numerico":2023.04.05,\n         "unidad":"YYYY-MM-DD",\n         "ambito_geografico":["Medell√≠n"],\n         "periodo_referencia_inicio":null,\n         "periodo_referencia_fin":null,\n         "tipo_periodo":null,\n         "fuente_especifica":null,\n         "notas_contexto":null\n      },\n      {\n         "indicador":"A√±o electoral",\n         "categoria":"electoral",\n         "valor_numerico":2026,\n         "unidad":"a√±o",\n         "ambito_geografico":["Colombia"],\n         "periodo_referencia_inicio":null,\n         "periodo_referencia_fin":null,\n         "tipo_periodo":null,\n         "fuente_especifica":null,\n         "notas_contexto":null\n      }\n   ]\n}'}}





[test_049] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:16<00:07,  1.57s/it][A[A[A[A[A2025-04-21 15:13:46,772 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_031] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:11<00:09,  1.30s/it][A[A[A[A2025-04-21 15:13:46,967 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:46,968 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:13:47,026 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_013] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:05<00:03,  1.65it/s][A[A[A2025-04-21 15:13:47,151 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_068] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:04<00:01,  3.59it/s][A[A2025-04-21 15:13:47,224 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:47,225 - ERROR - [test_013][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29462, Requested 1887. Please try again in 2.697s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_013] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:05<00:02,  2.03it/s][A[A[A2025-04-21 15:13:47,665 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:47,666 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:13:47,782 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:47,783 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:13:47,840 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_049] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:17<00:05,  1.50s/it][A[A[A[A[A2025-04-21 15:13:48,356 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_068] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:05<00:01,  2.23it/s][A[A2025-04-21 15:13:48,452 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_013] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:06<00:02,  1.43it/s][A[A[A2025-04-21 15:13:48,804 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:48,805 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:13:49,527 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:49,528 - ERROR - [test_031][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30244, Requested 1446. Please try again in 3.381s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_031] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:14<00:10,  1.74s/it][A[A[A[A2025-04-21 15:13:50,057 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:50,058 - ERROR - [test_013][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32181, Requested 1776. Please try again in 7.915s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_013] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:08<00:02,  1.04it/s][A[A[A2025-04-21 15:13:50,192 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:50,193 - ERROR - [test_013][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29908, Requested 1663. Please try again in 3.142s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_013] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:08<00:01,  1.39it/s][A[A[A2025-04-21 15:13:50,475 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:50,477 - ERROR - [test_031][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31972, Requested 1707. Please try again in 7.359s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_031] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:15<00:07,  1.50s/it][A[A[A[A2025-04-21 15:13:50,538 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:50,539 - ERROR - [test_031][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29735, Requested 1820. Please try again in 3.11s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:13:51,982 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_031] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:17<00:03,  1.16s/it][A[A[A[A2025-04-21 15:13:52,024 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:52,025 - ERROR - [test_067][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31200, Requested 2757. Please try again in 7.914s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_067] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:23<00:21,  4.32s/it][A2025-04-21 15:13:52,102 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:52,103 - ERROR - [test_067][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 28997, Requested 2393. Please try again in 2.779s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:13:56,888 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:13:56,889 - ERROR - [test_067][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 28770, Requested 2542. Please try again in 2.623s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_067] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:28<00:10,  3.45s/it][A2025-04-21 15:13:57,179 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_067] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:28<00:05,  2.67s/it][A2025-04-21 15:14:09,709 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:09,710 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:14:11,604 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_049] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:41<00:20,  6.85s/it][A[A[A[A[A2025-04-21 15:14:11,863 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_049] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:41<00:10,  5.16s/it][A[A[A[A[A2025-04-21 15:14:12,157 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_068] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:29<00:10,  5.29s/it][A[A2025-04-21 15:14:12,190 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:12,191 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:12,225 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:12,226 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:14:12,755 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:12,756 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:14:12,840 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_049] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:42<00:04,  4.04s/it][A[A[A[A[A2025-04-21 15:14:13,188 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:13,188 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:14:13,215 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:13,216 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:14:13,486 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_049] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:42<00:00,  3.10s/it][A[A[A[A[A




                                                                         [A[A[A[A[A2025-04-21 15:14:13,503 - INFO - --- Art√≠culo test_049 completado ---
2025-04-21 15:14:13,504 - INFO - --- Procesando Art√≠culo: test_050 ---
2025-04-21 15:14:13,505 - INFO - [test_050] Lanzando 25 llamadas a Groq...





[test_050] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[A[AProgreso General Art√≠culos:   8%|‚ñä         | 6/72 [00:53<14:18, 13.02s/it]2025-04-21 15:14:13,751 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:13,752 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:14:13,763 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:13,764 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:14:13,776 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:13,777 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:13,852 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:13,853 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:14:13,889 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_067] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:45<00:06,  6.34s/it][A2025-04-21 15:14:13,976 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_031] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:39<00:12,  6.31s/it][A[A[A[A2025-04-21 15:14:14,003 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_050] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:11,  2.00it/s][A[A[A[A[A2025-04-21 15:14:14,349 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_050] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:09,  2.45it/s][A[A[A[A[A2025-04-21 15:14:14,493 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_050] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:06,  3.47it/s][A[A[A[A[A2025-04-21 15:14:14,596 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_050] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:04,  4.65it/s][A[A[A[A[A2025-04-21 15:14:15,059 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_050] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:06,  3.28it/s][A[A[A[A[A2025-04-21 15:14:15,219 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_050] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:04,  3.92it/s][A[A[A[A[A2025-04-21 15:14:15,261 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:15,278 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:15,683 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_050] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:02<00:03,  5.11it/s][A[A[A[A[A2025-04-21 15:14:15,898 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_068] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:33<00:04,  4.94s/it][A[A2025-04-21 15:14:15,953 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:15,954 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:14:16,222 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_050] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:02<00:04,  3.69it/s][A[A[A[A[A2025-04-21 15:14:16,259 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:16,309 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:16,324 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:16,325 - ERROR - [test_068][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29422, Requested 1033. Please try again in 910ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_068] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:33<00:00,  3.83s/it][A[A

                                                                         [A[A2025-04-21 15:14:16,336 - INFO - --- Art√≠culo test_068 completado ---
2025-04-21 15:14:16,336 - INFO - --- Procesando Art√≠culo: test_032 ---
2025-04-21 15:14:16,337 - INFO - [test_032] Lanzando 25 llamadas a Groq...


[test_032] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[AProgreso General Art√≠culos:  10%|‚ñâ         | 7/72 [00:56<10:29,  9.69s/it]2025-04-21 15:14:16,483 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_050] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:02<00:02,  5.49it/s][A[A[A[A[A2025-04-21 15:14:16,508 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:16,509 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:16,581 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:16,582 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:16,585 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:16,586 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:14:16,696 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:16,697 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:14:16,824 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:14:16,826 - ERROR - [test_050][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""pleno apoyo" a sus reformas econ√≥micas",\n         "emisor_nombre": "Scott Bessent",\n         "contexto": "Reuni√≥n con el presidente Javier Milei",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""reafirm√≥ el pleno apoyo" de su pa√≠s "a las audaces reformas econ√≥micas"",\n         "emisor_nombre": "Scott Bessent",\n         "contexto": "Reuni√≥n con el presidente Javier Milei",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""la pronta acci√≥n de su gobierno para reducir las barreras al comercio rec√≠proco con Estados Unidos"",\n         "emisor_nombre": "Scott Bessent",\n         "contexto": "Reuni√≥n con el presidente Javier Milei",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""felicit√≥ al Presidente por las recientes y exitosas negociaciones de Argentina con el Fondo Monetario Internacional (FMI)"",\n         "emisor_nombre": "Scott Bessent",\n         "contexto": "Reuni√≥n con el presidente Javier Milei",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""reiter√≥ la confianza de Estados Unidos en el Presidente Milei para continuar impulsando el positivo impulso econ√≥mico de Argentina"",\n         "emisor_nombre": "Scott Bessent",\n         "contexto": "Reuni√≥n con el presidente Javier Milei",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""el apoyo que ha dado en el FMI, en el Banco Mundial y en el BID"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "Declaraci√≥n conjunta con Scott Bessent",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""est√° haciendo que se discutan desequilibrios comerciales de muchos a√±os en pos de un redise√±o m√°s justo"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "Aludiendo a la suba de aranceles de Trump",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""A nivel comercial entendemos la propuesta de aranceles rec√≠procos que elabor√≥ Trump y estamos listos para firmar un acuerdo comercial en dicha l√≠nea que beneficiar√° a ambos"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "Aludiendo a la suba de aranceles de Trump",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""la econom√≠a argentina se balanceaba al borde de un precipicio con default y una emisi√≥n desbordada y la soluci√≥n a estos problemas siempre era m√°s gasto, m√°s burocracia y menos ten√≠a la gente"",\n         "emisor_nombre": "Scott Bessent",\n         "contexto": "Recordando la situaci√≥n econ√≥mica de Argentina antes de la llegada de Milei",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Ese hombre est√° aqu√≠, es Javier Milei, me enorgullece apoyarlo en su esfuerzo de volver a hacer grande a la Argentina"",\n         "emisor_nombre": "Scott Bessent",\n         "contexto": "Aludiendo a la llegada de Milei a la presidencia",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Me entusiasmaba hace este viaje a Argentina para comenzar a tener las primeras conversaciones formales sobre comercio rec√≠proco"",\n         "emisor_nombre": "Scott Bessent",\n         "contexto": "Aludiendo a su visita a Argentina",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""a lo que deber√≠a ser un auge de masivas inversiones directas"",\n         "emisor_nombre": "Scott Bessent",\n         "contexto": "Aludiendo a las reformas de Milei",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""por su papel fundamental en el dise√±o e implementaci√≥n" de las reformas de la gesti√≥n libertaria"",\\n         "emisor_nombre": "Scott Bessent",\\n         "contexto": "Elogio al ministro de Econom√≠a, Luis Caputo",\\n         "fecha_cita": null,\\n         "relevancia_cita": 4\\n      },\\n      {\\n         "cita": ""Argentina puede lograr un futuro brillante para su poblaci√≥n mediante pol√≠ticas econ√≥micas que brinden estabilidad y crecimiento a los trabajadores del pa√≠s y a las din√°micas empresas del sector privado"",\\n         "emisor_nombre": "Scott Bessent",\\n         "contexto": "Elogio al ministro de Econom√≠a, Luis Caputo",\\n         "fecha_cita": null,\\n         "relevancia_cita": 5\\n      },\\n      {\\n         "cita": ""Elogi√≥ a Argentina por su r√°pida negociaci√≥n con Estados Unidos sobre un paquete de medidas comerciales rec√≠procas"",\\n         "emisor_nombre": "Scott Bessent",\\n         "contexto": "Elogio al ministro de Econom√≠a, Luis Caputo",\\n         "fecha_cita": null,\\n         "relevancia_cita": 4\\n      },\\n      {\\n         "cita": ""manifest√≥ su inter√©s en copresidir, junto con el Representante Comercial de Estados Unidos (USTR), las conversaciones pendientes con Argentina en un futuro muy pr√≥ximo"",\\n         "emisor_nombre": "Scott Bessent",\\n         "contexto": "Elogio al ministro de Econom√≠a, Luis Caputo",\\n         "fecha_cita": null,\\n         "relevancia_cita": 4\\n      }\\n   ]\\n}'}}





[test_050] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:03<00:02,  4.73it/s][A[A[A[A[A2025-04-21 15:14:16,835 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_032] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:11,  2.00it/s][A[A2025-04-21 15:14:16,868 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:16,878 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:16,884 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:16,885 - ERROR - [test_013][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29147, Requested 1663. Please try again in 1.619s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_013] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:35<00:08,  8.36s/it][A[A[A2025-04-21 15:14:16,894 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



                                                                         [A[A[A2025-04-21 15:14:16,906 - INFO - --- Art√≠culo test_013 completado ---
2025-04-21 15:14:16,907 - INFO - --- Procesando Art√≠culo: test_014 ---
2025-04-21 15:14:16,909 - INFO - [test_014] Lanzando 25 llamadas a Groq...



[test_014] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[AProgreso General Art√≠culos:  11%|‚ñà         | 8/72 [00:57<07:14,  6.78s/it]2025-04-21 15:14:16,968 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_050] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:03<00:01,  6.11it/s][A[A[A[A[A2025-04-21 15:14:16,978 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:18,185 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:14:18,188 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:18,189 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:18,190 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:18,192 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:18,193 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:18,194 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:18,195 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:18,196 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:18,197 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:18,198 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:14:18,221 - ERROR - [test_032][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""A siete a√±os del inicio de la crisis de derechos humanos en Nicaragua, la CIDH condena la continua represi√≥n estatal y la consolidaci√≥n de un r√©gimen autoritario"",\n         "emisor_nombre": "Comisi√≥n Interamericana de Derechos Humanos (CIDH)",\n         "contexto": "Declaraci√≥n p√∫blica de la CIDH",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""La situaci√≥n de derechos humanos en Nicaragua sigue siendo una de las m√°s cr√≠ticas de la regi√≥n y contin√∫a deterior√°ndose"",\n         "emisor_nombre": "Comisi√≥n Interamericana de Derechos Humanos (CIDH)",\n         "contexto": "Mensaje de la CIDH",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""A ello se suman las reformas constitucionales publicadas en febrero de este a√±o entre las cuales destaca la centralizaci√≥n del control absoluto del poder pol√≠tico en la Presidencia, encabezada por un copresidente y una copresidenta"",\n         "emisor_nombre": "Comisi√≥n Interamericana de Derechos Humanos (CIDH)",\n         "contexto": "Mensaje de la CIDH",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""En este contexto de cierre de espacio c√≠vico, persiste la persecuci√≥n contra periodistas, personas defensoras, artistas y cualquier persona percibida como opositora"",\n         "emisor_nombre": "Comisi√≥n Interamericana de Derechos Humanos (CIDH)",\n         "contexto": "Mensaje de la CIDH",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Por tanto, la CIDH urgi√≥ al Estado de Nicaragua a cesar de inmediato las violaciones a los derechos humanos, restablecer el Estado de derecho y a liberar de inmediato a todas las personas que se encuentran privadas arbitrariamente de su libertad por motivos pol√≠ticos"",\n         "emisor_nombre": "Comisi√≥n Interamericana de Derechos Humanos (CIDH)",\n         "contexto": "Mensaje de la CIDH",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}

[test_067] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:50<00:00,  5.79s/it][A
                                                                         [A2025-04-21 15:14:18,239 - INFO - --- Art√≠culo test_067 completado ---


[test_032] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:01<00:14,  1.54it/s][A[A




[test_050] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:04<00:03,  2.61it/s][A[A[A[A[A2025-04-21 15:14:18,248 - INFO - --- Procesando Art√≠culo: test_069 ---
2025-04-21 15:14:18,249 - INFO - [test_069] Lanzando 25 llamadas a Groq...

[test_069] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][AProgreso General Art√≠culos:  12%|‚ñà‚ñé        | 9/72 [00:58<05:20,  5.09s/it]2025-04-21 15:14:18,372 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_032] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:02<00:01,  7.08it/s][A[A2025-04-21 15:14:18,423 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:18,515 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:18,535 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_032] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:02<00:01,  8.98it/s][A[A2025-04-21 15:14:18,548 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:18,610 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:18,611 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:14:18,612 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:18,613 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:18,620 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:18,621 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:14:18,643 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:18,644 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:18,698 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:18,699 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:18,721 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:18,722 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:14:18,859 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_014] Llamadas Groq:   4%|‚ñç         | 1/25 [00:01<00:46,  1.95s/it][A[A[A2025-04-21 15:14:18,882 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:18,936 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:18,961 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_014] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:02<00:08,  2.52it/s][A[A[A2025-04-21 15:14:18,986 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_069] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:17,  1.36it/s][A2025-04-21 15:14:19,019 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:19,086 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_069] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:08,  2.75it/s][A2025-04-21 15:14:19,101 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:19,126 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_014] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:02<00:04,  3.85it/s][A[A[A2025-04-21 15:14:19,162 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:19,179 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_050] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:05<00:03,  1.97it/s][A[A[A[A[A2025-04-21 15:14:19,188 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_069] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:00<00:03,  5.97it/s][A2025-04-21 15:14:19,205 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:19,209 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:19,294 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_014] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:02<00:02,  6.19it/s][A[A[A2025-04-21 15:14:19,333 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:19,388 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:19,569 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_014] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:01,  7.52it/s][A[A[A2025-04-21 15:14:19,628 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:19,685 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:19,721 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:19,722 - INFO - Retrying request to /openai/v1/chat/completions in 15.000000 seconds
2025-04-21 15:14:19,748 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_014] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:02<00:01,  8.29it/s][A[A[A2025-04-21 15:14:19,752 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:19,753 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:14:19,784 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:19,785 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:14:19,814 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:19,931 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_050] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:06<00:02,  2.19it/s][A[A[A[A[A2025-04-21 15:14:19,934 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:14:19,936 - ERROR - [test_050][extraccion_hechos][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "contenido": "El secretario del Tesoro de los Estados Unidos, Scott Bessent, se reuni√≥ con el presidente argentino Javier Milei en Casa Rosada.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": ["Casa Rosada"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Javier Milei", "Casa Rosada"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense reafirm√≥ el pleno apoyo de su pa√≠s a las reformas econ√≥micas de Milei.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Javier Milei", "reformas econ√≥micas"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense elogi√≥ a Milei por la pronta acci√≥n de su gobierno para reducir las barreras al comercio rec√≠proco con Estados Unidos.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Javier Milei", "comercio rec√≠proco"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense felicit√≥ a Milei por las recientes y exitosas negociaciones de Argentina con el FMI.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Javier Milei", "FMI"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense reiter√≥ la confianza de Estados Unidos en el Presidente Milei para continuar impulsando el positivo impulso econ√≥mico de Argentina.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Javier Milei", "impulso econ√≥mico"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense se reuni√≥ con el ministro de Econom√≠a, Luis Caputo, y elogi√≥ su papel fundamental en el dise√±o e implementaci√≥n de las reformas de la gesti√≥n libertaria.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 7,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Luis Caputo", "reformas de la gesti√≥n libertaria"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense destac√≥ que Argentina puede lograr un futuro brillante para su poblaci√≥n mediante pol√≠ticas econ√≥micas que brinden estabilidad y crecimiento a los trabajadores del pa√≠s y a las din√°micas empresas del sector privado.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Argentina", "pol√≠ticas econ√≥micas"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense manifest√≥ su inter√©s en copresidir, junto con el Representante Comercial de Estados Unidos (USTR), las conversaciones pendientes con Argentina en un futuro muy pr√≥ximo.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Argentina", "conversaciones pendientes"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense record√≥ que la econom√≠a argentina se balanceaba al borde de un precipicio con default y una emisi√≥n desbordada y la soluci√≥n a estos problemas siempre era m√°s gasto, m√°s burocracia y menos ten√≠a la gente.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Argentina", "econom√≠a"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense destac√≥ que luego apareci√≥ un hombre con el coraje de defender a la Argentina, oponi√©ndose al establishment, y ese hombre est√° aqu√≠, es Javier Milei.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Javier Milei", "establishment"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense destac√≥ que Milei se comprometi√≥ a combatir el gasto p√∫blico excesivo, y el presidente Trump, lo mismo.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Javier Milei", "gasto p√∫blico excesivo"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense destac√≥ que Milei y el movimiento MAGA comparten lo mismo, privilegian la democracia por sobre la burocracia y destrabar el crecimiento econ√≥mico.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Javier Milei", "movimiento MAGA"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense destac√≥ que el apoyo del FMI, el Banco Mundial y el BID a las reformas de Milei dar√° lugar a lo que deber√≠a ser un auge de masivas inversiones directas.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Javier Milei", "FMI", "Banco Mundial", "BID"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense destac√≥ que el apoyo del FMI, el Banco Mundial y el BID a las reformas de Milei dar√° lugar a lo que deber√≠a ser un auge de masivas inversiones directas.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Javier Milei", "FMI", "Banco Mundial", "BID"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense destac√≥ que el apoyo del FMI, el Banco Mundial y el BID a las reformas de Milei dar√° lugar a lo que deber√≠a ser un auge de masivas inversiones directas.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Javier Milei", "FMI", "Banco Mundial", "BID"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense destac√≥ que el apoyo del FMI, el Banco Mundial y el BID a las reformas de Milei dar√° lugar a lo que deber√≠a ser un auge de masivas inversiones directas.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Javier Milei", "FMI", "Banco Mundial", "BID"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense destac√≥ que el apoyo del FMI, el Banco Mundial y el BID a las reformas de Milei dar√° lugar a lo que deber√≠a ser un auge de masivas inversiones directas.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Javier Milei", "FMI", "Banco Mundial", "BID"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense destac√≥ que el apoyo del FMI, el Banco Mundial y el BID a las reformas de Milei dar√° lugar a lo que deber√≠a ser un auge de masivas inversiones directas.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Javier Milei", "FMI", "Banco Mundial", "BID"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense destac√≥ que el apoyo del FMI, el Banco Mundial y el BID a las reformas de Milei dar√° lugar a lo que deber√≠a ser un auge de masivas inversiones directas.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Javier Milei", "FMI", "Banco Mundial", "BID"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense destac√≥ que el apoyo del FMI, el Banco Mundial y el BID a las reformas de Milei dar√° lugar a lo que deber√≠a ser un auge de masivas inversiones directas.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Javier Milei", "FMI", "Banco Mundial", "BID"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El secretario del Tesoro estadounidense destac√≥ que el apoyo del FMI, el Banco Mundial y el BID a las reformas de Milei dar√° lugar a lo que deber√≠a ser un auge de masivas inversiones directas.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-21",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["US", "AR"],\n         "ubicaciones_especificas": [],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Scott Bessent", "Javier Milei", "FMI", "Banco Mundial", "BID"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      }}'}}
2025-04-21 15:14:19,970 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_032] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:03<00:01,  4.50it/s][A[A2025-04-21 15:14:19,994 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:20,228 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:20,229 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:14:20,238 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_069] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:06,  2.97it/s][A2025-04-21 15:14:20,264 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:20,429 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:20,430 - ERROR - [test_050][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 28588, Requested 1491. Please try again in 157ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_050] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:06<00:00,  3.08it/s][A[A[A[A[A2025-04-21 15:14:20,537 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:14:20,538 - ERROR - [test_069][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""El cepo se puso durante el final del gobierno de Macri con Hern√°n Lacunza, generando un monstruo cambiario que adem√°s defaulte√≥ la deuda en pesos. Bajo el artilugio del reperfilamiento, Lacunza y Macri defaultearon deuda en pesos, algo in√©dito"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "En declaraciones a FM El Observador",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Por el tema de la Ciudad se gener√≥ mucho problema y est√°n demonizando a mi hermana de una manera absolutamente injusta. Yo dije vamos juntos en todos lados. ¬øY yo desdobl√© las elecciones en la Ciudad?"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "En un discurso",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""¬øA usted le parece que por eso nosotros podemos avalar una suba de impuestos (en la Ciudad)? ¬øO que nosotros proponemos una agenda de reformas parecidas a las que estamos haciendo en Naci√≥n y las voltean? No hay voluntad de cambio en la Ciudad"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "En un discurso",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Que explique por qu√© quiso subir los impuestos, por qu√© quiere sostener ese Estado elefanti√°sico, por qu√© la Ciudad es una mugre... Se lo dice el propio Larreta. Mire qu√© bajo han ca√≠do que hasta Larreta hace eso. Ac√° el que decidi√≥ desdoblar y violentar la posibilidad de un acuerdo para defender el reducto fue Jorge Macri"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "En un discurso",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""¬øUsted no vio la √∫ltima foto de mi hermana, Ritondo, Santilli, Lule (Menem), (Sebasti√°n) Pareja...? ¬øEso no muestra que tenemos una voluntad de ir a ganar la Provincia todos juntos? ¬øUsted cree que la gente se sienta en esa foto de manera inocua? Estamos para ir y ganarles a los kukas en la provincia de Buenos Aires. Nuestra intenci√≥n es ganarles y sacarles el basti√≥n kirchnerista por antonomasia"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "En un di√°logo con el periodista Luis Majul",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Contrataron para una campa√±a negativa contra m√≠ a Guti√©rrez-Rub√≠, el mismo que contrat√≥ Massa. ¬øNo le parece un acto de deslealtad? A m√≠ me parece una traici√≥n por la espalda si empieza a repetir las cosas que hizo con Massa"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "En un discurso",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}

[test_069] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:02<00:05,  3.06it/s][A2025-04-21 15:14:20,570 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:20,657 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_069] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:02<00:03,  4.65it/s][A2025-04-21 15:14:20,696 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:20,756 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:20,770 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_069] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:02<00:02,  6.42it/s][A2025-04-21 15:14:20,784 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_014] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:03<00:02,  4.27it/s][A[A[A2025-04-21 15:14:20,833 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:20,833 - INFO - Retrying request to /openai/v1/chat/completions in 16.000000 seconds
2025-04-21 15:14:20,943 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_032] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:04<00:01,  3.56it/s][A[A2025-04-21 15:14:21,477 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_014] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:04<00:02,  3.21it/s][A[A[A2025-04-21 15:14:21,517 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:21,519 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:21,735 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:21,735 - INFO - Retrying request to /openai/v1/chat/completions in 20.000000 seconds
2025-04-21 15:14:21,746 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_050] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:08<00:00,  2.00it/s][A[A[A[A[A2025-04-21 15:14:21,765 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:21,766 - INFO - Retrying request to /openai/v1/chat/completions in 21.000000 seconds
2025-04-21 15:14:21,847 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:21,848 - INFO - Retrying request to /openai/v1/chat/completions in 20.000000 seconds
2025-04-21 15:14:21,898 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_069] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:03<00:03,  3.36it/s][A2025-04-21 15:14:22,254 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_014] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:05<00:02,  2.97it/s][A[A[A2025-04-21 15:14:22,331 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:22,332 - ERROR - [test_032][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31412, Requested 1826. Please try again in 6.476s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:14:22,334 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:22,339 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:14:22,341 - ERROR - [test_032][extraccion_hechos][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "contenido": "La CIDH denunci√≥ la consolidaci√≥n de un r√©gimen autoritario en Nicaragua.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "r√©gimen autoritario"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH condena la continua represi√≥n estatal en Nicaragua.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "represi√≥n estatal"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una situaci√≥n cr√≠tica de derechos humanos.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "derechos humanos"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una crisis sociopol√≠tica y de derechos humanos desde 2018.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2018-04-01T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "crisis sociopol√≠tica"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que al menos 355 personas murieron en las protestas en Nicaragua en 2018.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2018-04-01T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "protestas"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una situaci√≥n de cierre de espacio c√≠vico.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "cierre de espacio c√≠vico"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una persecuci√≥n contra periodistas y personas defensoras.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "persecuci√≥n"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una persecuci√≥n contra l√≠deres religiosos y comunidades de fe.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "persecuci√≥n religiosa"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una persecuci√≥n contra la libertad de prensa.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "persecuci√≥n a la libertad de prensa"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una situaci√≥n de represi√≥n estatal.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "represi√≥n estatal"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una situaci√≥n de cierre de espacio c√≠vico.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "cierre de espacio c√≠vico"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una situaci√≥n de persecuci√≥n religiosa.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "persecuci√≥n religiosa"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una situaci√≥n de persecuci√≥n a la libertad de prensa.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "persecuci√≥n a la libertad de prensa"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una situaci√≥n de represi√≥n estatal.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "represi√≥n estatal"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una situaci√≥n de cierre de espacio c√≠vico.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "cierre de espacio c√≠vico"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una situaci√≥n de persecuci√≥n religiosa.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "persecuci√≥n religiosa"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una situaci√≥n de persecuci√≥n a la libertad de prensa.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "persecuci√≥n a la libertad de prensa"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una situaci√≥n de represi√≥n estatal.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "represi√≥n estatal"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una situaci√≥n de cierre de espacio c√≠vico.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "cierre de espacio c√≠vico"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una situaci√≥n de persecuci√≥n religiosa.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "persecuci√≥n religiosa"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una situaci√≥n de persecuci√≥n a la libertad de prensa.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "persecuci√≥n a la libertad de prensa"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una situaci√≥n de represi√≥n estatal.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "represi√≥n estatal"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una situaci√≥n de cierre de espacio c√≠vico.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "cierre de espacio c√≠vico"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "La CIDH denunci√≥ que Nicaragua vive una situaci√≥n de persecuci√≥n religiosa.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-15T00:00:00.000000",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "exacta",\n         "paises": ["NI"],\n         "ubicaciones_especificas": ["Nicaragua"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["CIDH", "Nicaragua", "persecuci√≥n religiosa"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      }}'}}


[test_032] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:06<00:01,  2.62it/s][A[A2025-04-21 15:14:22,872 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_031] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:47<00:06,  6.98s/it][A[A[A[A2025-04-21 15:14:22,920 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_014] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:06<00:01,  2.98it/s][A[A[A2025-04-21 15:14:23,007 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_031] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:48<00:00,  5.12s/it][A[A[A[A



                                                                         [A[A[A[A2025-04-21 15:14:23,025 - INFO - --- Art√≠culo test_031 completado ---
2025-04-21 15:14:23,025 - INFO - --- Procesando Art√≠culo: test_051 ---
2025-04-21 15:14:23,026 - INFO - [test_051] Lanzando 25 llamadas a Groq...




[test_051] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[AProgreso General Art√≠culos:  14%|‚ñà‚ñç        | 10/72 [01:03<05:09,  4.99s/it]2025-04-21 15:14:23,186 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:23,187 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:14:23,230 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_014] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:06<00:00,  3.02it/s][A[A[A2025-04-21 15:14:23,267 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:23,268 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:14:23,280 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:23,281 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:23,284 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:23,285 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:14:23,290 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:23,290 - INFO - Retrying request to /openai/v1/chat/completions in 17.000000 seconds
2025-04-21 15:14:23,370 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_069] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:05<00:05,  1.88it/s][A2025-04-21 15:14:23,540 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_014] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:06<00:00,  3.06it/s][A[A[A2025-04-21 15:14:23,696 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_051] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:16,  1.49it/s][A[A[A[A2025-04-21 15:14:23,752 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:23,798 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_069] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:05<00:05,  1.97it/s][A2025-04-21 15:14:23,881 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:23,881 - ERROR - [test_032][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31666, Requested 1942. Please try again in 7.217s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_032] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:07<00:01,  1.81it/s][A[A2025-04-21 15:14:23,889 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_051] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:05,  4.08it/s][A[A[A[A2025-04-21 15:14:24,021 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:24,022 - ERROR - [test_069][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 34559, Requested 2142. Please try again in 13.403s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_069] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:05<00:03,  2.27it/s][A2025-04-21 15:14:24,071 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_032] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:07<00:00,  2.04it/s][A[A2025-04-21 15:14:24,155 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_051] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:05,  3.96it/s][A[A[A[A2025-04-21 15:14:24,195 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_069] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:05<00:02,  2.69it/s][A2025-04-21 15:14:24,237 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:24,259 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:14:24,262 - ERROR - [test_014][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El sujeto cruz√≥ la calle para evitar pasar junto a una patrulla que brindaba seguridad en la zona, lo que alert√≥ a los oficiales"",\n         "emisor_nombre": "Fern√°ndez",\n         "contexto": "Descripci√≥n de la detenci√≥n del presunto miembro de la Mara Salvatrucha",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }}'}}



[test_014] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:07<00:00,  2.40it/s][A[A[A2025-04-21 15:14:24,268 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_051] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:02,  6.45it/s][A[A[A[A2025-04-21 15:14:24,452 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:24,495 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_051] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  7.26it/s][A[A[A[A2025-04-21 15:14:24,562 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_069] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:06<00:02,  2.70it/s][A2025-04-21 15:14:24,689 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_051] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:02,  6.63it/s][A[A[A[A2025-04-21 15:14:24,798 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:14:24,802 - ERROR - [test_069][extraccion_datos][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "indicador": "Tasa de inflaci√≥n interanual",\n         "categoria": "econ√≥mico",\n         "valor_numerico": "34.61",\n         "unidad": "%",\n         "ambito_geografico": ["Santa Fe"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": "seg√∫n estimaciones preliminares"\n      },\n      {\n         "indicador": "N√∫mero de votos obtenidos por Pullaro",\n         "categoria": "electoral",\n         "valor_numerico": "15",\n         "unidad": "% del electorado en verdad",\n         "ambito_geografico": ["Santa Fe"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de asistentes a manifestaci√≥n",\n         "categoria": "social",\n         "valor_numerico": null,\n         "unidad": null,\n         "ambito_geografico": null,\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "4",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "1",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "4",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "1",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "4",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "1",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "4",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "1",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "4",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "1",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "4",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "1",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "4",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "1",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "4",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "1",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "4",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "1",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "4",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "1",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "4",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "1",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "4",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "1",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "4",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "1",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "4",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "1",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "4",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "1",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "4",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "1",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "4",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "1",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "4",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "1",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de legisladores locales",\n         "categoria": "electoral",\n         "valor_numerico": "4",\n         "unidad": null,\n         "ambito_geografico": ["Ciudad de Buenos Aires"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": null,\n         "notas_contexto": null\n      }}'}}

[test_069] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:06<00:02,  2.99it/s][A2025-04-21 15:14:24,881 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_051] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:02,  6.22it/s][A[A[A[A2025-04-21 15:14:24,925 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_032] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:08<00:00,  1.78it/s][A[A2025-04-21 15:14:25,118 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_032] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:08<00:00,  2.08it/s][A[A

                                                                         [A[A2025-04-21 15:14:25,135 - INFO - --- Art√≠culo test_032 completado ---
2025-04-21 15:14:25,135 - INFO - --- Procesando Art√≠culo: test_033 ---
2025-04-21 15:14:25,136 - INFO - [test_033] Lanzando 25 llamadas a Groq...


[test_033] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[AProgreso General Art√≠culos:  15%|‚ñà‚ñå        | 11/72 [01:05<04:10,  4.11s/it]2025-04-21 15:14:25,198 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_051] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:02<00:02,  4.96it/s][A[A[A[A2025-04-21 15:14:25,207 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:25,300 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:25,301 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:14:25,369 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:25,370 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:14:25,381 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:25,381 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:14:25,383 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:25,383 - INFO - Retrying request to /openai/v1/chat/completions in 23.000000 seconds
2025-04-21 15:14:25,387 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:25,388 - INFO - Retrying request to /openai/v1/chat/completions in 24.000000 seconds
2025-04-21 15:14:25,394 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:25,394 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:14:25,417 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:25,418 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:14:25,478 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:25,479 - INFO - Retrying request to /openai/v1/chat/completions in 25.000000 seconds
2025-04-21 15:14:25,744 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:14:25,746 - ERROR - [test_069][extraccion_citas][gemma2-9b-it] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n  "resultados": [\n    {\n      "cita": "cuidar los negocios",\n      "emisor_nombre": "Javier Milei",\n      "contexto": "Describiendo la motivaci√≥n de Macri y Milei para desdoblar las elecciones porte√±as",\n      "fecha_cita": null,\n      "relevancia_cita": 4\n    },\n    {\n      "cita": "traici√≥n por la espalda",\n      "emisor_nombre": "Javier Milei",\n      "contexto": "Describiendo la contrataci√≥n del publicista de Sergio Masa por el alcalde porte√±o y el ex presidente",\n      "fecha_cita": null,\n      "relevancia_cita": 3\n    },\n    {\n      "cita": "Est√°n demonizando a mi hermana de una manera injusta ¬øYo desdobl√© las elecciones? No, lo hizo Jorge Macri. Si vamos divididos es por su culpa",\n      "emisor_nombre": "Javier Milei",\n      "contexto": "Cuestionando a Jorge Macri por la divisi√≥n en el PRO y la demonizaci√≥n de su hermana",\n      "fecha_cita": null,\n      "relevancia_cita": 5\n    },\n    {\n      "cita": "El cepo se puso durante el final del gobierno de Macri con Hern√°n Lacunza, generando un monstruo cambiario que adem√°s defaulte√≥ la deuda en pesos. Bajo el artilugio del reperfilamiento, Lacunza y Macri defaultearon deuda en pesos, algo in√©dito‚Äú,\\n      "emisor_nombre": "Javier Milei",\\n      "contexto": "Criticando la gesti√≥n econ√≥mica de Macri y Lacunza",\\n      "fecha_cita": null,\\n      "relevancia_cita": 4\\n    },\\n    {\\n      "cita": "Por el tema de la Ciudad se gener√≥ mucho problema y est√°n demonizando a mi hermana de una manera absolutamente injusta. Yo dije vamos juntos en todos lados. ¬øY yo desdobl√© las elecciones en la Ciudad?",\\n      "emisor_nombre": "Javier Milei",\\n      "contexto": "Cuestionando a Jorge Macri por la divisi√≥n en el PRO y la demonizaci√≥n de su hermana",\\n      "fecha_cita": null,\\n      "relevancia_cita": 3\\n    },\\n    {\\n      "cita": "¬øA usted le parece que por eso nosotros podemos avalar una suba de impuestos (en la Ciudad)? ¬øO que nosotros proponemos una agenda de reformas parecidas a las que estamos haciendo en Naci√≥n y las voltean? No hay voluntad de cambio en la Ciudad",\\n      "emisor_nombre": "Javier Milei",\\n      "contexto": "Criticando la gesti√≥n del Ejecutivo porte√±o",\\n      "fecha_cita": null,\\n      "relevancia_cita": 3\\n    },\\n    {\\n      "cita": "Pon√≠an cuatro legisladores y nosotros uno. Si a ustedes le hacen esa propuesta parece una cargada, porque hoy La Libertad Avanza es mucho m√°s poderosa que el PRO",\\n      "emisor_nombre": "Javier Milei",\\n      "contexto": "Criticando la propuesta de listas del PRO",\\n      "fecha_cita": null,\\n      "relevancia_cita": 2\\n    },\\n    {\\n      "cita": "Que explique por qu√© quiso subir los impuestos, por qu√© quiere sostener ese Estado elefanti√°sico, por qu√© la Ciudad es una mugre... Se lo dice el propio Larreta. Mire qu√© bajo han ca√≠do que hasta Larreta hace eso. Ac√° el que decidi√≥ desdoblar y violentar la posibilidad de un acuerdo para defender el reducto fue Jorge Macri",\\n      "emisor_nombre": "Javier Milei",\\n      "contexto": "Criticando a Jorge Macri por su gesti√≥n",\\n      "fecha_cita": null,\\n      "relevancia_cita": 4\\n    },\\n    {\\n      "cita": "la vuelta del kirchnerismo no va a pasar",\\n      "emisor_nombre": "Javier Milei",\\n      "contexto": "Describiendo la estrategia electoral del PRO y LLA",\\n      "fecha_cita": null,\\n      "relevancia_cita": 3\\n    },\\n    {\\n      "cita": "¬øUsted no vio la √∫ltima foto de mi hermana, Ritondo, Santilli, Lule (Menem), (Sebasti√°n) Pareja...? ¬øEso no muestra que tenemos una voluntad de ir a ganar la Provincia todos juntos? ¬øUsted cree que la gente se sienta en esa foto de manera inocua? Estamos para ir y ganarles a los kukas en la provincia de Buenos Aires. Nuestra intenci√≥n es ganarles y sacarles el basti√≥n kirchnerista por antonomasia",\\n      "emisor_nombre": "Javier Milei",\\n      "contexto": "Describiendo la estrategia electoral del PRO y LLA",\\n      "fecha_cita": null,\\n      "relevancia_cita": 4\\n    },\\n    {\\n      "cita": "Quiero felicitar a LLA en Santa Fe, ya que ganamos en Rosario. Es una estructura que tiene cinco meses y se gan√≥ esa a ciudad, No es un tema menor",\\n      "emisor_nombre": "Javier Milei",\\n      "contexto": "Celebrando el triunfo de LLA en Rosario",\\n      "fecha_cita": null,\\n      "relevancia_cita": 2\\n    },\\n    {\\n      "cita": "Esta desesperado. Con una baja participaci√≥n, vot√≥ a Pullaro s√≥lo un 15% del electorado en verdad",\\n      "emisor_nombre": "Colaborador de la Secretaria general",\\n      "contexto": "Criticando la gesti√≥n de Maxi Pullaro",\\n      "fecha_cita": null,\\n      "relevancia_cita": 2\\n    },\\n    {\\n      "cita": "Contrataron para una campa√±a negativa contra m√≠ a Guti√©rrez-Rub√≠, el mismo que contrat√≥ Massa. ¬øNo le parece un acto de deslealtad? A m√≠ me parece una traici√≥n por la espalda si empieza a repetir las cosas que hizo con Massa",\\n      "emisor_nombre": "Javier Milei",\\n      "contexto": "Criticando la contrataci√≥n de Antoni Guti√©rrez-Rub√≠ por el alcalde porte√±o",\\n      "fecha_cita": null,\\n      "relevancia_cita": 3\\n    }\\n  ]\\n}'}}

[test_069] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:07<00:02,  1.97it/s][A2025-04-21 15:14:25,798 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_033] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:15,  1.51it/s][A[A2025-04-21 15:14:25,945 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_033] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:08,  2.78it/s][A[A2025-04-21 15:14:26,076 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_051] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:03<00:03,  3.30it/s][A[A[A[A2025-04-21 15:14:26,133 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:26,147 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_033] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:01<00:06,  3.47it/s][A[A2025-04-21 15:14:26,238 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_051] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:03<00:02,  4.57it/s][A[A[A[A2025-04-21 15:14:26,247 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:26,314 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_033] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:03,  5.81it/s][A[A2025-04-21 15:14:26,345 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:26,348 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_050] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:12<00:00,  1.33s/it][A[A[A[A[A




                                                                         [A[A[A[A[A2025-04-21 15:14:26,363 - INFO - --- Art√≠culo test_050 completado ---
2025-04-21 15:14:26,363 - INFO - --- Procesando Art√≠culo: test_015 ---
2025-04-21 15:14:26,364 - INFO - [test_015] Lanzando 25 llamadas a Groq...





[test_015] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[A[AProgreso General Art√≠culos:  17%|‚ñà‚ñã        | 12/72 [01:06<03:13,  3.23s/it]2025-04-21 15:14:26,422 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:14:26,423 - ERROR - [test_033][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Bueno, hablamos de que hay un vac√≠o en la ley, y nosotros tenemos que llenar ese vac√≠o para evitar que una tragedia as√≠ vuelva a suceder. Vamos a trabajar arduamente en ese sentido"",\n         "emisor_nombre": "Abinader",\n         "contexto": "Respuesta del presidente sobre qu√© podr√≠a hacer el Estado para mitigar situaciones como la del centro nocturno",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lo que nos ha permitido evitar muchas situaciones en los √∫ltimos a√±os"",\n         "emisor_nombre": "Abinader",\n         "contexto": "Explicaci√≥n del presidente sobre el trabajo de la Oficina Nacional de Evaluaci√≥n S√≠smica y Vulnerabilidad de Infraestructura y Edificaciones (Onesvie)",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""De cualquier manera, nosotros estaremos tomando medidas especiales tambi√©n para, en lo que respecta a ese proyecto de ley que debe ser declarado de emergencia, ir realizando otras gestiones"",\n         "emisor_nombre": "Abinader",\n         "contexto": "Comentarios del presidente sobre el proyecto de ley para supervisar obras privadas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Todo ese detalle... si es a la fiscal√≠a, es al Ministerio P√∫blico. Entonces, el Ministerio P√∫blico tiene que dar ese informe, y debe hacerlo"",\n         "emisor_nombre": "Abinader",\n         "contexto": "Indicaciones del presidente sobre la responsabilidad de presentar los resultados de la investigaci√≥n penal",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Lo que tiene que saberse obligatoriamente es qu√© pas√≥, por qu√© pas√≥ y c√≥mo pas√≥. Eso es lo que la poblaci√≥n y el Gobierno requieren"",\n         "emisor_nombre": "Abinader",\n         "contexto": "Comentarios del presidente sobre el informe t√©cnico que se est√° desarrollando",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}
2025-04-21 15:14:26,424 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_033] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:02,  8.37it/s][A[A



[test_051] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:03<00:01,  4.71it/s][A[A[A[A2025-04-21 15:14:26,448 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:26,517 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:26,518 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:26,526 - INFO - Retrying request to /openai/v1/chat/completions in 21.000000 seconds
2025-04-21 15:14:26,529 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"


[test_033] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:01, 10.71it/s][A[A2025-04-21 15:14:26,530 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:14:26,566 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:26,567 - INFO - Retrying request to /openai/v1/chat/completions in 22.000000 seconds
2025-04-21 15:14:26,612 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:26,613 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:26,614 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:26,614 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:26,615 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:26,617 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:26,617 - INFO - Retrying request to /openai/v1/chat/completions in 22.000000 seconds
2025-04-21 15:14:26,624 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:26,625 - INFO - Retrying request to /openai/v1/chat/completions in 22.000000 seconds
2025-04-21 15:14:26,678 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_033] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:01, 11.53it/s][A[A2025-04-21 15:14:26,695 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:26,696 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:26,735 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:26,736 - INFO - Retrying request to /openai/v1/chat/completions in 19.000000 seconds
2025-04-21 15:14:26,917 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:26,942 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_015] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:13,  1.73it/s][A[A[A[A[A2025-04-21 15:14:26,975 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:27,284 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:14:27,285 - ERROR - [test_015][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""representan el sentir y la esperanza de millones de ecuatorianos y ecuatorianas"",\n         "emisor_nombre": "El Movimiento de Unidad Plurinacional Pachakutik",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""M√°s all√° de los resultados, reconocemos y agradecemos el compromiso de nuestra militancia durante todo este proceso"",\n         "emisor_nombre": "El Movimiento de Unidad Plurinacional Pachakutik",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""seguramos que continuar√°n aportando con propuestas y compromiso para el desarrollo de un Ecuador m√°s justo, plurinacional y solidario"",\n         "emisor_nombre": "El Movimiento de Unidad Plurinacional Pachakutik",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}





[test_015] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:06,  3.62it/s][A[A[A[A[A2025-04-21 15:14:27,289 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:27,380 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:27,381 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:14:27,411 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_033] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:02<00:02,  5.51it/s][A[A2025-04-21 15:14:27,424 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_015] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:03,  5.86it/s][A[A[A[A[A2025-04-21 15:14:27,546 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_069] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:09<00:03,  1.14it/s][A2025-04-21 15:14:27,712 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_015] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:03,  4.95it/s][A[A[A[A[A2025-04-21 15:14:27,728 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:27,761 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_033] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:02<00:01,  5.58it/s][A[A2025-04-21 15:14:27,770 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:27,846 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_015] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  6.97it/s][A[A[A[A[A2025-04-21 15:14:28,029 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_015] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:02,  6.55it/s][A[A[A[A[A2025-04-21 15:14:28,196 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_015] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:02,  6.40it/s][A[A[A[A[A2025-04-21 15:14:28,249 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_033] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:03<00:02,  4.21it/s][A[A2025-04-21 15:14:28,410 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:28,411 - INFO - Retrying request to /openai/v1/chat/completions in 18.000000 seconds
2025-04-21 15:14:28,512 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:28,513 - INFO - Retrying request to /openai/v1/chat/completions in 18.000000 seconds
2025-04-21 15:14:28,625 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_015] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:02<00:03,  4.37it/s][A[A[A[A[A2025-04-21 15:14:28,676 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:29,279 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_051] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:06<00:06,  1.21it/s][A[A[A[A2025-04-21 15:14:29,515 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_015] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:03<00:03,  3.11it/s][A[A[A[A[A2025-04-21 15:14:29,595 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:29,730 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_015] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:03<00:02,  4.16it/s][A[A[A[A[A2025-04-21 15:14:29,825 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:29,826 - INFO - Retrying request to /openai/v1/chat/completions in 16.000000 seconds
2025-04-21 15:14:29,831 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:29,832 - INFO - Retrying request to /openai/v1/chat/completions in 16.000000 seconds
2025-04-21 15:14:29,930 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_051] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:06<00:05,  1.28it/s][A[A[A[A2025-04-21 15:14:29,957 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_015] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:03<00:02,  4.20it/s][A[A[A[A[A2025-04-21 15:14:30,019 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_033] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:04<00:04,  1.78it/s][A[A2025-04-21 15:14:30,389 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:30,390 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:14:30,482 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:30,483 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:14:30,603 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:30,604 - INFO - Retrying request to /openai/v1/chat/completions in 16.000000 seconds
2025-04-21 15:14:30,623 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:30,624 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:14:30,656 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_015] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:04<00:02,  2.90it/s][A[A[A[A[A2025-04-21 15:14:30,699 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:31,485 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:31,486 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:14:32,205 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_051] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:09<00:07,  1.18s/it][A[A[A[A2025-04-21 15:14:32,570 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:32,571 - ERROR - [test_033][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29698, Requested 1222. Please try again in 1.84s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_033] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:07<00:07,  1.03s/it][A[A2025-04-21 15:14:32,610 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:32,611 - ERROR - [test_033][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 35479, Requested 1370. Please try again in 13.699s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:14:32,836 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:32,837 - ERROR - [test_015][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 35361, Requested 1185. Please try again in 13.093s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_015] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:06<00:03,  1.55it/s][A[A[A[A[A2025-04-21 15:14:33,019 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_051] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:09<00:05,  1.08s/it][A[A[A[A2025-04-21 15:14:34,367 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_051] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:11<00:04,  1.15s/it][A[A[A[A2025-04-21 15:14:34,947 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:34,948 - ERROR - [test_014][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31715, Requested 1140. Please try again in 5.71s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_014] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:18<00:00,  2.96s/it][A[A[A


                                                                         [A[A[A2025-04-21 15:14:34,964 - INFO - --- Art√≠culo test_014 completado ---
2025-04-21 15:14:34,964 - INFO - --- Procesando Art√≠culo: test_070 ---
2025-04-21 15:14:34,965 - INFO - [test_070] Lanzando 25 llamadas a Groq...



[test_070] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[AProgreso General Art√≠culos:  18%|‚ñà‚ñä        | 13/72 [01:15<04:46,  4.86s/it]2025-04-21 15:14:35,129 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:35,130 - INFO - Retrying request to /openai/v1/chat/completions in 16.000000 seconds
2025-04-21 15:14:35,137 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:35,138 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:14:35,214 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:35,215 - INFO - Retrying request to /openai/v1/chat/completions in 15.000000 seconds
2025-04-21 15:14:35,222 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:35,223 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:14:35,227 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:35,227 - INFO - Retrying request to /openai/v1/chat/completions in 14.000000 seconds
2025-04-21 15:14:35,256 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:35,257 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:14:35,267 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:35,268 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:14:35,366 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:35,366 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:14:35,579 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_070] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:14,  1.63it/s][A[A[A2025-04-21 15:14:35,629 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:35,630 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:14:35,700 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:35,701 - ERROR - [test_033][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 33930, Requested 1587. Please try again in 11.035s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_033] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:10<00:06,  1.24s/it][A[A2025-04-21 15:14:35,733 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_070] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:07,  2.91it/s][A[A[A2025-04-21 15:14:35,868 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_070] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:05,  4.03it/s][A[A[A2025-04-21 15:14:35,992 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_070] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:04,  5.01it/s][A[A[A2025-04-21 15:14:36,291 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:14:36,292 - ERROR - [test_070][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""esta forma de elecci√≥n que se aplica desde 2020 es inconstitucional"",\n         "emisor_nombre": "Eugenio Mart√≠nez",\n         "contexto": "Comentario sobre la forma de elecci√≥n en Venezuela",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Nosotros debemos seguir buscando que en Venezuela se respete el voto democr√°tico. Yo esto lo veo como un desaf√≠o gigantesco contracorriente"",\n         "emisor_nombre": "Henrique Capriles Radonski",\n         "contexto": "Comentario sobre la situaci√≥n pol√≠tica en Venezuela",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lo m√°s f√°cil ser√≠a no hacer nada"",\n         "emisor_nombre": "Henrique Capriles Radonski",\n         "contexto": "Comentario sobre su decisi√≥n de participar en los comicios",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Evitar a toda costa que este pa√≠s entre en la resignaci√≥n y en la desesperanza, que eso lo que trae es que haya m√°s venezolanos fuera del pa√≠s, no hay que tirar la toalla"",\n         "emisor_nombre": "Henrique Capriles Radonski",\n         "contexto": "Comentario sobre la situaci√≥n pol√≠tica en Venezuela",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""esta forma de elecci√≥n que se aplica desde 2020 es inconstitucional"",\n         "emisor_nombre": "Eugenio Mart√≠nez",\n         "contexto": "Comentario sobre la forma de elecci√≥n en Venezuela",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""En febrero el propio ministro de Interior del gobierno de Maduro, Diosdado Cabello, aseguraba que no podr√≠a ejercer funciones pol√≠ticas hasta 2032"",\n         "emisor_nombre": "Diosdado Cabello",\n         "contexto": "Comentario sobre su situaci√≥n pol√≠tica",\n         "fecha_cita": "febrero",\n         "relevancia_cita": 4\n      }\n   ]\n}'}}



[test_070] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:04,  4.25it/s][A[A[A2025-04-21 15:14:36,314 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:36,315 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:14:36,336 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:36,359 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:36,360 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:14:36,381 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:36,382 - INFO - Retrying request to /openai/v1/chat/completions in 11.000000 seconds
2025-04-21 15:14:36,423 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_070] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:02,  6.69it/s][A[A[A2025-04-21 15:14:37,055 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:37,056 - ERROR - [test_069][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30658, Requested 1993. Please try again in 5.303s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_069] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:18<00:10,  3.40s/it][A2025-04-21 15:14:37,216 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_070] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:02<00:05,  3.12it/s][A[A[A2025-04-21 15:14:37,295 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:37,904 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_070] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:02<00:04,  3.02it/s][A[A[A2025-04-21 15:14:38,030 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_070] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:03<00:03,  3.54it/s][A[A[A2025-04-21 15:14:38,078 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:38,268 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_070] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:03<00:02,  4.61it/s][A[A[A2025-04-21 15:14:38,564 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:38,565 - ERROR - [test_070][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32498, Requested 1947. Please try again in 8.89s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_070] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:03<00:02,  4.27it/s][A[A[A2025-04-21 15:14:38,645 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:39,231 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_070] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:04<00:02,  3.66it/s][A[A[A2025-04-21 15:14:40,524 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:40,526 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:14:40,877 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_070] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:05<00:04,  1.75it/s][A[A[A2025-04-21 15:14:40,940 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:14:40,944 - ERROR - [test_070][extraccion_entidades][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "nombre": "Henrique Capriles Radonski",\n         "tipo": "PERSONA",\n         "alias": ["Henrique Capriles", "Capriles"],\n         "descripcion_contextual": "L√≠der del partido Un Nuevo Tiempo (UNT)",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Tom√°s Guanipa",\n         "tipo": "PERSONA",\n         "alias": ["Tom√°s Guanipa Villalobos"],\n         "descripcion_contextual": "L√≠der del partido Un Nuevo Tiempo (UNT)",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Un Nuevo Tiempo (UNT)",\n         "tipo": "ORGANIZACION",\n         "alias": ["UNT", "Un Nuevo Tiempo"],\n         "descripcion_contextual": "Partido pol√≠tico venezolano",\n         "relevancia_articulo": 9\n      },\n      {\n         "nombre": "Eugenio Mart√≠nez",\n         "tipo": "PERSONA",\n         "alias": ["Eugenio G. Mart√≠nez"],\n         "descripcion_contextual": "Experto en temas electorales",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Elecciones parlamentarias y regionales de Venezuela de 2023",\n         "tipo": "EVENTO",\n         "alias": ["Elecciones de 2023"],\n         "descripcion_contextual": "Elecciones en Venezuela",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Venezuela",\n         "tipo": "LUGAR",\n         "alias": ["Rep√∫blica Bolivariana de Venezuela"],\n         "descripcion_contextual": "Pa√≠s sudamericano",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Maduro",\n         "tipo": "PERSONA",\n         "alias": ["Nicol√°s Maduro"],\n         "descripcion_contextual": "Presidente de Venezuela",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Diosdado Cabello",\n         "tipo": "PERSONA",\n         "alias": ["Diosdado Cabello Rond√≥n"],\n         "descripcion_contextual": "Ministro de Interior de Venezuela",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Juan Requesens",\n         "tipo": "PERSONA",\n         "alias": ["Juan Requesens"],\n         "descripcion_contextual": "Candidato a la gobernaci√≥n de Miranda",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Miranda",\n         "tipo": "LUGAR",\n         "alias": ["Estado Miranda"],\n         "descripcion_contextual": "Estado venezolano",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Ley Org√°nica 3/2018",\n         "tipo": "NORMATIVA",\n         "alias": ["Ley Org√°nica 3/2018"],\n         "descripcion_contextual": "Ley venezolana",\n         "relevancia_articulo": 2\n      },\n      {\n         "nombre": "Elecciones Generales Espa√±a 2023",\n         "tipo": "EVENTO",\n         "alias": ["Elecciones de Espa√±a 2023"],\n         "descripcion_contextual": "Elecciones en Espa√±a",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Pedro S√°nchez P√©rez-Castej√≥n",\n         "tipo": "PERSONA",\n         "alias": ["Pedro S√°nchez"],\n         "descripcion_contextual": "L√≠der del PSOE",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Organizaci√≥n de las Naciones Unidas (ONU)",\n         "tipo": "ORGANIZACION",\n         "alias": ["ONU"],\n         "descripcion_contextual": "Organizaci√≥n internacional",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Ley Org√°nica 3/2018",\n         "tipo": "NORMATIVA",\n         "alias": ["Ley Org√°nica 3/2018"],\n         "descripcion_contextual": "Ley venezolana",\n         "relevancia_articulo": 2\n      },\n      {\n         "nombre": "Elecciones Generales Espa√±a 2023",\n         "tipo": "EVENTO",\n         "alias": ["Elecciones de Espa√±a 2023"],\n         "descripcion_contextual": "Elecciones en Espa√±a",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Pedro S√°nchez P√©rez-Castej√≥n",\n         "tipo": "PERSONA",\n         "alias": ["Pedro S√°nchez"],\n         "descripcion_contextual": "L√≠der del PSOE",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Organizaci√≥n de las Naciones Unidas (ONU)",\n         "tipo": "ORGANIZACION",\n         "alias": ["ONU"],\n         "descripcion_contextual": "Organizaci√≥n internacional",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Ley Org√°nica 3/2018",\n         "tipo": "NORMATIVA",\n         "alias": ["Ley Org√°nica 3/2018"],\n         "descripcion_contextual": "Ley venezolana",\n         "relevancia_articulo": 2\n      },\n      {\n         "nombre": "Elecciones Generales Espa√±a 2023",\n         "tipo": "EVENTO",\n         "alias": ["Elecciones de Espa√±a 2023"],\n         "descripcion_contextual": "Elecciones en Espa√±a",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Pedro S√°nchez P√©rez-Castej√≥n",\n         "tipo": "PERSONA",\n         "alias": ["Pedro S√°nchez"],\n         "descripcion_contextual": "L√≠der del PSOE",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Organizaci√≥n de las Naciones Unidas (ONU)",\n         "tipo": "ORGANIZACION",\n         "alias": ["ONU"],\n         "descripcion_contextual": "Organizaci√≥n internacional",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Ley Org√°nica 3/2018",\n         "tipo": "NORMATIVA",\n         "alias": ["Ley Org√°nica 3/2018"],\n         "descripcion_contextual": "Ley venezolana",\n         "relevancia_articulo": 2\n      },\n      {\n         "nombre": "Elecciones Generales Espa√±a 2023",\n         "tipo": "EVENTO",\n         "alias": ["Elecciones de Espa√±a 2023"],\n         "descripcion_contextual": "Elecciones en Espa√±a",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Pedro S√°nchez P√©rez-Castej√≥n",\n         "tipo": "PERSONA",\n         "alias": ["Pedro S√°nchez"],\n         "descripcion_contextual": "L√≠der del PSOE",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Organizaci√≥n de las Naciones Unidas (ONU)",\n         "tipo": "ORGANIZACION",\n         "alias": ["ONU"],\n         "descripcion_contextual": "Organizaci√≥n internacional",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Ley Org√°nica 3/2018",\n         "tipo": "NORMATIVA",\n         "alias": ["Ley Org√°nica 3/2018"],\n         "descripcion_contextual": "Ley venezolana",\n         "relevancia_articulo": 2\n      },\n      {\n         "nombre": "Elecciones Generales Espa√±a 2023",\n         "tipo": "EVENTO",\n         "alias": ["Elecciones de Espa√±a 2023"],\n         "descripcion_contextual": "Elecciones en Espa√±a",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Pedro S√°nchez P√©rez-Castej√≥n",\n         "tipo": "PERSONA",\n         "alias": ["Pedro S√°nchez"],\n         "descripcion_contextual": "L√≠der del PSOE",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Organizaci√≥n de las Naciones Unidas (ONU)",\n         "tipo": "ORGANIZACION",\n         "alias": ["ONU"],\n         "descripcion_contextual": "Organizaci√≥n internacional",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Ley Org√°nica 3/2018",\n         "tipo": "NORMATIVA",\n         "alias": ["Ley Org√°nica 3/2018"],\n         "descripcion_contextual": "Ley venezolana",\n         "relevancia_articulo": 2\n      },\n      {\n         "nombre": "Elecciones Generales Espa√±a 2023",\n         "tipo": "EVENTO",\n         "alias": ["Elecciones de Espa√±a 2023"],\n         "descripcion_contextual": "Elecciones en Espa√±a",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Pedro S√°nchez P√©rez-Castej√≥n",\n         "tipo": "PERSONA",\n         "alias": ["Pedro S√°nchez"],\n         "descripcion_contextual": "L√≠der del PSOE",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Organizaci√≥n de las Naciones Unidas (ONU)",\n         "tipo": "ORGANIZACION",\n         "alias": ["ONU"],\n         "descripcion_contextual": "Organizaci√≥n internacional",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Ley Org√°nica 3/2018",\n         "tipo": "NORMATIVA",\n         "alias": ["Ley Org√°nica 3/2018"],\n         "descripcion_contextual": "Ley venezolana",\n         "relevancia_articulo": 2\n      },\n      {\n         "nombre": "Elecciones Generales Espa√±a 2023",\n         "tipo": "EVENTO",\n         "alias": ["Elecciones de Espa√±a 2023"],\n         "descripcion_contextual": "Elecciones en Espa√±a",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Pedro S√°nchez P√©rez-Castej√≥n",\n         "tipo": "PERSONA",\n         "alias": ["Pedro S√°nchez"],\n         "descripcion_contextual": "L√≠der del PSOE",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Organizaci√≥n de las Naciones Unidas (ONU)",\n         "tipo": "ORGANIZACION",\n         "alias": ["ONU"],\n         "descripcion_contextual": "Organizaci√≥n internacional",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Ley Org√°nica 3/2018",\n         "tipo": "NORMATIVA",\n         "alias": ["Ley Org√°nica 3/2018"],\n         "descripcion_contextual": "Ley venezolana",\n         "relevancia_articulo": 2\n      },\n      {\n         "nombre": "Elecciones Generales Espa√±a 2023",\n         "tipo": "EVENTO",\n         "alias": ["Elecciones de Espa√±a 2023"],\n         "descripcion_contextual": "Elecciones en Espa√±a",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Pedro S√°nchez P√©rez-Castej√≥n",\n         "tipo": "PERSONA",\n         "alias": ["Pedro S√°nchez"],\n         "descripcion_contextual": "L√≠der del PSOE",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Organizaci√≥n de las Naciones Unidas (ONU)",\n         "tipo": "ORGANIZACION",\n         "alias": ["ONU"],\n         "descripcion_contextual": "Organizaci√≥n internacional",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Ley Org√°nica 3/2018",\n         "tipo": "NORMATIVA",\n         "alias": ["Ley Org√°nica 3/2018"],\n         "descripcion_contextual": "Ley venezolana",\n         "relevancia_articulo": 2\n      },\n      {\n         "nombre": "Elecciones Generales Espa√±a 2023",\n         "tipo": "EVENTO",\n         "alias": ["Elecciones de Espa√±a 2023"],\n         "descripcion_contextual": "Elecciones en Espa√±a",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Pedro S√°nchez P√©rez-Castej√≥n",\n         "tipo": "PERSONA",\n         "alias": ["Pedro S√°nchez"],\n         "descripcion_contextual": "L√≠der del PSOE",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Organizaci√≥n de las Naciones Unidas (ONU)",\n         "tipo": "ORGANIZACION",\n         "alias": ["ONU"],\n         "descripcion_contextual": "Organizaci√≥n internacional",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Ley Org√°nica 3/2018",\n         "tipo": "NORMATIVA",\n         "alias": ["Ley Org√°nica 3/2018"],\n         "descripcion_contextual": "Ley venezolana",\n         "relevancia_articulo": 2\n      },\n      {\n         "nombre": "Elecciones Generales Espa√±a 2023",\n         "tipo": "EVENTO",\n         "alias": ["Elecciones de Espa√±a 2023"],\n         "descripcion_contextual": "Elecciones en Espa√±a",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Pedro S√°nchez P√©rez-Castej√≥n",\n         "tipo": "PERSONA",\n         "alias": ["Pedro S√°nchez"],\n         "descripcion_contextual": "L√≠der del PSOE",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Organizaci√≥n de las Naciones Unidas (ONU)",\n         "tipo": "ORGANIZACION",\n         "alias": ["ONU"],\n         "descripcion_contextual": "Organizaci√≥n internacional",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Ley Org√°nica 3/2018",\n         "tipo": "NORMATIVA",\n         "alias": ["Ley Org√°nica 3/2018"],\n         "descripcion_contextual": "Ley venezolana",\n         "relevancia_articulo": 2\n      },\n      {\n         "nombre": "Elecciones Generales Espa√±a 2023",\n         "tipo": "EVENTO",\n         "alias": ["Elecciones de Espa√±a 2023"],\n         "descripcion_contextual": "Elecciones en Espa√±a",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Pedro S√°nchez P√©rez-Castej√≥n",\n         "tipo": "PERSONA",\n         "alias": ["Pedro S√°nchez"],\n         "descripcion_contextual": "L√≠der del PSOE",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Organizaci√≥n de las Naciones Unidas (ONU)",\n         "tipo": "ORGANIZACION",\n         "alias": ["ONU"],\n         "descripcion_contextual": "Organizaci√≥n internacional",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Ley Org√°nica 3/2018",\n         "tipo": "NORMATIVA",\n         "alias": ["Ley Org√°nica 3/2018"],\n         "descripcion_contextual": "Ley venezolana",\n         "relevancia_articulo": 2\n      },\n      {\n         "nombre": "Elecciones Generales Espa√±a 2023",\n         "tipo": "EVENTO",\n         "alias": ["Elecciones de Espa√±a 2023"],\n         "descripcion_contextual": "Elecciones en Espa√±a",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Pedro S√°nchez P√©rez-Castej√≥n",\n         "tipo": "PERSONA",\n         "alias": ["Pedro S√°nchez"],\n         "descripcion_contextual": "L√≠der del PSOE",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Organizaci√≥n de las Naciones Unidas (ONU)",\n         "tipo": "ORGANIZACION",\n         "alias": ["ONU"],\n         "descripcion_contextual": "Organizaci√≥n internacional",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Ley Org√°nica 3/2018",\n         "tipo": "NORMATIVA",\n         "alias": ["Ley Org√°nica 3/2018"],\n         "descripcion_contextual": "Ley venezolana",\n         "relevancia_articulo": 2\n      },\n      {\n         "nombre": "Elecciones Generales Espa√±a 2023",\n         "tipo": "EVENTO",\n         "alias": ["Elecciones de Espa√±a 2023"],\n         "descripcion_contextual": "Elecciones en Espa√±a",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Pedro S√°nchez P√©rez-Castej√≥n",\n         "tipo": "PERSONA",\n         "alias": ["Pedro S√°nchez"],\n         "descripcion_contextual": "L√≠der del PSOE",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Organizaci√≥n de las Naciones Unidas (ONU)",\n         "tipo": "ORGANIZACION",\n         "alias": ["ONU"],\n         "descripcion_contextual": "Organizaci√≥n internacional",\n         "relevancia_articulo": 1\n      },\n      {\n         "nombre": "Ley Org√°nica 3/2018",\n         "tipo": "NORMATIVA",\n         "alias": ["Ley Org√°nica 3/2018"],\n         "descripcion_contextual": "Ley venezolana",\n         "relevancia_articulo": 2\n      },\n      {\n         "nombre": "Elecciones Generales Espa√±a 2023",\n         "tipo": "EVENTO",\n         "alias": ["Elecciones de Espa√±a 2023"],\n         "descripcion_contextual": "Elecciones en Espa√±a",\n         "relevancia_articulo": 1\n      }}'}}
2025-04-21 15:14:41,967 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_051] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:18<00:08,  3.00s/it][A[A[A[A2025-04-21 15:14:41,983 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:41,984 - ERROR - [test_069][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29558, Requested 2254. Please try again in 3.624s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_069] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:23<00:07,  3.85s/it][A2025-04-21 15:14:42,073 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:42,074 - ERROR - [test_069][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29513, Requested 2142. Please try again in 3.309s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:14:42,569 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:42,570 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:42,940 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:42,941 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:14:43,014 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:43,015 - ERROR - [test_069][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29043, Requested 2363. Please try again in 2.811s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_069] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:24<00:00,  2.33s/it][A
                                                                         [A2025-04-21 15:14:43,029 - INFO - --- Art√≠culo test_069 completado ---
2025-04-21 15:14:43,030 - INFO - --- Procesando Art√≠culo: test_052 ---
2025-04-21 15:14:43,030 - INFO - [test_052] Lanzando 25 llamadas a Groq...

[test_052] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][AProgreso General Art√≠culos:  19%|‚ñà‚ñâ        | 14/72 [01:23<05:37,  5.82s/it]2025-04-21 15:14:43,087 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:43,088 - ERROR - [test_070][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30237, Requested 1722. Please try again in 3.918s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_070] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:08<00:04,  1.29it/s][A[A[A2025-04-21 15:14:43,199 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:43,200 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:14:43,271 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:43,272 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:14:43,275 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:43,276 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:14:43,285 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:43,285 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:14:43,297 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:43,298 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:43,355 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:43,356 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:14:43,541 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_052] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:12,  1.95it/s][A2025-04-21 15:14:43,603 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:43,755 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_052] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:04,  4.72it/s][A2025-04-21 15:14:44,237 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_052] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:06,  3.27it/s][A2025-04-21 15:14:44,244 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:44,361 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_052] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:03,  5.42it/s][A2025-04-21 15:14:44,535 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_052] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:03,  5.50it/s][A2025-04-21 15:14:44,686 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_052] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  5.77it/s][A2025-04-21 15:14:44,896 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_052] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:02,  5.45it/s][A2025-04-21 15:14:44,967 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:44,976 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:45,048 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_052] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:01,  8.98it/s][A2025-04-21 15:14:45,058 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:45,059 - ERROR - [test_070][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30638, Requested 1573. Please try again in 4.422s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_070] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:10<00:05,  1.03s/it][A[A[A2025-04-21 15:14:45,122 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:45,248 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_052] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:02<00:01,  9.33it/s][A2025-04-21 15:14:45,404 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:45,516 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_052] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:01,  8.62it/s][A2025-04-21 15:14:45,683 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:45,684 - ERROR - [test_070][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30329, Requested 1834. Please try again in 4.327s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_070] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:10<00:03,  1.07it/s][A[A[A2025-04-21 15:14:45,742 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:45,743 - ERROR - [test_033][relevancia][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31562, Requested 1002. Please try again in 5.129s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_033] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:20<00:12,  3.19s/it][A[A2025-04-21 15:14:45,865 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:45,866 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:14:45,927 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:45,928 - ERROR - [test_015][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31462, Requested 1072. Please try again in 5.068s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_015] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:19<00:17,  3.41s/it][A[A[A[A[A2025-04-21 15:14:45,935 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:45,937 - ERROR - [test_015][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31458, Requested 960. Please try again in 4.836s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:14:46,418 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:46,419 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:14:46,523 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:46,524 - ERROR - [test_051][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31164, Requested 1137. Please try again in 4.603s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_051] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:23<00:06,  3.45s/it][A[A[A[A2025-04-21 15:14:46,701 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:46,702 - ERROR - [test_033][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31076, Requested 1483. Please try again in 5.118s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_033] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:21<00:07,  2.66s/it][A[A2025-04-21 15:14:46,733 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:46,734 - ERROR - [test_051][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31063, Requested 1398. Please try again in 4.922s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_051] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:23<00:02,  2.50s/it][A[A[A[A2025-04-21 15:14:47,031 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_052] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:04<00:03,  2.62it/s][A2025-04-21 15:14:47,331 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_052] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:04<00:02,  2.75it/s][A2025-04-21 15:14:47,531 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_052] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:04<00:01,  3.07it/s][A2025-04-21 15:14:47,631 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:47,633 - ERROR - [test_051][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 34283, Requested 1510. Please try again in 11.586s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_051] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:24<00:00,  2.03s/it][A[A[A[A



                                                                         [A[A[A[A2025-04-21 15:14:47,645 - INFO - --- Art√≠culo test_051 completado ---
2025-04-21 15:14:47,645 - INFO - --- Procesando Art√≠culo: test_034 ---
2025-04-21 15:14:47,648 - INFO - [test_034] Lanzando 25 llamadas a Groq...




[test_034] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[AProgreso General Art√≠culos:  21%|‚ñà‚ñà        | 15/72 [01:27<05:11,  5.47s/it]2025-04-21 15:14:47,830 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:47,830 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:14:47,839 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:47,840 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:47,878 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:47,879 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:47,880 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:47,881 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:14:47,903 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:47,904 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:48,037 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:48,038 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:14:48,055 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:48,056 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:14:48,278 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_034] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:15,  1.58it/s][A[A[A[A2025-04-21 15:14:48,343 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_070] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:13<00:04,  1.37s/it][A[A[A2025-04-21 15:14:48,380 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_034] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:07,  3.13it/s][A[A[A[A2025-04-21 15:14:48,576 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_034] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:05,  3.80it/s][A[A[A[A2025-04-21 15:14:48,608 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:49,000 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:14:49,003 - ERROR - [test_034][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""¬°Yes, Master!‚Äù, asegur√≥ que se ‚Äúconsum√≥‚Äù la acci√≥n, al mismo tiempo que pidi√≥ soltar ‚Äúa los perro‚Äù y etiquet√≥ al Organismo Judicial.",\n         "emisor_nombre": "¬°Yes, Master!",\n         "contexto": "Anuncio de una acci√≥n en contra de la designaci√≥n de Werner Florencio Ovalle Ram√≠rez como titular de la Superintendencia de Administraci√≥n Tributaria (SAT).",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Consumado es ‚Äîrepito, consumado es. Abogado MAYNOR GIOVANNY CAT√â CHIRIX interpone amparo en contra del directorio de la @SATGT. Sueltan a los perros. @OJGuatemala https://t.co/PLMLwfTTys pic.twitter.com/vXM2Qqv60L"",\n         "emisor_nombre": "¬°Yes, Master!",\n         "contexto": "Anuncio de una acci√≥n en contra de la designaci√≥n de Werner Florencio Ovalle Ram√≠rez como titular de la Superintendencia de Administraci√≥n Tributaria (SAT).",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""ES JURAMENTADO"",\n         "emisor_nombre": null,\n         "contexto": "Comunicado oficial sobre la juramentaci√≥n del nuevo Superintendente de la SAT.",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""La Corte tiene conocimiento de un instrumento, y de hecho resuelve con base a un instrumento que se denomina Constituci√≥n Pol√≠tica de la Rep√∫blica de Guatemala‚Äù"",\n         "emisor_nombre": "Leyla Susana Lemus Arriaga",\n         "contexto": "Respuesta de la presidenta de la Corte de Constitucionalidad a preguntas de medios de comunicaci√≥n.",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""C√≥mo hacer que la clase pol√≠tica y que las instituciones que tienen entre sus funciones el ejercicio de poder, no lleguen a este tipo de tensiones, que eventualmente tiene que resolver la Corte, yo creo que esa ya es una pregunta que excede a lo que nosotros nos toca‚Äù"",\n         "emisor_nombre": "Leyla Susana Lemus Arriaga",\n         "contexto": "Respuesta de la presidenta de la Corte de Constitucionalidad a preguntas de medios de comunicaci√≥n.",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}




[test_034] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:04,  4.26it/s][A[A[A[A2025-04-21 15:14:49,005 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_033] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:23<00:05,  2.57s/it][A[A2025-04-21 15:14:49,033 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:49,034 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:14:49,247 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_034] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:04,  4.21it/s][A[A[A[A2025-04-21 15:14:49,249 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:49,250 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:14:49,264 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:49,267 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:49,306 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:49,417 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:49,418 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:14:49,438 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_034] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01,  8.36it/s][A[A[A[A2025-04-21 15:14:49,482 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:49,483 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:14:49,488 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:49,498 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_015] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:23<00:08,  2.78s/it][A[A[A[A[A2025-04-21 15:14:49,646 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_015] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:23<00:04,  2.21s/it][A[A[A[A[A2025-04-21 15:14:49,695 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:49,748 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_052] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:06<00:03,  1.25it/s][A2025-04-21 15:14:49,913 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_034] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:02,  6.41it/s][A[A[A[A2025-04-21 15:14:50,056 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_052] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:07<00:02,  1.49it/s][A2025-04-21 15:14:50,124 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_034] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:02<00:01,  6.03it/s][A[A[A[A2025-04-21 15:14:50,306 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:50,307 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:14:50,320 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:50,321 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:14:50,585 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:50,586 - ERROR - [test_052][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32004, Requested 1061. Please try again in 6.131s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_052] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:07<00:01,  1.59it/s][A2025-04-21 15:14:50,626 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:50,627 - ERROR - [test_070][relevancia][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29684, Requested 1020. Please try again in 1.407s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_070] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:15<00:03,  1.61s/it][A[A[A2025-04-21 15:14:50,702 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:50,703 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:14:50,734 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:50,735 - ERROR - [test_034][relevancia][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29629, Requested 1018. Please try again in 1.294s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_034] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:03<00:02,  3.90it/s][A[A[A[A2025-04-21 15:14:50,795 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:50,815 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_052] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:07<00:01,  1.93it/s][A2025-04-21 15:14:50,994 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:50,995 - INFO - Retrying request to /openai/v1/chat/completions in 12.000000 seconds
2025-04-21 15:14:51,068 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:51,069 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:14:51,080 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_033] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:25<00:02,  2.43s/it][A[A2025-04-21 15:14:51,083 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:51,084 - ERROR - [test_015][relevancia][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 35363, Requested 882. Please try again in 12.49s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_015] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:24<00:00,  1.64s/it][A[A[A[A[A




                                                                         [A[A[A[A[A2025-04-21 15:14:51,096 - INFO - --- Art√≠culo test_015 completado ---
2025-04-21 15:14:51,096 - INFO - --- Procesando Art√≠culo: test_016 ---
2025-04-21 15:14:51,098 - INFO - [test_016] Lanzando 25 llamadas a Groq...





[test_016] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[A[AProgreso General Art√≠culos:  22%|‚ñà‚ñà‚ñè       | 16/72 [01:31<04:31,  4.86s/it]2025-04-21 15:14:51,163 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:51,165 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:51,261 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:51,262 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:14:51,273 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:51,274 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:14:51,298 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:51,299 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:14:51,372 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:51,373 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:14:51,382 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:51,383 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:14:51,390 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:51,391 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:14:51,402 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:51,403 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:51,442 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:51,442 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:14:51,446 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:51,447 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:14:51,456 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:51,457 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:14:51,558 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_034] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:03<00:02,  3.18it/s][A[A[A[A2025-04-21 15:14:51,614 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:51,615 - ERROR - [test_052][relevancia][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32290, Requested 1012. Please try again in 6.604s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_052] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:08<00:00,  1.67it/s][A2025-04-21 15:14:51,684 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_016] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:14,  1.70it/s][A[A[A[A[A2025-04-21 15:14:51,726 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:51,867 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:51,868 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:14:51,967 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:51,968 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_016] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:05,  3.88it/s][A[A[A[A[A



[test_034] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:04<00:02,  2.99it/s][A[A[A[A2025-04-21 15:14:52,017 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:52,033 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:52,135 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_016] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:02,  7.48it/s][A[A[A[A[A2025-04-21 15:14:52,156 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_034] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:04<00:02,  3.33it/s][A[A[A[A2025-04-21 15:14:52,254 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:14:52,255 - ERROR - [test_016][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""En concreto, el art√≠culo menciona que: \'Por otra parte, dentro de la convocatoria hecha para rendir versi√≥n v√≠a Zoom el pasado jueves, 3 de abril, para las procesadas Yadira Saltos y Nicole Bonifaz, solo esta √∫ltima se hizo presente en la versi√≥n libre y voluntaria. Saltos no se habr√≠a conectado\'."",\n         "emisor_nombre": "Yadira Saltos Rivas",\n         "contexto": "Respuesta a una nota period√≠stica que la acusaba de no asistir a una versi√≥n",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "Es decir, me encuentro ejerciendo activamente mi defensa.",\n         "emisor_nombre": "Yadira Saltos Rivas",\n         "contexto": "Explicaci√≥n de su situaci√≥n en la causa",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Es decir, me encuentro ejerciendo activamente mi defensa.",\n         "emisor_nombre": "Yadira Saltos Rivas",\n         "contexto": "Explicaci√≥n de su situaci√≥n en la causa",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "La nota period√≠stica mencionada confunde a la opini√≥n p√∫blica y desinforma, por lo que, amparados en lo que establece la Ley de Comunicaci√≥n, solicito se realice la rectificaci√≥n de la noticia antes mencionada y de esta forma aclarar a la ciudadan√≠a, que se merece informaci√≥n veraz y oportuna.",\n         "emisor_nombre": "Yadira Saltos Rivas",\n         "contexto": "Solicitud de rectificaci√≥n de la nota period√≠stica",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "En efecto, la se√±ora Yadira Saltos s√≠ asisti√≥ a la citada diligencia. Lamentamos la confusi√≥n.",\n         "emisor_nombre": "Redacci√≥n del Diario",\n         "contexto": "Respuesta a la carta de Yadira Saltos Rivas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}
2025-04-21 15:14:52,273 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_034] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:04<00:01,  3.92it/s][A[A[A[A2025-04-21 15:14:52,442 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:52,444 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_016] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  7.07it/s][A[A[A[A[A2025-04-21 15:14:52,468 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:52,469 - INFO - Retrying request to /openai/v1/chat/completions in 12.000000 seconds
2025-04-21 15:14:52,540 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:52,541 - INFO - Retrying request to /openai/v1/chat/completions in 12.000000 seconds
2025-04-21 15:14:52,726 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_016] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:02,  7.07it/s][A[A[A[A[A2025-04-21 15:14:52,771 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:52,830 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_016] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:01<00:01,  8.95it/s][A[A[A[A[A2025-04-21 15:14:53,467 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:53,924 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_016] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:02<00:02,  3.98it/s][A[A[A[A[A2025-04-21 15:14:54,281 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:54,282 - ERROR - [test_034][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 33782, Requested 1893. Please try again in 11.35s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_034] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:06<00:03,  1.40it/s][A[A[A[A2025-04-21 15:14:54,285 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_016] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:03<00:02,  3.68it/s][A[A[A[A[A2025-04-21 15:14:54,413 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:54,415 - ERROR - [test_034][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 33713, Requested 2154. Please try again in 11.734s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_034] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:06<00:02,  1.80it/s][A[A[A[A2025-04-21 15:14:54,612 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:54,613 - ERROR - [test_070][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 33617, Requested 1947. Please try again in 11.129s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_070] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:19<00:02,  2.26s/it][A[A[A2025-04-21 15:14:55,178 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:55,179 - ERROR - [test_034][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 33331, Requested 2042. Please try again in 10.746s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_034] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:07<00:01,  1.63it/s][A[A[A[A2025-04-21 15:14:55,346 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:55,347 - ERROR - [test_034][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30424, Requested 2260. Please try again in 5.369s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_034] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:07<00:00,  2.06it/s][A[A[A[A2025-04-21 15:14:55,396 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_052] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:12<00:00,  1.52s/it][A
                                                                         [A2025-04-21 15:14:55,413 - INFO - --- Art√≠culo test_052 completado ---
2025-04-21 15:14:55,413 - INFO - --- Procesando Art√≠culo: test_071 ---
2025-04-21 15:14:55,414 - INFO - [test_071] Lanzando 25 llamadas a Groq...

[test_071] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][AProgreso General Art√≠culos:  24%|‚ñà‚ñà‚ñé       | 17/72 [01:35<04:18,  4.69s/it]2025-04-21 15:14:55,589 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:55,590 - INFO - Retrying request to /openai/v1/chat/completions in 16.000000 seconds
2025-04-21 15:14:55,603 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:55,604 - INFO - Retrying request to /openai/v1/chat/completions in 17.000000 seconds
2025-04-21 15:14:55,653 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:55,654 - INFO - Retrying request to /openai/v1/chat/completions in 16.000000 seconds
2025-04-21 15:14:55,655 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:55,655 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:14:55,662 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:55,663 - INFO - Retrying request to /openai/v1/chat/completions in 16.000000 seconds
2025-04-21 15:14:55,694 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:55,695 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:14:55,711 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:55,712 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:55,713 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:55,713 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:14:55,776 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:55,776 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:14:55,845 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_016] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:04<00:04,  1.84it/s][A[A[A[A[A2025-04-21 15:14:55,855 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_071] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:10,  2.26it/s][A2025-04-21 15:14:56,168 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_071] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:08,  2.73it/s][A2025-04-21 15:14:56,416 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_071] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:01<00:06,  3.20it/s][A2025-04-21 15:14:56,480 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:14:56,482 - ERROR - [test_071][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""La voz del pueblo es la que manda, por eso quiero decirles que a partir de esta semana van a conocer los dos nombres, del presidente y vicepresidente (con los que participar√° UCS en las elecciones generales). Ma√±ana firmo los acuerdos, que son los √∫ltimos en La Paz. Luego tendremos una asamblea para definir, porque no quiero equivocarme, no podemos hacer locuras, no podemos hacer al primer pitazo de una encuesta; ustedes han visto c√≥mo fracasaron otros"",\n         "emisor_nombre": "Jhonny Fern√°ndez",\n         "contexto": "En un discurso en el Camb√≥dromo, la tarde del lunes",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Nosotros primero escuchamos al pueblo. Nosotros tenemos que ratificar el triunfo en Santa Cruz, porque ello nos llevar√° al triunfo nacional"",\n         "emisor_nombre": "Jhonny Fern√°ndez",\n         "contexto": "En un discurso en el Camb√≥dromo, la tarde del lunes",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}
2025-04-21 15:14:56,670 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_071] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:04,  4.82it/s][A2025-04-21 15:14:56,721 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:56,768 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:56,940 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_071] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  6.99it/s][A2025-04-21 15:14:56,997 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:57,056 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_071] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01,  8.78it/s][A2025-04-21 15:14:57,130 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:57,179 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_071] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:01<00:01, 10.35it/s][A2025-04-21 15:14:57,292 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:57,580 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_071] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:02<00:01,  7.70it/s][A2025-04-21 15:14:57,836 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:58,517 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:58,518 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:14:58,526 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:58,527 - ERROR - [test_070][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 35344, Requested 1722. Please try again in 14.133s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_070] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:23<00:00,  2.73s/it][A[A[A


                                                                         [A[A[A2025-04-21 15:14:58,539 - INFO - --- Art√≠culo test_070 completado ---
2025-04-21 15:14:58,539 - INFO - --- Procesando Art√≠culo: test_053 ---
2025-04-21 15:14:58,540 - INFO - [test_053] Lanzando 25 llamadas a Groq...



[test_053] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[AProgreso General Art√≠culos:  25%|‚ñà‚ñà‚ñå       | 18/72 [01:38<03:48,  4.22s/it]2025-04-21 15:14:58,803 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:58,804 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:14:58,816 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:58,817 - ERROR - [test_033][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 35198, Requested 1587. Please try again in 13.57s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_033] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:33<00:00,  3.90s/it][A[A

                                                                         [A[A2025-04-21 15:14:58,830 - INFO - --- Art√≠culo test_033 completado ---
2025-04-21 15:14:58,831 - INFO - --- Procesando Art√≠culo: test_035 ---
2025-04-21 15:14:58,832 - INFO - [test_035] Lanzando 25 llamadas a Groq...


[test_035] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[AProgreso General Art√≠culos:  26%|‚ñà‚ñà‚ñã       | 19/72 [01:39<02:41,  3.05s/it]2025-04-21 15:14:58,920 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:58,925 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:14:58,932 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:58,934 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:14:58,954 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:58,997 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:14:59,058 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_053] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:12,  1.92it/s][A[A[A2025-04-21 15:14:59,138 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:59,139 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:14:59,152 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:59,153 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:14:59,170 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:59,171 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:14:59,253 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:59,254 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:14:59,283 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:59,284 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:14:59,388 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_071] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:03<00:03,  2.68it/s][A2025-04-21 15:14:59,444 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_053] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:10,  2.27it/s][A[A[A2025-04-21 15:14:59,483 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:59,491 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_016] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:08<00:10,  1.26s/it][A[A[A[A[A2025-04-21 15:14:59,518 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_035] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:16,  1.46it/s][A[A2025-04-21 15:14:59,532 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:59,546 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_053] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:04,  5.09it/s][A[A[A2025-04-21 15:14:59,567 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:59,568 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_071] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:04<00:02,  2.96it/s][A2025-04-21 15:14:59,616 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:59,618 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:59,657 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_053] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:01,  9.50it/s][A[A[A2025-04-21 15:14:59,674 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:59,700 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:14:59,702 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:59,706 - ERROR - [test_053][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Ha encontrado el l√≠mite material de su modelo socialista"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "Conferencia de prensa en Casa Rosada",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""pol√≠tica socialista"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "Conferencia de prensa en Casa Rosada",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""(...) Esto no se limit√≥ en la Rep√∫blica Argentina, similares experiencias tuvieron lugar en Venezuela, Ecuador, Bolivia e incluso Brasil, en menor medida. Producto de pol√≠ticas socialistas escondidas bajo un nacionalismo meramente ret√≥rico, muchos de esos pa√≠ses terminaron destrozados"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "Conferencia de prensa en Casa Rosada",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Empezando por Venezuela que es una gran villa miseria, adem√°s de una c√°rcel a cielo abierto, o Bolivia que tambi√©n ha encontrado el l√≠mite material de su modelo socialista y que paulatinamente se est√° deteriorando"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "Conferencia de prensa en Casa Rosada",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""reafirm√≥ el pleno apoyo de EEUU a las audaces reformas econ√≥micas"",\n         "emisor_nombre": "Scott Bessent",\n         "contexto": "Reuni√≥n con el presidente Milei",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""lo elogi√≥ por la pronta acci√≥n de su gobierno para reducir las barreras al comercio rec√≠proco"",\n         "emisor_nombre": "Scott Bessent",\n         "contexto": "Reuni√≥n con el presidente Milei",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}


[test_035] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:00<00:03,  5.55it/s][A[A2025-04-21 15:14:59,788 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:14:59,789 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:14:59,813 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:59,822 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_035] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:00<00:02,  7.85it/s][A[A2025-04-21 15:14:59,837 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:59,881 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:59,884 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_053] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01, 10.89it/s][A[A[A2025-04-21 15:14:59,891 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:14:59,918 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:14:59,920 - ERROR - [test_035][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Me informan Tesorer√≠a de la Asamblea, que a los diputados (as), tambi√©n se les pagar√° en cheque. C√≥mo los auditores de Contralor√≠a cargan los cheques no he podido cobrar tampoco. Ser√° que tendr√© que firmar ante √©l para recibirlo? ‚Äú",\\n         "emisor_nombre": "Luis Eduardo Camacho",\\n         "contexto": "Diputado oficialista quej√°ndose de no poder cobrar su salario",\\n         "fecha_cita": null,\\n         "relevancia_cita": 5\\n      },\\n      {\\n         "cita": ""Un diputado confirm√≥ a La Decana que los diputados deber√≠an ir a buscar sus cheques a la sede de la Contralor√≠a General de la Rep√∫blica."",\\n         "emisor_nombre": "Un diputado (anonimo)",\\n         "contexto": "Confirmaci√≥n de la medida de pagar con cheques a funcionarios legislativos",\\n         "fecha_cita": null,\\n         "relevancia_cita": 4\\n      },\\n      {\\n         "cita": ""Me quej√≥ el diputado oficialista Luis Eduardo Camacho en su cuenta de X."",\\n         "emisor_nombre": "Luis Eduardo Camacho",\\n         "contexto": "Queja del diputado oficialista en redes sociales",\\n         "fecha_cita": null,\\n         "relevancia_cita": 3\\n      },\\n      {\\n         "cita": ""La situaci√≥n, incluso, fue denunciada en redes sociales."",\\n         "emisor_nombre": "La Estrella de Panam√°",\\n         "contexto": "Denuncia de la situaci√≥n en redes sociales",\\n         "fecha_cita": null,\\n         "relevancia_cita": 2\\n      }\\n   ]\\n}'}}
2025-04-21 15:15:00,108 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:00,129 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_053] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:01<00:01,  9.90it/s][A[A[A2025-04-21 15:15:00,133 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:00,235 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_035] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:01,  9.99it/s][A[A2025-04-21 15:15:00,400 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:00,466 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_053] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:01<00:01,  8.25it/s][A[A[A2025-04-21 15:15:00,570 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_035] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:01<00:01,  8.51it/s][A[A2025-04-21 15:15:00,575 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:00,727 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:00,917 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_053] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:01,  6.56it/s][A[A[A2025-04-21 15:15:00,941 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_035] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:02<00:01,  7.36it/s][A[A2025-04-21 15:15:00,988 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:00,989 - INFO - Retrying request to /openai/v1/chat/completions in 12.000000 seconds
2025-04-21 15:15:01,040 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_035] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:01,  7.65it/s][A[A2025-04-21 15:15:01,069 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_053] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:02<00:01,  6.56it/s][A[A[A2025-04-21 15:15:01,179 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_053] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:02<00:01,  6.95it/s][A[A[A2025-04-21 15:15:01,556 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_053] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:03<00:01,  5.10it/s][A[A[A2025-04-21 15:15:01,579 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:01,632 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:01,977 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_035] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:03<00:02,  3.56it/s][A[A2025-04-21 15:15:02,233 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_035] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:03<00:01,  3.63it/s][A[A2025-04-21 15:15:03,027 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_035] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:04<00:02,  2.53it/s][A[A2025-04-21 15:15:03,097 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:03,098 - ERROR - [test_034][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 33056, Requested 2260. Please try again in 10.633s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_034] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:15<00:02,  2.59s/it][A[A[A[A2025-04-21 15:15:03,793 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:03,794 - INFO - Retrying request to /openai/v1/chat/completions in 22.000000 seconds
2025-04-21 15:15:04,086 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:04,087 - INFO - Retrying request to /openai/v1/chat/completions in 22.000000 seconds
2025-04-21 15:15:04,349 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:04,350 - INFO - Retrying request to /openai/v1/chat/completions in 21.000000 seconds
2025-04-21 15:15:04,369 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:04,370 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:15:04,483 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:04,485 - INFO - Retrying request to /openai/v1/chat/completions in 21.000000 seconds
2025-04-21 15:15:04,492 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:04,493 - INFO - Retrying request to /openai/v1/chat/completions in 22.000000 seconds
2025-04-21 15:15:04,576 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:04,577 - ERROR - [test_016][relevancia][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32317, Requested 949. Please try again in 6.532s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_016] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:13<00:15,  2.21s/it][A[A[A[A[A2025-04-21 15:15:04,649 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:04,650 - ERROR - [test_016][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32281, Requested 876. Please try again in 6.314s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:15:04,673 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:04,674 - INFO - Retrying request to /openai/v1/chat/completions in 12.000000 seconds
2025-04-21 15:15:04,717 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:04,718 - ERROR - [test_016][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 39292, Requested 876. Please try again in 20.337s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_016] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:13<00:06,  1.32s/it][A[A[A[A[A2025-04-21 15:15:04,875 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:04,876 - INFO - Retrying request to /openai/v1/chat/completions in 21.000000 seconds
2025-04-21 15:15:04,898 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:04,899 - INFO - Retrying request to /openai/v1/chat/completions in 21.000000 seconds
2025-04-21 15:15:05,069 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:05,070 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:05,117 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_035] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:06<00:04,  1.22it/s][A[A2025-04-21 15:15:05,365 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_071] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:09<00:10,  1.47s/it][A2025-04-21 15:15:06,906 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:06,907 - ERROR - [test_071][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 38198, Requested 1255. Please try again in 18.907s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_071] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:11<00:08,  1.48s/it][A2025-04-21 15:15:07,178 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:07,179 - ERROR - [test_016][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 38063, Requested 1137. Please try again in 18.401s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_016] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:16<00:06,  1.58s/it][A[A[A[A[A2025-04-21 15:15:11,871 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:11,872 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:15:12,126 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_071] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:16<00:12,  2.40s/it][A2025-04-21 15:15:12,128 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:12,129 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:15:12,242 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:12,243 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:12,376 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:12,377 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:15:12,381 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:12,382 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:15:12,468 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:12,468 - ERROR - [test_016][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29481, Requested 1137. Please try again in 1.236s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_016] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:21<00:07,  2.49s/it][A[A[A[A[A2025-04-21 15:15:12,704 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:12,705 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:12,806 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_071] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:17<00:07,  1.96s/it][A2025-04-21 15:15:13,089 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:13,090 - ERROR - [test_034][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 35108, Requested 2042. Please try again in 14.3s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_034] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:25<00:00,  4.76s/it][A[A[A[A



                                                                         [A[A[A[A2025-04-21 15:15:13,103 - INFO - --- Art√≠culo test_034 completado ---
2025-04-21 15:15:13,103 - INFO - --- Procesando Art√≠culo: test_017 ---
2025-04-21 15:15:13,104 - INFO - [test_017] Lanzando 25 llamadas a Groq...




[test_017] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[AProgreso General Art√≠culos:  28%|‚ñà‚ñà‚ñä       | 20/72 [01:53<05:33,  6.41s/it]2025-04-21 15:15:13,343 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:13,344 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:15:13,347 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:13,348 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:15:13,351 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:13,352 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:15:13,353 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:13,354 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:15:13,369 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:13,370 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:15:13,457 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:13,457 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:13,584 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_017] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:11,  2.08it/s][A[A[A[A2025-04-21 15:15:13,730 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_017] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:06,  3.52it/s][A[A[A[A2025-04-21 15:15:13,769 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:13,869 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_017] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:00<00:03,  6.69it/s][A[A[A[A2025-04-21 15:15:13,990 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_017] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:00<00:02,  7.09it/s][A[A[A[A2025-04-21 15:15:14,028 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:15:14,029 - ERROR - [test_017][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Lo dijimos una y otra vez, la autonom√≠a solo va a funcionar si empieza a implementarse de forma total; es con salud, educaci√≥n y seguridad descentralizadas (y entregadas) a las regiones y a los municipios, para que t√∫ sepas qui√©n le brinda salud, qui√©n educa a tus hijos(...) que no adoctrinen, que eduquen a los ni√±os"",\n         "emisor_nombre": "Jorge Quiroga",\n         "contexto": "En su discurso sobre el plan de Gobierno",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""yo no soy millonario, pero soy rico, tengo tres t√≠tulos universitarios, esa es mi riqueza"",\n         "emisor_nombre": "Jorge Quiroga",\n         "contexto": "En su discurso sobre su patrimonio",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""solo un debate p√∫blico de todos los candidatos permitir√° a la poblaci√≥n ver y escuchar las propuestas que tienen para el caso de que sean gobierno, y por eso insistir√° en que se realicen esos encuentros p√∫blicos entre postulantes a la presidencia"",\n         "emisor_nombre": "Jorge Quiroga",\n         "contexto": "En su discurso sobre la importancia de los debates p√∫blicos",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}
2025-04-21 15:15:14,056 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:14,109 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_017] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:01, 12.04it/s][A[A[A[A2025-04-21 15:15:14,185 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:14,352 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_017] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01, 10.35it/s][A[A[A[A2025-04-21 15:15:14,414 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:14,451 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:14,452 - ERROR - [test_035][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29607, Requested 1112. Please try again in 1.437s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_035] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:15<00:12,  3.05s/it][A[A2025-04-21 15:15:14,482 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_017] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:01<00:01, 11.55it/s][A[A[A[A2025-04-21 15:15:14,594 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:14,809 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_017] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:01<00:01,  8.99it/s][A[A[A[A2025-04-21 15:15:14,822 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:14,904 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:14,905 - ERROR - [test_071][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29379, Requested 1255. Please try again in 1.267s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_071] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:19<00:05,  1.99s/it][A2025-04-21 15:15:15,329 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_017] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:01,  6.33it/s][A[A[A[A2025-04-21 15:15:15,473 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_017] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:02<00:01,  6.43it/s][A[A[A[A2025-04-21 15:15:15,975 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:15,976 - ERROR - [test_071][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29340, Requested 1038. Please try again in 755ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_071] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:20<00:03,  1.74s/it][A2025-04-21 15:15:16,223 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:16,225 - ERROR - [test_053][relevancia][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29213, Requested 950. Please try again in 325ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_053] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:17<00:07,  2.49s/it][A[A[A2025-04-21 15:15:16,487 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:16,488 - ERROR - [test_035][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29080, Requested 1221. Please try again in 602ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_035] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:17<00:08,  2.77s/it][A[A2025-04-21 15:15:16,654 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_017] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:03<00:02,  2.71it/s][A[A[A[A2025-04-21 15:15:16,773 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:16,774 - ERROR - [test_016][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 28937, Requested 1252. Please try again in 378ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_016] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:25<00:05,  2.97s/it][A[A[A[A[A2025-04-21 15:15:16,984 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_017] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:03<00:02,  2.78it/s][A[A[A[A2025-04-21 15:15:17,546 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:17,547 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:15:17,581 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:17,582 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:15:18,157 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_017] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:05<00:02,  1.78it/s][A[A[A[A2025-04-21 15:15:18,643 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:18,644 - ERROR - [test_017][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29593, Requested 982. Please try again in 1.15s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_017] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:05<00:02,  1.85it/s][A[A[A[A2025-04-21 15:15:18,714 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:18,854 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_035] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:20<00:05,  2.66s/it][A[A2025-04-21 15:15:20,502 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_017] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:07<00:01,  1.41it/s][A[A[A[A2025-04-21 15:15:21,092 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_017] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:07<00:00,  1.47it/s][A[A[A[A2025-04-21 15:15:26,024 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_016] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:34<00:04,  4.67s/it][A[A[A[A[A2025-04-21 15:15:26,128 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_035] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:27<00:03,  3.98s/it][A[A2025-04-21 15:15:26,217 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:26,218 - ERROR - [test_053][relevancia][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29562, Requested 950. Please try again in 1.024s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_053] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:27<00:07,  3.91s/it][A[A[A2025-04-21 15:15:26,576 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_071] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:31<00:04,  4.26s/it][A2025-04-21 15:15:26,589 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:26,590 - ERROR - [test_016][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29367, Requested 1252. Please try again in 1.238s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_016] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:35<00:00,  3.52s/it][A[A[A[A[A




                                                                         [A[A[A[A[A2025-04-21 15:15:26,608 - INFO - --- Art√≠culo test_016 completado ---
2025-04-21 15:15:26,608 - INFO - --- Procesando Art√≠culo: test_072 ---
2025-04-21 15:15:26,609 - INFO - [test_072] Lanzando 25 llamadas a Groq...





[test_072] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[A[AProgreso General Art√≠culos:  29%|‚ñà‚ñà‚ñâ       | 21/72 [02:06<07:15,  8.54s/it]2025-04-21 15:15:26,855 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:26,856 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:15:26,884 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_071] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:31<00:00,  3.12s/it][A
                                                                         [A2025-04-21 15:15:26,896 - INFO - --- Art√≠culo test_071 completado ---
2025-04-21 15:15:26,896 - INFO - --- Procesando Art√≠culo: test_054 ---
2025-04-21 15:15:26,897 - INFO - [test_054] Lanzando 25 llamadas a Groq...

[test_054] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][AProgreso General Art√≠culos:  31%|‚ñà‚ñà‚ñà       | 22/72 [02:07<05:03,  6.06s/it]2025-04-21 15:15:28,049 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:28,050 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:28,051 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:28,052 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:28,053 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:28,054 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:28,054 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:28,055 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:28,056 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:28,057 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:15:28,058 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:28,059 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:28,065 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:28,066 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:28,068 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:15:28,068 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:15:28,070 - ERROR - [test_053][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n  "resultados": [\n    {\n      "nombre": "Javier Milei",\n      "tipo": "PERSONA",\n      "alias": [\n        "Milei"\n      ],\n      "descripcion_contextual": "Presidente de Argentina, protagonista del art√≠culo.",\n      "relevancia_articulo": 10\n    },\n    {\n      "nombre": "Scott Bessent",\n      "tipo": "PERSONA",\n      "alias": [],\n      "descripcion_contextual": "Secretario del Tesoro de los Estados Unidos, se reuni√≥ con Milei.",\n      "relevancia_articulo": 7\n    },\n    {\n      "nombre": "Donald Trump",\n      "tipo": "PERSONA",\n      "alias": [],\n      "descripcion_contextual": "Expresidente de los Estados Unidos, mencionado en relaci√≥n a Bessent.",\n      "relevancia_articulo": 3\n    },\n    {\n      "nombre": "Rep√∫blica Argentina",\n      "tipo": "LUGAR",\n      "alias": [],\n      "descripcion_contextual": "Pa√≠s donde se encuentra el presidente Milei.",\n      "relevancia_articulo": 9\n    },\n    {\n      "nombre": "Venezuela",\n      "tipo": "LUGAR",\n      "alias": [],\n      "descripcion_contextual": Pa√≠s mencionado como ejemplo de pol√≠tica socialista.",\n      "relevancia_articulo": 6\n    },\n    {\n      "nombre": "Bolivia",\n      "tipo": "LUGAR",\n      "alias": [],\n      "descripcion_contextual": Pa√≠s mencionado como ejemplo de modelo econ√≥mico socialista.",\n      "relevancia_articulo": 6\n    },\n    {\n      "nombre": "Ecuador",\n      "tipo": "LUGAR",\n      "alias": [],\n      "descripcion_contextual": Pa√≠s mencionado como ejemplo de pol√≠tica socialista.",\n      "relevancia_articulo": 4\n    },\n    {\n      "nombre": "Brasil",\n      "tipo": "LUGAR",\n      "alias": [],\n      "descripcion_contextual": Pa√≠s mencionado como ejemplo de pol√≠tica socialista.",\n      "relevancia_articulo": 4\n    },\n    {\n      "nombre": "Estados Unidos",\n      "tipo": "LUGAR",\n      "alias": ["EEUU"],\n      "descripcion_contextual": Pa√≠s del que proviene el Secretario del Tesoro.",\n      "relevancia_articulo": 6\n    },\n    {\n      "nombre": "Casa Rosada",\n      "tipo": "LUGAR",\n      "alias": [],\n      "descripcion_contextual": Sede del gobierno argentino.",\n      "relevancia_articulo": 4\n    },\n    {\n      "nombre": "modelo econ√≥mico boliviano",\n      "tipo": "CONCEPTO",\n      "alias": [],\n      "descripcion_contextual": Modelo econ√≥mico del que habla Milei.",\n      "relevancia_articulo": 8\n    },\n    {\n      "nombre": "pol√≠tica socialista",\n      "tipo": "CONCEPTO",\n      "alias": [],\n      "descripcion_contextual": Tipo de pol√≠tica mencionada en relaci√≥n a Venezuela y Bolivia.",\n      "relevancia_articulo": 7\n    },\n    {\n      "nombre": "cepo",\n      "tipo": "CONCEPTO",\n      "alias": [],\n      "descripcion_contextual": Restricciones cambiarias levantadas en Argentina.",\n      "relevancia_articulo": 5\n    },\n    {\n      "nombre": "reformas econ√≥micas",\n      "tipo": "CONCEPTO",\n      "alias": [],\n      "descripcion_contextual": Reformas econ√≥micas de la gesti√≥n de Milei.",\n      "relevancia_articulo": 5\n    },\n    {\n      "nombre": "acuerdo de cooperaci√≥n bilateral",\n      "tipo": "CONCEPTO",\n      "alias": [],\n      "descripcion_contextual": Posible acuerdo entre Argentina y Estados Unidos.",\n      "relevancia_articulo": 5\n    }\n  ]\n}'}}





[test_072] Llamadas Groq:   4%|‚ñç         | 1/25 [00:01<00:35,  1.46s/it][A[A[A[A[A



[test_017] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:14<00:00,  2.26s/it][A[A[A[A



                                                                         [A[A[A[A2025-04-21 15:15:28,084 - INFO - --- Art√≠culo test_017 completado ---



[test_053] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:29<00:03,  3.47s/it][A[A[A2025-04-21 15:15:28,085 - INFO - --- Procesando Art√≠culo: test_036 ---
2025-04-21 15:15:28,087 - INFO - [test_036] Lanzando 25 llamadas a Groq...




[test_036] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[AProgreso General Art√≠culos:  32%|‚ñà‚ñà‚ñà‚ñè      | 23/72 [02:08<03:45,  4.60s/it]2025-04-21 15:15:28,167 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:15:28,181 - ERROR - [test_072][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""El proceso para ellos no ha quedado trunco, sigue en su curso. En los pr√≥ximos d√≠as o semanas van a poder o no lograr su inscripci√≥n en funci√≥n del cumplimiento de los requisitos y resolver los cuestionamientos que, tengo entendido, est√°n en proceso. Si logran inscribirse antes de octubre, que es la probable fecha de convocatoria del proceso de Elecciones Regionales y Municipales, podr√°n participar en esos mismos con todas las de la ley"",\n         "emisor_nombre": "Roberto Burneo",\n         "contexto": "Sobre la inscripci√≥n de 29 partidos pol√≠ticos en el Registro de Organizaciones Pol√≠ticas (ROP) del Jurado Nacional de Elecciones (JNE)",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Si estos 29 partidos lograran su inscripci√≥n, se suman a los 43 que ya est√°n inscritos y a los 98 movimientos regionales que ya cuentan con inscripci√≥n Por lo tanto, las elecciones regionales y municipales s√≠ van a ser complejas. Si las elecciones generales de abril del pr√≥ximo a√±o son complejas, las que se nos vienen en octubre van a hacer de una complejidad a√∫n mayor"",\n         "emisor_nombre": "Roberto Burneo",\n         "contexto": "Sobre la complejidad de las Elecciones Regionales y Municipales de octubre de 2026",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Estas nuevas disposiciones que se han emitido s√≠ generan impacto en cuanto a la necesidad de mayores recursos. De por s√≠, el pedido inicial [800 millones] tampoco lo dieron completo, pero el compromiso que tiene el Ejecutivo y el Ministerio de Econom√≠a es que, en la medida que vayamos ejecutando el presupuesto, ellos nos van a seguir canalizando los recursos"",\n         "emisor_nombre": "Roberto Burneo",\n         "contexto": "Sobre la necesidad de un presupuesto adicional para implementar nuevas disposiciones electorales",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El proceso para ellos no ha quedado trunco, sigue en su curso"",\n         "emisor_nombre": "Roberto Burneo",\n         "contexto": "Sobre la inscripci√≥n de 29 partidos pol√≠ticos en el Registro de Organizaciones Pol√≠ticas (ROP) del Jurado Nacional de Elecciones (JNE)",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Si las elecciones generales de abril del pr√≥ximo a√±o son complejas, las que se nos vienen en octubre van a hacer de una complejidad a√∫n mayor"",\n         "emisor_nombre": "Roberto Burneo",\n         "contexto": "Sobre la complejidad de las Elecciones Regionales y Municipales de octubre de 2026",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Las elecciones regionales y municipales s√≠ van a ser complejas"",\n         "emisor_nombre": "Roberto Burneo",\n         "contexto": "Sobre la complejidad de las Elecciones Regionales y Municipales de octubre de 2026",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}
2025-04-21 15:15:28,188 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_072] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:03,  5.66it/s][A[A[A[A[A2025-04-21 15:15:28,289 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:28,300 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:28,360 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_072] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01,  8.02it/s][A[A[A[A[A2025-04-21 15:15:28,366 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:28,374 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:28,375 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:28,376 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:28,376 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:15:28,394 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:28,395 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:28,396 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:28,397 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:28,447 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:28,448 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:28,448 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:28,449 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:28,457 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:28,458 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:28,458 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:28,459 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:28,473 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:28,474 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:28,494 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:28,495 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:28,500 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:28,501 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:15:28,508 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:28,509 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:28,561 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:28,562 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:28,564 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:28,565 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:28,600 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_072] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:01<00:01,  9.20it/s][A[A[A[A[A2025-04-21 15:15:28,707 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_036] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:14,  1.61it/s][A[A[A[A2025-04-21 15:15:28,814 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_054] Llamadas Groq:   4%|‚ñç         | 1/25 [00:01<00:46,  1.92s/it][A2025-04-21 15:15:28,866 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:28,933 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_036] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:08,  2.57it/s][A[A[A[A2025-04-21 15:15:29,010 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_054] Llamadas Groq:   8%|‚ñä         | 2/25 [00:02<00:20,  1.10it/s][A2025-04-21 15:15:29,025 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:15:29,027 - ERROR - [test_054][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Nos dijo p√∫blicamente que, en 15 d√≠as, con la sentencia de la justicia, se realizar√≠a el pago, e incluso se comprometi√≥ a colaborar para agilizar el juicio. Sin embargo, todas las instancias han fallado a nuestro favor y ellos siguen apelando"",\n         "emisor_nombre": "uno de los afectados",\n         "contexto": "Durante una protesta frente al Ministerio de Obras P√∫blicas",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Nos sentimos desamparados, pese a que la justicia nos ha respaldado en todas las instancias"",\n         "emisor_nombre": "los exempleados",\n         "contexto": "Durante una movilizaci√≥n",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}
2025-04-21 15:15:29,047 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:29,082 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:29,083 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:29,090 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:29,095 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_036] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:01<00:06,  3.51it/s][A[A[A[A2025-04-21 15:15:29,118 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_072] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:02<00:01,  6.81it/s][A[A[A[A[A2025-04-21 15:15:29,214 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:29,239 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_036] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:04,  4.36it/s][A[A[A[A2025-04-21 15:15:29,265 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_054] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:02<00:04,  3.90it/s][A2025-04-21 15:15:29,277 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:29,320 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:29,323 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:29,324 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:29,376 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_072] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:02<00:01,  7.04it/s][A[A[A[A[A2025-04-21 15:15:29,404 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:15:29,405 - ERROR - [test_036][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Esta victoria ha sido hist√≥rica, una victoria de m√°s de 10 puntos"",\n         "emisor_nombre": "Daniel Noboa",\n         "contexto": "Declaraciones de Daniel Noboa tras conocer los resultados de las elecciones en Ecuador",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Me niego a creer que exista un pueblo que prefiera la mentira antes que la verdad"",\n         "emisor_nombre": "Luisa Gonz√°lez",\n         "contexto": "Declaraciones de Luisa Gonz√°lez tras conocer los resultados de las elecciones en Ecuador",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Es el m√°s grotesco fraude electoral"",\n         "emisor_nombre": "Luisa Gonz√°lez",\n         "contexto": "Declaraciones de Luisa Gonz√°lez tras conocer los resultados de las elecciones en Ecuador",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Daniel Noboa registr√≥ incrementos estad√≠sticamente imposibles en numerosos recintos electorales"",\n         "emisor_nombre": "Revoluci√≥n Ciudadana (RC5)",\n         "contexto": "Acusaciones de fraude electoral presentadas por Revoluci√≥n Ciudadana (RC5)",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}




[test_036] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:02,  6.60it/s][A[A[A[A2025-04-21 15:15:29,417 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:29,419 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:29,444 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:29,499 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_054] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:02<00:02,  6.54it/s][A2025-04-21 15:15:29,521 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_036] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01, 12.84it/s][A[A[A[A2025-04-21 15:15:29,691 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:29,706 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_054] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:01,  7.18it/s][A2025-04-21 15:15:29,868 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:29,968 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_054] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:03<00:01,  7.30it/s][A2025-04-21 15:15:30,007 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:30,016 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:30,064 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:30,085 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_036] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:01<00:01,  7.18it/s][A[A[A[A2025-04-21 15:15:30,130 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:30,157 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:30,164 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:30,282 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:30,283 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:30,673 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:30,674 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:15:30,690 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:30,691 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:15:30,705 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_072] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:04<00:01,  3.49it/s][A[A[A[A[A2025-04-21 15:15:30,830 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_054] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:03<00:01,  4.52it/s][A2025-04-21 15:15:31,054 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_036] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:01,  5.35it/s][A[A[A[A2025-04-21 15:15:31,064 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_054] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:04<00:01,  4.48it/s][A2025-04-21 15:15:31,108 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:31,227 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_054] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:04<00:01,  4.73it/s][A2025-04-21 15:15:31,277 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:31,278 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:15:31,329 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_072] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:04<00:01,  2.93it/s][A[A[A[A[A2025-04-21 15:15:31,371 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_054] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:04<00:01,  5.08it/s][A2025-04-21 15:15:31,513 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:31,514 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:15:31,585 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:31,586 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:15:31,600 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:31,601 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:15:31,620 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_072] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:05<00:01,  3.00it/s][A[A[A[A[A2025-04-21 15:15:31,659 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:31,660 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:15:31,666 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:31,667 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:15:31,673 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:31,674 - INFO - Retrying request to /openai/v1/chat/completions in 18.000000 seconds
2025-04-21 15:15:31,907 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_036] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:03<00:01,  4.06it/s][A[A[A[A2025-04-21 15:15:32,175 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_036] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:04<00:01,  4.01it/s][A[A[A[A2025-04-21 15:15:32,257 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:32,480 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:32,481 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:15:32,499 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:32,501 - ERROR - [test_072][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30614, Requested 1512. Please try again in 4.252s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:15:32,501 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"





[test_072] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:05<00:01,  2.23it/s][A[A[A[A[A2025-04-21 15:15:32,503 - ERROR - [test_072][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30614, Requested 1281. Please try again in 3.791s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:15:32,733 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:32,734 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:15:32,829 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:32,830 - ERROR - [test_054][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30449, Requested 1232. Please try again in 3.362s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_054] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:05<00:02,  2.02it/s][A2025-04-21 15:15:32,973 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_054] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:06<00:01,  2.46it/s][A2025-04-21 15:15:33,281 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:33,282 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:15:33,295 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:33,296 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:15:33,680 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_036] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:05<00:01,  2.49it/s][A[A[A[A2025-04-21 15:15:33,888 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_054] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:06<00:01,  1.84it/s][A2025-04-21 15:15:35,723 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 500 Internal Server Error"
2025-04-21 15:15:35,725 - INFO - Retrying request to /openai/v1/chat/completions in 0.429739 seconds
2025-04-21 15:15:35,857 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 500 Internal Server Error"
2025-04-21 15:15:35,858 - INFO - Retrying request to /openai/v1/chat/completions in 0.497362 seconds
2025-04-21 15:15:36,876 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:36,877 - ERROR - [test_036][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32304, Requested 749. Please try again in 6.106s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_036] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:08<00:02,  1.12it/s][A[A[A[A2025-04-21 15:15:36,976 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:36,977 - ERROR - [test_054][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32261, Requested 1338. Please try again in 7.198s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_054] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:10<00:02,  1.24s/it][A2025-04-21 15:15:37,878 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:37,879 - ERROR - [test_036][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31802, Requested 1010. Please try again in 5.625s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_036] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:09<00:01,  1.09it/s][A[A[A[A2025-04-21 15:15:39,784 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:39,785 - ERROR - [test_036][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 33654, Requested 749. Please try again in 8.806s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_036] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:11<00:01,  1.14s/it][A[A[A[A2025-04-21 15:15:39,860 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_053] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:41<00:00,  5.41s/it][A[A[A


                                                                         [A[A[A2025-04-21 15:15:39,875 - INFO - --- Art√≠culo test_053 completado ---
2025-04-21 15:15:39,876 - INFO - --- Procesando Art√≠culo: test_018 ---
2025-04-21 15:15:39,877 - INFO - [test_018] Lanzando 25 llamadas a Groq...



[test_018] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[AProgreso General Art√≠culos:  33%|‚ñà‚ñà‚ñà‚ñé      | 24/72 [02:20<05:24,  6.76s/it]2025-04-21 15:15:40,117 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:40,118 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:40,134 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:40,135 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:40,150 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:40,151 - INFO - Retrying request to /openai/v1/chat/completions in 12.000000 seconds
2025-04-21 15:15:40,233 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:40,233 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:15:40,249 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:40,249 - INFO - Retrying request to /openai/v1/chat/completions in 12.000000 seconds
2025-04-21 15:15:40,256 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:40,256 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:15:40,397 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_018] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:12,  1.92it/s][A[A[A2025-04-21 15:15:40,498 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_018] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:06,  3.65it/s][A[A[A2025-04-21 15:15:40,518 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_035] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:41<00:00,  7.00s/it][A[A

                                                                         [A[A2025-04-21 15:15:40,530 - INFO - --- Art√≠culo test_035 completado ---
2025-04-21 15:15:40,530 - INFO - --- Procesando Art√≠culo: test_055 ---
2025-04-21 15:15:40,531 - INFO - [test_055] Lanzando 25 llamadas a Groq...


[test_055] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[AProgreso General Art√≠culos:  35%|‚ñà‚ñà‚ñà‚ñç      | 25/72 [02:20<03:51,  4.92s/it]2025-04-21 15:15:40,589 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:40,693 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:40,694 - ERROR - [test_054][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29694, Requested 1338. Please try again in 2.064s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_054] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:13<00:01,  1.94s/it][A2025-04-21 15:15:40,713 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:40,714 - ERROR - [test_054][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29684, Requested 1119. Please try again in 1.606s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

                                                                         [A2025-04-21 15:15:40,726 - INFO - --- Art√≠culo test_054 completado ---
2025-04-21 15:15:40,726 - INFO - --- Procesando Art√≠culo: test_037 ---
2025-04-21 15:15:40,727 - INFO - [test_037] Lanzando 25 llamadas a Groq...

[test_037] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][AProgreso General Art√≠culos:  36%|‚ñà‚ñà‚ñà‚ñå      | 26/72 [02:20<02:41,  3.51s/it]2025-04-21 15:15:40,798 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:40,801 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:40,879 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:40,888 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"



[test_018] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:04,  4.46it/s][A[A[A2025-04-21 15:15:40,890 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:40,891 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:15:40,891 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:40,892 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:40,892 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:40,894 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:40,895 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:15:40,896 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:40,897 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:15:40,912 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:40,913 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:40,937 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:40,938 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:40,975 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:40,976 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:40,980 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:40,980 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:41,003 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:41,004 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:41,090 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:41,091 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:15:41,096 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:41,097 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:15:41,098 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:41,099 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:41,488 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_055] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:23,  1.04it/s][A[A2025-04-21 15:15:41,500 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:41,513 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:41,550 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_018] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:07,  2.78it/s][A[A[A2025-04-21 15:15:41,577 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:41,577 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:15:41,584 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:41,599 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:41,745 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_037] Llamadas Groq:   4%|‚ñç         | 1/25 [00:01<00:24,  1.02s/it][A2025-04-21 15:15:41,880 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_055] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:06,  3.48it/s][A[A2025-04-21 15:15:41,884 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_037] Llamadas Groq:   8%|‚ñä         | 2/25 [00:01<00:11,  1.99it/s][A2025-04-21 15:15:41,933 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_072] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:15<00:02,  2.07s/it][A[A[A[A[A2025-04-21 15:15:41,951 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_018] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:02<00:03,  4.32it/s][A[A[A2025-04-21 15:15:42,092 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_055] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:05,  3.75it/s][A[A2025-04-21 15:15:42,138 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_037] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:01<00:08,  2.57it/s][A2025-04-21 15:15:42,166 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:42,167 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:15:42,169 - ERROR - [test_055][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""He instruido a la Consultor\\u00eda Jur\\u00eddica del Poder Ejecutivo para que redacte un decreto que reconozca la labor patri\\u00f3tica y ejemplar de los cientos de hombres y mujeres que, con valent\\u00eda y entrega, participaron en las labores de rescate"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Durante su intervenci\\u00f3n en LA Semanal con la Prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Para no dejar a ninguno de los h\\u00e9roes, que desde las diferentes labores nos llenaron de orgullo en esta hora tan dif\\u00edcil y dolorosa para la naci\\u00f3n"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Enf\\u00e1tiz\\u00f3",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}





[test_072] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:15<00:00,  1.68s/it][A[A[A[A[A




                                                                         [A[A[A[A[A2025-04-21 15:15:42,182 - INFO - --- Art√≠culo test_072 completado ---
2025-04-21 15:15:42,182 - INFO - --- Procesando Art√≠culo: test_019 ---
2025-04-21 15:15:42,183 - INFO - [test_019] Lanzando 25 llamadas a Groq...





[test_019] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[A[AProgreso General Art√≠culos:  38%|‚ñà‚ñà‚ñà‚ñä      | 27/72 [02:22<02:10,  2.89s/it]2025-04-21 15:15:42,242 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_055] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:03,  5.50it/s][A[A2025-04-21 15:15:42,295 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:15:42,313 - ERROR - [test_018][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""¬øVos te das cuenta de que ten√©s un Monumental vi√©ndote?",",\n         "emisor_nombre": "Alejandro Fantino",\n         "contexto": "En un programa de streaming con el presidente Javier Milei",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""Es el d√≠a de la liberaci√≥n"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "En alusi√≥n a la denominaci√≥n de Donald Trump para el d√≠a en que anunci√≥ la imposici√≥n de aranceles",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""La caracter√≠stica de esta salida del cepo es totalmente distinta a la experiencia del gobierno de (Mauricio) Macri, que hab√≠a expectativas. Ac√° estaba pulverizada la confianza"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "En referencia a la salida del cepo",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""La dolarizaci√≥n es como una pizza: est√° la de jam√≥n y mozzarella, la de mozzarella, la primavera que tiene anan√°, la que tiene pepperoni... hay un mont√≥n de modelos de pizza, pod√©s hacerle de distintas maneras"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "En referencia a la dolarizaci√≥n",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Los indicadores dicen que los tipos de cambio tienen que caer, los factores monetarios de Argentina llevan a eso"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "En referencia a la ca√≠da del tipo de cambio",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Que agradezcan que Toto es muy contemplativo. Yo hubiera puesto la banda m√°s abajo para hacerles perder m√°s plata"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "En referencia a los especuladores con el precio del d√≥lar",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Messi se defendi√≥ de esto, no le daba notas al periodismo por basuras mentirosas. ¬øD√≥nde est√° escrito que una basura ensobrada te puede golpear y no te pod√©s defender?"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "En referencia a la cr√≠tica a la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Nos correspond√≠a 35% m√°s las penalidades, por el ‚Äòmercasur‚Äô. Nos pusieron 10 a nosotros, generaba un desv√≠o de comercio, lo extendieron a todo el Mercosur y cuando vieron cu√°nto pesaba el Mercosur en Sudam√©rica dijeron ‚Äòles ponemos a todos 10‚Äù"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "En referencia a los aranceles de Trump",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Mandril, decime qu√© se siente que el cepo lleg√≥ a su final. Te juro que aunque pasen los a√±os vos siempre vas a pifiar..."",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "En referencia al levantamiento del cepo",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""Ten√≠amos el tipo de cambio libre en torno a 1400 pesos y hoy se cay√≥ a 1195. Me causa gracia los que dicen que hab√≠a una devaluaci√≥n. Che, cuando se fue (Sergio) Massa el d√≥lar se fue a 1300 y hoy est√° en 1195. Qu√© devaluaci√≥n rara"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "En referencia a la cotizaci√≥n del d√≥lar",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""¬øQu√© pas√≥ hoy (por el lunes) con el tipo de cambio? Estaba cerca de 1.400. ¬øY d√≥nde se fue? A 1.190. La base monetaria no crece, el resultado fiscal no me inyecta pesos, me saca pesos, con lo cual va a haber menos pesos. Se est√° recomponiendo la demanda de dinero. La verdad que seis puntos y medio del PBI es una pelotudez. La base monetaria deber√≠a duplicarse en condiciones normales"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "En referencia a la salida del cepo sin bandas",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Adem√°s, la econom√≠a argentina crece m√°s que la americana, con lo cual la demanda de dinero est√° volando. Vos necesit√°s pesos y no hay m√°s. Entonces inexorablemente en alg√∫n momento la inflaci√≥n va a colapsar. ¬øCu√°ndo? A mitad del a√±o que viene"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "En referencia a la inflaci√≥n",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}



[test_018] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:02<00:04,  3.78it/s][A[A[A2025-04-21 15:15:42,346 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:42,373 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_055] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  5.91it/s][A[A2025-04-21 15:15:42,443 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:42,444 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:15:42,484 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_018] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:02<00:02,  5.22it/s][A[A[A2025-04-21 15:15:42,525 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:42,526 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:15:42,528 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:42,529 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:42,535 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:42,536 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:15:42,541 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:42,542 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:42,543 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:15:42,544 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:42,544 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:42,545 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:15:42,545 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:15:42,546 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:15:42,550 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:42,550 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:15:42,562 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:42,563 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:15:42,572 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_055] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:02<00:02,  5.65it/s][A[A2025-04-21 15:15:42,575 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_037] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:08,  2.45it/s][A2025-04-21 15:15:42,613 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:15:42,614 - ERROR - [test_037][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""para combatir a los grupos armados que amenazan la estabilidad nacional"",\n         "emisor_nombre": "consejo presidencial de transici√≥n de Hait√≠",\n         "contexto": "Describiendo el destino del 40% del presupuesto de guerra",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""el presupuesto especial refleja el compromiso del estado de actuar con decisi√≥n y abordar la creciente inseguridad"",\n         "emisor_nombre": "consejo presidencial de transici√≥n de Hait√≠",\n         "contexto": "Describiendo el objetivo del presupuesto especial",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Bandas armadas incendiaron la comisar√≠a y tomaron el control de la prisi√≥n, orquestando una fuga masiva de reclusos"",\n         "emisor_nombre": "Red Nacional de Defensa de los Derechos Humanos",\n         "contexto": "Describiendo los ataques a la comisar√≠a y la prisi√≥n de Mirebalais",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Algunos dicen que esto fue facilitado por la redistribuci√≥n de las fuerzas del orden a Mirebalais, dejando a Saut-d‚ÄôEau vulnerable"",\n         "emisor_nombre": "activistas",\n         "contexto": "Describiendo la ca√≠da de la ciudad de Saut-d‚ÄôEau en manos de las pandillas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Al ignorar el colapso de la regi√≥n central, las autoridades de transici√≥n demuestran que no tienen un plan real para restaurar los derechos ciudadanos y la seguridad p√∫blica"",\n         "emisor_nombre": "Red Nacional de Defensa de los Derechos Humanos",\n         "contexto": "Criticando la respuesta de las autoridades a la violencia de pandillas",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""La ausencia de respuesta estatal ha convertido a la polic√≠a en bomberos, reaccionando constantemente sin rumbo estrat√©gico, mientras las ciudades caen una tras otra"",\n         "emisor_nombre": "Red Nacional de Defensa de los Derechos Humanos",\n         "contexto": "Criticando la respuesta de las autoridades a la violencia de pandillas",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}
2025-04-21 15:15:42,638 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_018] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:02,  5.45it/s][A[A[A2025-04-21 15:15:42,687 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_055] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:02<00:02,  6.24it/s][A[A2025-04-21 15:15:42,783 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:42,791 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_019] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:14,  1.64it/s][A[A[A[A[A2025-04-21 15:15:42,910 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_037] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:02<00:05,  3.57it/s][A2025-04-21 15:15:43,020 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_018] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:03<00:02,  4.35it/s][A[A[A2025-04-21 15:15:43,081 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_037] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:02<00:04,  3.99it/s][A2025-04-21 15:15:43,091 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:43,108 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_055] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:02,  5.50it/s][A[A2025-04-21 15:15:43,157 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_019] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:10,  2.15it/s][A[A[A[A[A2025-04-21 15:15:43,169 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:43,169 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:15:43,220 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:43,223 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_037] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:02<00:02,  5.84it/s][A2025-04-21 15:15:43,225 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:43,243 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:43,243 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:43,249 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:43,252 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:43,253 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:43,269 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_055] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:02<00:02,  5.65it/s][A[A2025-04-21 15:15:43,298 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:15:43,299 - ERROR - [test_019][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Lo dijimos una y otra vez, la autonom√≠a solo va a funcionar si empieza a implementarse de forma total; es con salud, educaci√≥n y seguridad descentralizadas (y entregadas) a las regiones y a los municipios, para que t√∫ sepas qui√©n le brinda salud, qui√©n educa a tus hijos(...) que no adoctrinen, que eduquen a los ni√±os"",\n         "emisor_nombre": "Jorge Quiroga",\n         "contexto": "En su discurso sobre su plan de Gobierno",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""yo no soy millonario, pero soy rico, tengo tres t√≠tulos universitarios, esa es mi riqueza"",\n         "emisor_nombre": "Jorge Quiroga",\n         "contexto": "En su discurso sobre su plan de Gobierno",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""solo un debate p√∫blico de todos los candidatos permitir√° a la poblaci√≥n ver y escuchar las propuestas que tienen para el caso de que sean gobierno, y por eso insistir√° en que se realicen esos encuentros p√∫blicos entre postulantes a la presidencia"",\n         "emisor_nombre": "Jorge Quiroga",\n         "contexto": "En su discurso sobre su plan de Gobierno",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}





[test_019] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:04,  4.59it/s][A[A[A[A[A2025-04-21 15:15:43,347 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:43,417 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_018] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:03<00:02,  3.68it/s][A[A[A2025-04-21 15:15:43,496 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_037] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:01,  7.55it/s][A2025-04-21 15:15:43,506 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:43,563 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_055] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:03<00:02,  4.84it/s][A[A2025-04-21 15:15:43,590 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_018] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:03<00:02,  4.07it/s][A[A[A2025-04-21 15:15:43,668 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_019] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:03,  4.94it/s][A[A[A[A[A2025-04-21 15:15:43,670 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:43,698 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:43,888 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_019] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:02,  7.27it/s][A[A[A[A[A2025-04-21 15:15:43,957 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_037] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:03<00:01,  6.12it/s][A2025-04-21 15:15:44,012 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:44,013 - INFO - Retrying request to /openai/v1/chat/completions in 31.000000 seconds
2025-04-21 15:15:44,064 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_019] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:02,  6.90it/s][A[A[A[A[A2025-04-21 15:15:44,070 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_037] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:03<00:01,  6.49it/s][A2025-04-21 15:15:44,107 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:44,108 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:44,187 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:44,188 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:15:44,212 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:44,213 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:44,262 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:44,263 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:15:44,517 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_019] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:02<00:02,  4.72it/s][A[A[A[A[A2025-04-21 15:15:44,526 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:44,558 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:44,644 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_019] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:02<00:01,  7.68it/s][A[A[A[A[A2025-04-21 15:15:44,728 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:44,729 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:44,820 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_037] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:04<00:02,  3.59it/s][A2025-04-21 15:15:44,832 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:44,984 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:44,985 - INFO - Retrying request to /openai/v1/chat/completions in 34.000000 seconds
2025-04-21 15:15:45,152 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_055] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:04<00:05,  1.75it/s][A[A2025-04-21 15:15:45,173 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:45,229 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_018] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:05<00:05,  1.60it/s][A[A[A2025-04-21 15:15:45,281 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:45,282 - INFO - Retrying request to /openai/v1/chat/completions in 35.000000 seconds
2025-04-21 15:15:45,316 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_055] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:04<00:02,  2.77it/s][A[A2025-04-21 15:15:45,333 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:45,334 - ERROR - [test_018][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31200, Requested 2308. Please try again in 7.016s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_018] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:05<00:03,  2.09it/s][A[A[A2025-04-21 15:15:45,483 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:45,484 - ERROR - [test_018][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30805, Requested 2420. Please try again in 6.45s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_018] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:05<00:02,  2.60it/s][A[A[A2025-04-21 15:15:45,554 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_055] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:05<00:02,  3.00it/s][A[A2025-04-21 15:15:45,664 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_037] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:04<00:03,  2.45it/s][A2025-04-21 15:15:45,677 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:45,678 - INFO - Retrying request to /openai/v1/chat/completions in 34.000000 seconds
2025-04-21 15:15:45,953 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_018] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:06<00:02,  2.44it/s][A[A[A2025-04-21 15:15:46,356 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_037] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:05<00:03,  2.09it/s][A2025-04-21 15:15:46,370 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:46,371 - INFO - Retrying request to /openai/v1/chat/completions in 34.000000 seconds
2025-04-21 15:15:46,546 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_055] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:06<00:02,  2.01it/s][A[A2025-04-21 15:15:46,907 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_019] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:04<00:04,  2.25it/s][A[A[A[A[A2025-04-21 15:15:46,951 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:46,952 - ERROR - [test_019][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29327, Requested 1346. Please try again in 1.345s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:15:47,169 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_055] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:06<00:02,  1.88it/s][A[A2025-04-21 15:15:47,174 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_018] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:07<00:03,  1.54it/s][A[A[A2025-04-21 15:15:47,321 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:47,322 - INFO - Retrying request to /openai/v1/chat/completions in 34.000000 seconds
2025-04-21 15:15:47,440 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:47,441 - ERROR - [test_037][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29826, Requested 1514. Please try again in 2.679s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_037] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:06<00:03,  1.57it/s][A2025-04-21 15:15:47,467 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_018] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:07<00:02,  1.84it/s][A[A[A2025-04-21 15:15:48,003 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_037] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:07<00:03,  1.62it/s][A2025-04-21 15:15:49,612 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:49,613 - INFO - Retrying request to /openai/v1/chat/completions in 29.000000 seconds
2025-04-21 15:15:49,764 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:49,765 - ERROR - [test_036][relevancia][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31679, Requested 820. Please try again in 4.998s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_036] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:21<00:00,  3.28s/it][A[A[A[A



                                                                         [A[A[A[A2025-04-21 15:15:49,774 - INFO - --- Art√≠culo test_036 completado ---
2025-04-21 15:15:49,775 - INFO - --- Procesando Art√≠culo: test_001 ---
2025-04-21 15:15:49,776 - INFO - [test_001] Lanzando 25 llamadas a Groq...




[test_001] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[AProgreso General Art√≠culos:  39%|‚ñà‚ñà‚ñà‚ñâ      | 28/72 [02:29<03:09,  4.31s/it]2025-04-21 15:15:49,955 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_055] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:09<00:04,  1.15s/it][A[A2025-04-21 15:15:49,980 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:49,981 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:15:50,026 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:50,027 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:15:50,030 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:50,031 - INFO - Retrying request to /openai/v1/chat/completions in 31.000000 seconds
2025-04-21 15:15:50,032 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:50,032 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:15:50,033 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:50,034 - INFO - Retrying request to /openai/v1/chat/completions in 30.000000 seconds
2025-04-21 15:15:50,039 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:50,040 - INFO - Retrying request to /openai/v1/chat/completions in 30.000000 seconds
2025-04-21 15:15:50,088 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:50,089 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:15:50,124 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:50,125 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:15:50,151 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:50,151 - INFO - Retrying request to /openai/v1/chat/completions in 28.000000 seconds
2025-04-21 15:15:50,152 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:50,153 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:50,156 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_019] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:07<00:05,  1.23it/s][A[A[A[A[A2025-04-21 15:15:50,169 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:50,170 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:50,242 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:50,243 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:15:50,324 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_019] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:08<00:04,  1.44it/s][A[A[A[A[A2025-04-21 15:15:50,432 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_001] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:15,  1.52it/s][A[A[A[A2025-04-21 15:15:50,457 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_019] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:08<00:02,  1.73it/s][A[A[A[A[A2025-04-21 15:15:50,542 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_001] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:07,  2.98it/s][A[A[A[A2025-04-21 15:15:50,697 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_001] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:05,  3.95it/s][A[A[A[A2025-04-21 15:15:50,742 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:50,742 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:15:50,772 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:50,772 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:15:50,903 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_001] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:04,  4.27it/s][A[A[A[A2025-04-21 15:15:50,967 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_055] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:10<00:03,  1.11s/it][A[A2025-04-21 15:15:51,062 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_001] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:04,  4.83it/s][A[A[A[A2025-04-21 15:15:51,138 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:51,165 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_019] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:08<00:02,  1.64it/s][A[A[A[A[A2025-04-21 15:15:51,205 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_001] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:02,  7.22it/s][A[A[A[A2025-04-21 15:15:51,274 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:51,275 - ERROR - [test_037][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30922, Requested 1738. Please try again in 5.32s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_037] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:10<00:05,  1.36s/it][A2025-04-21 15:15:51,475 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:51,477 - ERROR - [test_037][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31511, Requested 1626. Please try again in 6.274s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_037] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:10<00:03,  1.03s/it][A2025-04-21 15:15:51,617 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_001] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:03,  4.74it/s][A[A[A[A2025-04-21 15:15:51,648 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_019] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:09<00:01,  1.73it/s][A[A[A[A[A2025-04-21 15:15:51,782 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_001] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:02<00:03,  5.04it/s][A[A[A[A2025-04-21 15:15:51,800 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:52,248 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:52,249 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:15:52,344 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:52,345 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:15:52,351 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_001] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:02<00:03,  4.23it/s][A[A[A[A2025-04-21 15:15:52,356 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:52,357 - ERROR - [test_055][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32872, Requested 1308. Please try again in 8.359999999s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_055] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:11<00:02,  1.19s/it][A[A2025-04-21 15:15:52,390 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:52,391 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:52,445 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:52,957 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_001] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:03<00:03,  3.82it/s][A[A[A[A2025-04-21 15:15:53,004 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:15:54,276 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:54,277 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:15:54,833 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:54,834 - ERROR - [test_019][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29143, Requested 1346. Please try again in 978ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_019] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:12<00:02,  1.25s/it][A[A[A[A[A2025-04-21 15:15:55,700 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_037] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:14<00:03,  1.95s/it][A2025-04-21 15:15:55,861 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:55,862 - ERROR - [test_019][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29838, Requested 1243. Please try again in 2.161s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_019] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:13<00:01,  1.19s/it][A[A[A[A[A2025-04-21 15:15:56,086 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_001] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:06<00:07,  1.38it/s][A[A[A[A2025-04-21 15:15:56,117 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:56,118 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:57,120 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:57,121 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:57,231 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:57,232 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:15:57,536 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_001] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:07<00:07,  1.15it/s][A[A[A[A2025-04-21 15:15:58,064 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:58,065 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:15:58,368 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:58,369 - ERROR - [test_001][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 28584, Requested 2087. Please try again in 1.342s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_001] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:08<00:06,  1.16it/s][A[A[A[A2025-04-21 15:15:58,482 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:58,483 - ERROR - [test_018][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29809, Requested 2159. Please try again in 3.936s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_018] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:18<00:10,  3.65s/it][A[A[A2025-04-21 15:15:58,593 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:58,594 - ERROR - [test_018][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29753, Requested 2550. Please try again in 4.605s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_018] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:18<00:05,  2.60s/it][A[A[A2025-04-21 15:15:58,654 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_001] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:08<00:05,  1.38it/s][A[A[A[A2025-04-21 15:15:59,210 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:15:59,211 - ERROR - [test_001][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29310, Requested 1718. Please try again in 2.056s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_001] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:09<00:04,  1.47it/s][A[A[A[A2025-04-21 15:16:00,157 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:00,158 - ERROR - [test_001][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 28837, Requested 1979. Please try again in 1.631s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_001] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:10<00:03,  1.33it/s][A[A[A[A2025-04-21 15:16:00,330 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:00,331 - ERROR - [test_001][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 28753, Requested 1867. Please try again in 1.24s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_001] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:10<00:02,  1.69it/s][A[A[A[A2025-04-21 15:16:16,658 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_055] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:36<00:07,  7.91s/it][A[A2025-04-21 15:16:18,576 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_001] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:28<00:16,  5.60s/it][A[A[A[A2025-04-21 15:16:19,895 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_019] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:37<00:00,  7.55s/it][A[A[A[A[A




                                                                         [A[A[A[A[A2025-04-21 15:16:19,914 - INFO - --- Art√≠culo test_019 completado ---
2025-04-21 15:16:19,914 - INFO - --- Procesando Art√≠culo: test_056 ---
2025-04-21 15:16:19,916 - INFO - [test_056] Lanzando 25 llamadas a Groq...





[test_056] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[A[AProgreso General Art√≠culos:  40%|‚ñà‚ñà‚ñà‚ñà      | 29/72 [03:00<08:38, 12.05s/it]2025-04-21 15:16:20,499 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_056] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:14,  1.71it/s][A[A[A[A[A2025-04-21 15:16:20,509 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:20,522 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:20,820 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:16:20,821 - ERROR - [test_056][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""A nadie vamos a dejar solo"",\n         "emisor_nombre": "Abinader",\n         "contexto": "Respuesta del presidente Abinader sobre el acompa√±amiento del Gobierno a las v√≠ctimas de la tragedia en la discoteca Jet Set",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""A nadie vamos a dejar solo. El Gobierno va a estar con ellos"",\n         "emisor_nombre": "Abinader",\n         "contexto": "Respuesta del presidente Abinader sobre el acompa√±amiento del Gobierno a las v√≠ctimas de la tragedia en la discoteca Jet Set",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Incluso los rescatistas tambi√©n, porque su impacto fue muy fuerte"",\n         "emisor_nombre": "Abinader",\n         "contexto": "Comentario del presidente Abinader sobre el impacto en los rescatistas",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""Me cubri√≥ con su cuerpo y por eso estoy viva"",\n         "emisor_nombre": "Maribel Espaillat",\n         "contexto": "Declaraci√≥n de la sobreviviente Maribel Espaillat sobre la tragedia en la discoteca Jet Set",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}





[test_056] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:00<00:04,  5.07it/s][A[A[A[A[A2025-04-21 15:16:20,978 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_056] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:03,  5.37it/s][A[A[A[A[A2025-04-21 15:16:21,040 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:21,178 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_056] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:02,  6.75it/s][A[A[A[A[A2025-04-21 15:16:21,273 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:21,329 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_056] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:01,  8.34it/s][A[A[A[A[A2025-04-21 15:16:21,354 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:21,450 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_056] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:01, 10.12it/s][A[A[A[A[A2025-04-21 15:16:21,515 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:21,517 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:21,538 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_055] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:41<00:00,  7.02s/it][A[A

                                                                         [A[A2025-04-21 15:16:21,551 - INFO - --- Art√≠culo test_055 completado ---
2025-04-21 15:16:21,551 - INFO - --- Procesando Art√≠culo: test_038 ---
2025-04-21 15:16:21,552 - INFO - [test_038] Lanzando 25 llamadas a Groq...


[test_038] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[AProgreso General Art√≠culos:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 30/72 [03:01<06:14,  8.93s/it]2025-04-21 15:16:21,609 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_056] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:01<00:00, 12.64it/s][A[A[A[A[A2025-04-21 15:16:22,160 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_038] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:14,  1.64it/s][A[A2025-04-21 15:16:22,249 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:22,308 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_038] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:07,  2.96it/s][A[A2025-04-21 15:16:22,385 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:22,386 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:22,523 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_038] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:00<00:02,  6.79it/s][A[A2025-04-21 15:16:22,548 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_001] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:32<00:10,  5.13s/it][A[A[A[A2025-04-21 15:16:22,597 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:22,753 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_038] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:02,  7.45it/s][A[A2025-04-21 15:16:22,808 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:22,820 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:22,844 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:22,887 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_056] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:02,  4.12it/s][A[A[A[A[A2025-04-21 15:16:22,952 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:23,014 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_056] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:03<00:01,  5.27it/s][A[A[A[A[A2025-04-21 15:16:23,049 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_038] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:01,  9.82it/s][A[A2025-04-21 15:16:23,101 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:23,310 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:23,318 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:23,321 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_038] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:01<00:01,  8.99it/s][A[A
[test_037] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:42<00:09,  9.46s/it][A2025-04-21 15:16:23,370 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:23,383 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:16:23,384 - ERROR - [test_038][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Lo dijimos una y otra vez, la autonom√≠a solo va a funcionar si empieza a implementarse de forma total; es con salud, educaci√≥n y seguridad descentralizadas (y entregadas) a las regiones y a los municipios, para que t√∫ sepas qui√©n le brinda salud, qui√©n educa a tus hijos(...) que no adoctrinen, que eduquen a los ni√±os"",\n         "emisor_nombre": "Jorge Quiroga",\n         "contexto": "Discurso de Quiroga durante la firma de la alianza Libre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""yo no soy millonario, pero soy rico, tengo tres t√≠tulos universitarios, esa es mi riqueza"",\n         "emisor_nombre": "Jorge Quiroga",\n         "contexto": "Discurso de Quiroga durante la firma de la alianza Libre",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""solo un debate p√∫blico de todos los candidatos permitir√° a la poblaci√≥n ver y escuchar las propuestas que tienen para el caso de que sean gobierno, y por eso insistir√° en que se realicen esos encuentros p√∫blicos entre postulantes a la presidencia"",\n         "emisor_nombre": "Jorge Quiroga",\n         "contexto": "Discurso de Quiroga durante la firma de la alianza Libre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}
2025-04-21 15:16:23,574 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_038] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:00,  9.87it/s][A[A2025-04-21 15:16:23,712 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:23,783 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_056] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:03<00:01,  4.04it/s][A[A[A[A[A2025-04-21 15:16:23,842 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:23,861 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_038] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:02<00:00,  8.90it/s][A[A2025-04-21 15:16:23,909 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_056] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:03<00:00,  5.18it/s][A[A[A[A[A2025-04-21 15:16:24,046 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_001] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:34<00:04,  4.07s/it][A[A[A[A2025-04-21 15:16:24,167 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:24,596 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_056] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:04<00:00,  4.21it/s][A[A[A[A[A2025-04-21 15:16:24,951 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_038] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:03<00:01,  3.75it/s][A[A2025-04-21 15:16:25,030 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_056] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:05<00:00,  3.68it/s][A[A[A[A[A




                                                                         [A[A[A[A[A2025-04-21 15:16:25,045 - INFO - --- Art√≠culo test_056 completado ---
2025-04-21 15:16:25,045 - INFO - --- Procesando Art√≠culo: test_020 ---
2025-04-21 15:16:25,046 - INFO - [test_020] Lanzando 25 llamadas a Groq...





[test_020] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[A[AProgreso General Art√≠culos:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 31/72 [03:05<04:59,  7.30s/it]2025-04-21 15:16:25,191 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_038] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:03<00:01,  3.82it/s][A[A2025-04-21 15:16:25,198 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:25,198 - INFO - Retrying request to /openai/v1/chat/completions in 18.000000 seconds
2025-04-21 15:16:25,204 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:25,205 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:16:25,209 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:25,210 - INFO - Retrying request to /openai/v1/chat/completions in 17.000000 seconds
2025-04-21 15:16:25,434 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:25,435 - INFO - Retrying request to /openai/v1/chat/completions in 17.000000 seconds
2025-04-21 15:16:25,513 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_020] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:11,  2.13it/s][A[A[A[A[A2025-04-21 15:16:25,570 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_038] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:04<00:01,  3.50it/s][A[A2025-04-21 15:16:25,685 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_020] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:06,  3.40it/s][A[A[A[A[A2025-04-21 15:16:25,785 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_020] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:04,  4.86it/s][A[A[A[A[A2025-04-21 15:16:26,012 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_020] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:00<00:04,  4.68it/s][A[A[A[A[A2025-04-21 15:16:26,097 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_038] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:04<00:01,  2.93it/s][A[A2025-04-21 15:16:26,176 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_020] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:03,  5.10it/s][A[A[A[A[A2025-04-21 15:16:26,376 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_020] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:03,  5.07it/s][A[A[A[A[A2025-04-21 15:16:26,557 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_020] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:03,  5.20it/s][A[A[A[A[A2025-04-21 15:16:26,795 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_020] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:03,  4.84it/s][A[A[A[A[A2025-04-21 15:16:26,820 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:26,834 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:26,872 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:27,016 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_038] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:05<00:00,  2.07it/s][A[A2025-04-21 15:16:27,415 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:16:27,416 - ERROR - [test_020][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Es un cap√≠tulo olvidado de nuestro pasado"",\n         "emisor_nombre": "Mar\\u00eda Due\\u00f1as",\n         "contexto": "Presentaci\\u00f3n de la novela de Mar\\u00eda Due\\u00f1as",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""Son\\u00f3 un cap\\u00edtulo olvidado de nuestro pasado"",\n         "emisor_nombre": "Mar\\u00eda Due\\u00f1as",\n         "contexto": "Presentaci\\u00f3n de la novela de Mar\\u00eda Due\\u00f1as",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""Delicada, sensible y emocionante historia decimon√≥nica sobre el destino y los secretos"",\n         "emisor_nombre": "Desconocido",\n         "contexto": "Rese\\u00f1a de la novela de Mar\\u00eda Reig",\n         "fecha_cita": null,\n         "relevancia_cita": 2\n      },\n      {\n         "cita": ""El arte de la guerra, de Sun Tzu, el venerable manual estrat\\u00e9gico que se leen con fruici\\u00f3n directivos, empresarios y profesionales del m\\u00e1rquetin y la comunicaci\\u00f3n"",\n         "emisor_nombre": "Carlos Bassas del Rey",\n         "contexto": "Presentaci\\u00f3n de la novela de Carlos Bassas del Rey",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Mordaz, ir\\u00f3nico y ambiguo, Flashman es un cobarde, un oportunista, un embustero, un racista y un agresor sexual de tomo y lomo, que, a pesar de todo, se convertir\\u00e1 en un h\\u00e9roe y en un militar condecorado"",\n         "emisor_nombre": "George Macdonald Fraser",\n         "contexto": "Presentaci\\u00f3n de la novela de George Macdonald Fraser",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Uno de nuestros autores ya m\\u00e1s cl\\u00e1sicos y reconocidos de la novela hist\\u00f3rica contempor\\u00e1nea espa\\u00f1ola, prosigue incansable su labor creativa y, en esta ocasi√≥n, se adentra en el reinado de Felipe II con una historia vibrante a ritmo de thriller sobre su reinado"",\n         "emisor_nombre": "Jos\\u00e9 Calvo Poyato",\n         "contexto": "Presentaci\\u00f3n de la novela de Jos\\u00e9 Calvo Poyato",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Novela de aventuras llena de acci\\u00f3n, Harffy arranca su historia con el ataque al monasterio de Lindisfarne, el inicio de la era vikinga, y convierte a un novicio, superviviente del mismo y que descubre que quiz\\u00a1 no es su momento para orar sino para combatir, en una historia que homenajea a los cl\\u00e1sicos encadenados de cine \'Los siete samur\\u00e1is\' y \'Los siete magn\\u00edficos\'"",\n         "emisor_nombre": "Matthew Harffy",\n         "contexto": "Presentaci\\u00f3n de la novela de Matthew Harffy",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}





[test_020] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:02,  5.77it/s][A[A[A[A[A2025-04-21 15:16:27,798 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 503 Service Unavailable"
2025-04-21 15:16:27,799 - ERROR - [test_038][extraccion_datos][gemma2-9b-it] Error final tras reintentos: InternalServerError: Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}


[test_038] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:06<00:00,  1.78it/s][A[A2025-04-21 15:16:27,858 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_020] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:02<00:02,  4.47it/s][A[A[A[A[A2025-04-21 15:16:27,903 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 503 Service Unavailable"
2025-04-21 15:16:27,904 - ERROR - [test_038][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: InternalServerError: Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}


[test_038] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:06<00:00,  2.29it/s][A[A

                                                                         [A[A2025-04-21 15:16:27,915 - INFO - --- Art√≠culo test_038 completado ---
2025-04-21 15:16:27,915 - INFO - --- Procesando Art√≠culo: test_002 ---
2025-04-21 15:16:27,917 - INFO - [test_002] Lanzando 25 llamadas a Groq...


[test_002] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[AProgreso General Art√≠culos:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 32/72 [03:08<03:58,  5.97s/it]2025-04-21 15:16:28,068 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:28,069 - INFO - Retrying request to /openai/v1/chat/completions in 19.000000 seconds
2025-04-21 15:16:28,091 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_020] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:03<00:02,  4.43it/s][A[A[A[A[A2025-04-21 15:16:28,149 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:28,150 - INFO - Retrying request to /openai/v1/chat/completions in 19.000000 seconds
2025-04-21 15:16:28,156 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:28,157 - INFO - Retrying request to /openai/v1/chat/completions in 18.000000 seconds
2025-04-21 15:16:28,162 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:28,163 - INFO - Retrying request to /openai/v1/chat/completions in 18.000000 seconds
2025-04-21 15:16:28,363 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_002] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:10,  2.24it/s][A[A2025-04-21 15:16:28,517 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_002] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:06,  3.64it/s][A[A2025-04-21 15:16:28,615 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:28,659 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_002] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:00<00:03,  6.79it/s][A[A2025-04-21 15:16:28,759 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:29,170 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:16:29,172 - ERROR - [test_018][extraccion_citas][gemma2-9b-it] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n  "resultados": [\n    {\n      "cita": "Vos te das cuenta de que ten√©s un Monumental vi√©ndote?",\n      "emisor_nombre": "Alejandro Fantino",\n      "contexto": "En alusi√≥n a la capacidad del estadio de River y a la cantidad de personas que los estaban escuchando.",\n      "fecha_cita": null,\n      "relevancia_cita": 3\n    },\n    {\n      "cita": "Es el d√≠a de la liberaci√≥n",\n      "emisor_nombre": "Javier Milei",\n      "contexto": "Celebrando la convocatoria y el fin de las restricciones para la compra de la moneda extranjera.",\n      "fecha_cita": null,\n      "relevancia_cita": 4\n    },\n    {\n      "cita": "La caracter√≠stica de esta salida del cepo es totalmente distinta a la experiencia del gobierno de (Mauricio) Macri, que hab√≠a expectativas. Ac√° estaba pulverizada la confianza",\n      "emisor_nombre": "Javier Milei",\n      "contexto": "Comparando la salida del cepo con la del gobierno de Macri.",\n      "fecha_cita": null,\n      "relevancia_cita": 4\n    },\n    {\n      "cita": "La dolarizaci√≥n es como una pizza: est√° la de jam√≥n y mozzarella, la de mozzarella, la primavera que tiene anan√°, la que tiene pepperoni... hay un mont√≥n de modelos de pizza, pod√©s hacerle de distintas maneras",\n      "emisor_nombre": "Javier Milei",\n      "contexto": "Explicando las diferentes formas de dolarizar.",\n      "fecha_cita": null,\n      "relevancia_cita": 3\n    },\n    {\n      "cita": "Los indicadores dicen que los tipos de cambio tienen que caer, los factores monetarios de Argentina llevan a eso",\n      "emisor_nombre": "Javier Milei",\n      "contexto": "Explicando su previsi√≥n de ca√≠da del tipo de cambio.",\n      "fecha_cita": null,\n      "relevancia_cita": 3\n    },\n    {\n      "cita": "Que agradezcan que Toto es muy contemplativo. Yo hubiera puesto la banda m√°s abajo para hacerles perder m√°s plata",\n      "emisor_nombre": "Javier Milei",\n      "contexto": "En referencia a quienes especularon con el precio del d√≥lar.",\n      "fecha_cita": null,\n      "relevancia_cita": 2\n    },\n    {\n      "cita": "Trump no lleg√≥ porque ten√≠a el helic√≥ptero roto",\n      "emisor_nombre": "Javier Milei",\n      "contexto": "Explicando la raz√≥n por la que la reuni√≥n con Trump no se concret√≥.",\n      "fecha_cita": null,\n      "relevancia_cita": 2\n    },\n    {\n      "cita": "Messi se defendi√≥ de esto, no le daba notas al periodismo por basuras mentirosas. ¬øD√≥nde est√° escrito que una basura ensobrada te puede golpear y no te pod√©s defender?",\n      "emisor_nombre": "Javier Milei",\n      "contexto": "Explicando por qu√© no se queda callado ante los ataques de la prensa.",\n      "fecha_cita": null,\n      "relevancia_cita": 3\n    },\n    {\n      "cita": "Nos correspond√≠a 35% m√°s las penalidades, por el ‚Äòmercasur‚Äô. Nos pusieron 10 a nosotros, generaba un desv√≠o de comercio, lo extendieron a todo el Mercosur y cuando vieron cu√°nto pesaba el Mercosur en Sudam√©rica dijeron ‚Äòles ponemos a todos 10‚Äù.\\n      "emisor_nombre": "Javier Milei",\\n      "contexto": "Explicando el porcentaje de aranceles que le aplicaron a Argentina.",\n      "fecha_cita": null,\n      "relevancia_cita": 3\n    },\n    {\n      "cita": "Mandril, decime qu√© se siente que el cepo lleg√≥ a su final. Te juro que aunque pasen los a√±os vos siempre vas a pifiar...",\n      "emisor_nombre": "Javier Milei",\n      "contexto": "Cantando una canci√≥n que se hizo viral.",\n      "fecha_cita": null,\n      "relevancia_cita": 2\n    },\n    {\n      "cita": "Ten√≠amos el tipo de cambio libre en torno a 1400 pesos y hoy se cay√≥ a 1195. Me causa gracia los que dicen que hab√≠a una devaluaci√≥n. Che, cuando se fue (Sergio) Massa el d√≥lar se fue a 1300 y hoy est√° en 1195. Qu√© devaluaci√≥n rara",\n      "emisor_nombre": "Javier Milei",\n      "contexto": "Reaccionando a las cr√≠ticas sobre la devaluaci√≥n.",\n      "fecha_cita": null,\n      "relevancia_cita": 3\n    },\n    {\n      "cita": "La base monetaria no crece, el resultado fiscal no me inyecta pesos, me saca pesos, con lo cual va a haber menos pesos. Se est√° recomponiendo la demanda de dinero. La verdad que seis puntos y medio del PBI es una pelotudez. La base monetaria deber√≠a duplicarse en condiciones normales",\n      "emisor_nombre": "Javier Milei",\n      "contexto": "Explicando su visi√≥n sobre la inflaci√≥n.",\n      "fecha_cita": null,\n      "relevancia_cita": 4\n    },\n    {\n      "cita": "Entonces inexorablemente en alg√∫n momento la inflaci√≥n va a colapsar. ¬øCu√°ndo? A mitad del a√±o que viene",\n      "emisor_nombre": "Javier Milei",\n      "contexto": "Prevision sobre el colapso de la inflaci√≥n.",\n      "fecha_cita": null,\n      "relevancia_cita": 4\n    }\n  ]\n}'}}



[test_018] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:49<00:10, 10.94s/it][A[A[A2025-04-21 15:16:29,211 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_002] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:03,  4.81it/s][A[A2025-04-21 15:16:29,247 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:29,307 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:29,417 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_020] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:04<00:04,  2.08it/s][A[A[A[A[A2025-04-21 15:16:29,445 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_002] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:02,  7.01it/s][A[A2025-04-21 15:16:29,544 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:29,608 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_002] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:01,  8.14it/s][A[A2025-04-21 15:16:29,681 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:29,889 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_002] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:01<00:01,  7.79it/s][A[A2025-04-21 15:16:29,943 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_020] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:04<00:04,  2.03it/s][A[A[A[A[A2025-04-21 15:16:30,026 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:30,089 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_002] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:02<00:01,  7.07it/s][A[A2025-04-21 15:16:30,264 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_002] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:02<00:01,  6.73it/s][A[A2025-04-21 15:16:30,317 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:30,338 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_020] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:05<00:02,  2.71it/s][A[A[A[A[A2025-04-21 15:16:30,650 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_018] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:50<00:00,  8.12s/it][A[A[A


                                                                         [A[A[A2025-04-21 15:16:30,665 - INFO - --- Art√≠culo test_018 completado ---
2025-04-21 15:16:30,665 - INFO - --- Procesando Art√≠culo: test_057 ---
2025-04-21 15:16:30,666 - INFO - [test_057] Lanzando 25 llamadas a Groq...



[test_057] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[AProgreso General Art√≠culos:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 33/72 [03:10<03:15,  5.00s/it]2025-04-21 15:16:30,772 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_020] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:05<00:02,  2.55it/s][A[A[A[A[A2025-04-21 15:16:30,814 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:30,814 - INFO - Retrying request to /openai/v1/chat/completions in 26.000000 seconds
2025-04-21 15:16:30,815 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:30,832 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:30,833 - INFO - Retrying request to /openai/v1/chat/completions in 26.000000 seconds
2025-04-21 15:16:30,839 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:30,839 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:16:30,898 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:30,898 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:16:30,907 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:30,908 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:16:30,931 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:30,932 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:16:30,940 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:30,941 - INFO - Retrying request to /openai/v1/chat/completions in 26.000000 seconds
2025-04-21 15:16:31,037 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:31,038 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:16:31,053 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_002] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:03<00:01,  4.16it/s][A[A2025-04-21 15:16:31,220 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:16:31,222 - ERROR - [test_020][extraccion_entidades][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "nombre": "Sun Tzu",\n         "tipo": "PERSONA",\n         "alias": ["Sun Tzu"],\n         "descripcion_contextual": "Autor del manual estrat√©gico \'El arte de la guerra\'",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Felipe II",\n         "tipo": "PERSONA",\n         "alias": ["Felipe II"],\n         "descripcion_contextual": "Rey de Espa√±a y Portugal",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Cristi√°n VII de Dinamarca",\n         "tipo": "PERSONA",\n         "alias": ["Cristi√°n VII de Dinamarca"],\n         "descripcion_contextual": "Rey de Dinamarca",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Mar√≠a Due√±as",\n         "tipo": "PERSONA",\n         "alias": ["Mar√≠a Due√±as"],\n         "descripcion_contextual": "Autora de novelas hist√≥ricas",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Carlos Bassas del Rey",\n         "tipo": "PERSONA",\n         "alias": ["Carlos Bassas del Rey"],\n         "descripcion_contextual": "Autor de novelas negro y de cultura asi√°tica",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Arnaldur Indridason",\n         "tipo": "PERSONA",\n         "alias": ["Arnaldur Indridason"],\n         "descripcion_contextual": "Autor island√©s de g√©nero negro",\n         "relevancia_articulo": 7\n      },\n      {\n         "nombre": "George Macdonald Fraser",\n         "tipo": "PERSONA",\n         "alias": ["George Macdonald Fraser"],\n         "descripcion_contextual": "Autor escoc√©s de literatura brit√°nica hist√≥rica",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Jos√© Calvo Poyato",\n         "tipo": "PERSONA",\n         "alias": ["Jos√© Calvo Poyato"],\n         "descripcion_contextual": "Autor de novelas hist√≥ricas contempor√°neas espa√±olas",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Matthew Harffy",\n         "tipo": "PERSONA",\n         "alias": ["Matthew Harffy"],\n         "descripcion_contextual": "Autor ingl√©s de novelas de aventuras",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Mar√≠a Reig",\n         "tipo": "PERSONA",\n         "alias": ["Mar√≠a Reig"],\n         "descripcion_contextual": "Autora de novelas hist√≥ricas",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Par√≠s",\n         "tipo": "LUGAR",\n         "alias": ["Par√≠s"],\n         "descripcion_contextual": "Ciudad en el siglo XIX",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "China",\n         "tipo": "LUGAR",\n         "alias": ["China"],\n         "descripcion_contextual": "Pa√≠s en el siglo VI a.C.",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Espa√±a",\n         "tipo": "LUGAR",\n         "alias": ["Espa√±a"],\n         "descripcion_contextual": "Pa√≠s en el reinado de Felipe II",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Portugal",\n         "tipo": "LUGAR",\n         "alias": ["Portugal"],\n         "descripcion_contextual": "Pa√≠s en el reinado de Felipe II",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Islandia",\n         "tipo": "LUGAR",\n         "alias": ["Islandia"],\n         "descripcion_contextual": "Pa√≠s en el siglo XVIII",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Dinamarca",\n         "tipo": "LUGAR",\n         "alias": ["Dinamarca"],\n         "descripcion_contextual": "Pa√≠s en el siglo XVIII",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Britania",\n         "tipo": "LUGAR",\n         "alias": ["Britania"],\n         "descripcion_contextual": "Pa√≠s en el siglo VIII",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Lindisfarne",\n         "tipo": "LUGAR",\n         "alias": ["Lindisfarne"],\n         "descripcion_contextual": "Monasterio en el siglo VIII",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Semana Santa",\n         "tipo": "EVENTO",\n         "alias": ["Semana Santa"],\n         "descripcion_contextual": "Vacaciones en Espa√±a",\n         "relevancia_articulo": 10\n      },\n      {\n         "nombre": "El arte de la guerra",\n         "tipo": "CONCEPTO",\n         "alias": ["El arte de la guerra"],\n         "descripcion_contextual": "Manual estrat√©gico de Sun Tzu",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El rey y el relojero",\n         "tipo": "CONCEPTO",\n         "alias": ["El rey y el relojero"],\n         "descripcion_contextual": "Novela de Arnaldur Indridason",\n         "relevancia_articulo": 7\n      },\n      {\n         "nombre": "Flashman",\n         "tipo": "CONCEPTO",\n         "alias": ["Flashman"],\n         "descripcion_contextual": "Personaje de George Macdonald Fraser",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Due√±os del Mundo",\n         "tipo": "CONCEPTO",\n         "alias": ["Due√±os del Mundo"],\n         "descripcion_contextual": "Novela de Jos√© Calvo Poyato",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Tiempo de espadas",\n         "tipo": "CONCEPTO",\n         "alias": ["Tiempo de espadas"],\n         "descripcion_contextual": "Novela de Matthew Harffy",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El nacimiento de un guerrero",\n         "tipo": "CONCEPTO",\n         "alias": ["El nacimiento de un guerrero"],\n         "descripcion_contextual": "Novela de Matthew Harffy",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El arte de la guerra",\n         "tipo": "NORMATIVA",\n         "alias": ["El arte de la guerra"],\n         "descripcion_contextual": "Manual estrat√©gico de Sun Tzu",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El rey y el relojero",\n         "tipo": "NORMATIVA",\n         "alias": ["El rey y el relojero"],\n         "descripcion_contextual": "Novela de Arnaldur Indridason",\n         "relevancia_articulo": 7\n      },\n      {\n         "nombre": "Flashman",\n         "tipo": "NORMATIVA",\n         "alias": ["Flashman"],\n         "descripcion_contextual": "Personaje de George Macdonald Fraser",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Due√±os del Mundo",\n         "tipo": "NORMATIVA",\n         "alias": ["Due√±os del Mundo"],\n         "descripcion_contextual": "Novela de Jos√© Calvo Poyato",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Tiempo de espadas",\n         "tipo": "NORMATIVA",\n         "alias": ["Tiempo de espadas"],\n         "descripcion_contextual": "Novela de Matthew Harffy",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El nacimiento de un guerrero",\n         "tipo": "NORMATIVA",\n         "alias": ["El nacimiento de un guerrero"],\n         "descripcion_contextual": "Novela de Matthew Harffy",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El arte de la guerra",\n         "tipo": "OTRO",\n         "alias": ["El arte de la guerra"],\n         "descripcion_contextual": "Manual estrat√©gico de Sun Tzu",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El rey y el relojero",\n         "tipo": "OTRO",\n         "alias": ["El rey y el relojero"],\n         "descripcion_contextual": "Novela de Arnaldur Indridason",\n         "relevancia_articulo": 7\n      },\n      {\n         "nombre": "Flashman",\n         "tipo": "OTRO",\n         "alias": ["Flashman"],\n         "descripcion_contextual": "Personaje de George Macdonald Fraser",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Due√±os del Mundo",\n         "tipo": "OTRO",\n         "alias": ["Due√±os del Mundo"],\n         "descripcion_contextual": "Novela de Jos√© Calvo Poyato",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Tiempo de espadas",\n         "tipo": "OTRO",\n         "alias": ["Tiempo de espadas"],\n         "descripcion_contextual": "Novela de Matthew Harffy",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El nacimiento de un guerrero",\n         "tipo": "OTRO",\n         "alias": ["El nacimiento de un guerrero"],\n         "descripcion_contextual": "Novela de Matthew Harffy",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El arte de la guerra",\n         "tipo": "CONCEPTO",\n         "alias": ["El arte de la guerra"],\n         "descripcion_contextual": "Manual estrat√©gico de Sun Tzu",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El rey y el relojero",\n         "tipo": "CONCEPTO",\n         "alias": ["El rey y el relojero"],\n         "descripcion_contextual": "Novela de Arnaldur Indridason",\n         "relevancia_articulo": 7\n      },\n      {\n         "nombre": "Flashman",\n         "tipo": "CONCEPTO",\n         "alias": ["Flashman"],\n         "descripcion_contextual": "Personaje de George Macdonald Fraser",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Due√±os del Mundo",\n         "tipo": "CONCEPTO",\n         "alias": ["Due√±os del Mundo"],\n         "descripcion_contextual": "Novela de Jos√© Calvo Poyato",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Tiempo de espadas",\n         "tipo": "CONCEPTO",\n         "alias": ["Tiempo de espadas"],\n         "descripcion_contextual": "Novela de Matthew Harffy",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El nacimiento de un guerrero",\n         "tipo": "CONCEPTO",\n         "alias": ["El nacimiento de un guerrero"],\n         "descripcion_contextual": "Novela de Matthew Harffy",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El arte de la guerra",\n         "tipo": "OTRO",\n         "alias": ["El arte de la guerra"],\n         "descripcion_contextual": "Manual estrat√©gico de Sun Tzu",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El rey y el relojero",\n         "tipo": "OTRO",\n         "alias": ["El rey y el relojero"],\n         "descripcion_contextual": "Novela de Arnaldur Indridason",\n         "relevancia_articulo": 7\n      },\n      {\n         "nombre": "Flashman",\n         "tipo": "OTRO",\n         "alias": ["Flashman"],\n         "descripcion_contextual": "Personaje de George Macdonald Fraser",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Due√±os del Mundo",\n         "tipo": "OTRO",\n         "alias": ["Due√±os del Mundo"],\n         "descripcion_contextual": "Novela de Jos√© Calvo Poyato",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Tiempo de espadas",\n         "tipo": "OTRO",\n         "alias": ["Tiempo de espadas"],\n         "descripcion_contextual": "Novela de Matthew Harffy",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El nacimiento de un guerrero",\n         "tipo": "OTRO",\n         "alias": ["El nacimiento de un guerrero"],\n         "descripcion_contextual": "Novela de Matthew Harffy",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El arte de la guerra",\n         "tipo": "CONCEPTO",\n         "alias": ["El arte de la guerra"],\n         "descripcion_contextual": "Manual estrat√©gico de Sun Tzu",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El rey y el relojero",\n         "tipo": "CONCEPTO",\n         "alias": ["El rey y el relojero"],\n         "descripcion_contextual": "Novela de Arnaldur Indridason",\n         "relevancia_articulo": 7\n      },\n      {\n         "nombre": "Flashman",\n         "tipo": "CONCEPTO",\n         "alias": ["Flashman"],\n         "descripcion_contextual": "Personaje de George Macdonald Fraser",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Due√±os del Mundo",\n         "tipo": "CONCEPTO",\n         "alias": ["Due√±os del Mundo"],\n         "descripcion_contextual": "Novela de Jos√© Calvo Poyato",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Tiempo de espadas",\n         "tipo": "CONCEPTO",\n         "alias": ["Tiempo de espadas"],\n         "descripcion_contextual": "Novela de Matthew Harffy",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El nacimiento de un guerrero",\n         "tipo": "CONCEPTO",\n         "alias": ["El nacimiento de un guerrero"],\n         "descripcion_contextual": "Novela de Matthew Harffy",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El arte de la guerra",\n         "tipo": "OTRO",\n         "alias": ["El arte de la guerra"],\n         "descripcion_contextual": "Manual estrat√©gico de Sun Tzu",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El rey y el relojero",\n         "tipo": "OTRO",\n         "alias": ["El rey y el relojero"],\n         "descripcion_contextual": "Novela de Arnaldur Indridason",\n         "relevancia_articulo": 7\n      },\n      {\n         "nombre": "Flashman",\n         "tipo": "OTRO",\n         "alias": ["Flashman"],\n         "descripcion_contextual": "Personaje de George Macdonald Fraser",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Due√±os del Mundo",\n         "tipo": "OTRO",\n         "alias": ["Due√±os del Mundo"],\n         "descripcion_contextual": "Novela de Jos√© Calvo Poyato",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Tiempo de espadas",\n         "tipo": "OTRO",\n         "alias": ["Tiempo de espadas"],\n         "descripcion_contextual": "Novela de Matthew Harffy",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El nacimiento de un guerrero",\n         "tipo": "OTRO",\n         "alias": ["El nacimiento de un guerrero"],\n         "descripcion_contextual": "Novela de Matthew Harffy",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El arte de la guerra",\n         "tipo": "CONCEPTO",\n         "alias": ["El arte de la guerra"],\n         "descripcion_contextual": "Manual estrat√©gico de Sun Tzu",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "El rey y el relojero",\n         "tipo": "CONCEPTO",\n         "alias": ["El rey y el relojero"],\n         "descripcion_contextual": "Novela de Arnaldur Indridason",\n         "relevancia_articulo": 7\n      },\n      {\n         "nombre": "Flashman",\n         "tipo": "CONCEPTO",\n         "alias": ["Flashman"],\n         "descripcion_contextual": "Personaje de George Macdonald Fraser",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Due√±os del Mundo",\n         "tipo": "CONCEPTO",\n         "alias": ["Due√±os del Mundo"],\n         "descripcion_contextual": "Novela de Jos√© Calvo Poyato",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Tiempo de espadas",\n         "tipo": "CONCEPTO",\n         "alias": ["Tiempo de espadas"],\n         "descripcion_contextual": "Novela de Matthew Harffy",\n         "relevancia_articulo": 6\n      }}'}}





[test_020] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:06<00:01,  3.13it/s][A[A[A[A[A2025-04-21 15:16:31,482 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_057] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:19,  1.22it/s][A[A[A2025-04-21 15:16:31,536 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:31,637 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_057] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:05,  3.71it/s][A[A[A2025-04-21 15:16:31,645 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:16:31,646 - ERROR - [test_001][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n  "resultados": [\n    {\n      "contenido": "El senador Pedro Tineo present√≥ un proyecto de ley para crear el Sistema Nacional de Supervisi√≥n y Certificaci√≥n de Obras P√∫blicas y Privadas.",\n      "tipo_hecho": "ANUNCIO",\n      "fecha_ocurrencia_inicio": "2025-04-14T00:00:00+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "exacta",\n      "paises": [\n        "DO"\n      ],\n      "ubicaciones_especificas": [\n        "Monte Plata",\n        "Rep√∫blica Dominicana"\n      ],\n      "importancia": 8,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "ley",\n        "obras",\n        "supervision",\n        "certificacion",\n        "construccion",\n        "Rep√∫blica Dominicana"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "El proyecto de ley busca crear un mecanismo de evaluaci√≥n peri√≥dica, certificaci√≥n t√©cnica y prevenci√≥n de riesgos estructurales para obras p√∫blicas y privadas.",\n      "tipo_hecho": "CONCEPTO",\n      "fecha_ocurrencia_inicio": "2025-04-14T00:00:00+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "exacta",\n      "paises": [\n        "DO"\n      ],\n      "ubicaciones_especificas": [],\n      "importancia": 7,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "supervision",\n        "certificacion",\n        "riesgos",\n        "estructurales",\n        "obras",\n        "publicas",\n        "privadas"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "La ley se aplicar√≠a a todas las edificaciones e infraestructuras, tanto p√∫blicas como privadas, cuya construcci√≥n haya sido concluida diez (10) a√±os antes de la entrada en vigencia de esta ley en todo territorio nacional o que cumplan ese plazo posteriormente.",\n      "tipo_hecho": "NORMATIVA",\n      "fecha_ocurrencia_inicio": "2025-04-14T00:00:00+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "exacta",\n      "paises": [\n        "DO"\n      ],\n      "ubicaciones_especificas": [],\n      "importancia": 6,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "ley",\n        "aplicacion",\n        "edificaciones",\n        "infraestructuras",\n        "publicas",\n        "privadas"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "El Sistema Nacional de Supervisi√≥n se regir√° por los principios de seguridad estructural, la protecci√≥n de la vida humana, transparencia y rendici√≥n de cuentas, desarrollo sostenible, participaci√≥n ciudadana y respeto a los derechos de propiedad y uso del suelo.",\n      "tipo_hecho": "CONCEPTO",\n      "fecha_ocurrencia_inicio": "2025-04-14T00:00:00+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "exacta",\n      "paises": [\n        "DO"\n      ],\n      "ubicaciones_especificas": [],\n      "importancia": 7,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "principios",\n        "seguridad",\n        "transparencia",\n        "rendicion",\n        "cuentas",\n        "desarrollo",\n        "participacion",\n        "ciudadana"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "El proyecto de ley crea la Direcci√≥n Ejecutiva del Sistema Nacional de Supervisi√≥n y Certificaci√≥n de Obras P√∫blicas y Privadas (Sinasco) como √≥rgano t√©cnico-operativo encargado de ejecutar las funciones administrativas, t√©cnicas, de supervisi√≥n y certificaci√≥n del Sistema.",\n      "tipo_hecho": "ANUNCIO",\n      "fecha_ocurrencia_inicio": "2025-04-14T00:00:00+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "exacta",\n      "paises": [\n        "DO"\n      ],\n      "ubicaciones_especificas": [],\n      "importancia": 7,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "direccion",\n        "sinasco",\n        "supervision",\n        "certificacion",\n        "obras",\n        "publicas",\n        "privadas"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "El Sinasco ser√° una dependencia descentralizada funcionalmente, adscrita al Ministerio de Obras P√∫blicas y Comunicaciones (MOPC), con autonom√≠a t√©cnica, presupuestaria y de gesti√≥n, conforme a las disposiciones de la Ley N√∫m. 247-12, Org√°nica de la Administraci√≥n P√∫blica.",\n      "tipo_hecho": "NORMATIVA",\n      "fecha_ocurrencia_inicio": "2025-04-14T00:00:00+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "exacta",\n      "paises": [\n        "DO"\n      ],\n      "ubicaciones_especificas": [],\n      "importancia": 6,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "dependencia",\n        "mopc",\n        "autonomia",\n        "administrativa",\n        "ley",\n        "247-12"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "El art√≠culo 12 del proyecto de ley crea el certificado de condici√≥n estructural, que establece que luego de la inspecci√≥n, el Sinasco emitir√° un certificado de condici√≥n estructural, con validez de dos a√±os, renovable mediante nueva inspecci√≥n, el cual deber√° ser exhibido de manera visible en edificaciones p√∫blicas, privadas de acceso colectivo, y estar√° disponible en la base de datos del Sistema, podr√° ser validado a trav√©s de un c√≥digo asignado.",\n      "tipo_hecho": "NORMATIVA",\n      "fecha_ocurrencia_inicio": "2025-04-14T00:00:00+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "exacta",\n      "paises": [\n        "DO"\n      ],\n      "ubicaciones_especificas": [],\n      "importancia": 6,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "certificado",\n        "condicion",\n        "estructural",\n        "sinasco",\n        "validacion",\n        "codigo"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "El art√≠culo 14 del proyecto de ley establece que las obras comprendidas en esta ley deber√°n ser inspeccionadas cada dos (2) a√±os a partir de la fecha de su primera evaluaci√≥n. El MOPC podr√° establecer frecuencias menores en caso de zonas vulnerables o edificaciones de alto riesgo.",\n      "tipo_hecho": "NORMATIVA",\n      "fecha_ocurrencia_inicio": "2025-04-14T00:00:00+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "exacta",\n      "paises": [\n        "DO"\n      ],\n      "ubicaciones_especificas": [],\n      "importancia": 6,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "inspeccion",\n        "frecuencia",\n        "mopc",\n        "zonas",\n        "vulnerables",\n        "edificaciones",\n        "alto",\n        "riesgo"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "El art√≠culo 15 del proyecto de ley establece que el Sinasco podr√° ordenar inspecciones extraordinarias en zonas vulnerables a fen√≥menos s√≠smicos, deslizamientos o impactos ambientales, o ante denuncias debidamente fundamentadas.",\n      "tipo_hecho": "NORMATIVA",\n      "fecha_ocurrencia_inicio": "2025-04-14T00:00:00+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "exacta",\n      "paises": [\n        "DO"\n      ],\n      "ubicaciones_especificas": [],\n      "importancia": 6,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "inspeccion",\n        "extraordinaria",\n        "zonas",\n        "vulnerables",\n        "sinasco",\n        "denuncias"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "El art√≠culo 21 del proyecto de ley establece la responsabilidad del propietario o administrador, al indicar que toda persona f√≠sica o jur√≠dica propietaria, arrendataria o administradora de una edificaci√≥n comprendida en esta ley deber√° facilitar el acceso para inspecci√≥n, acoger las recomendaciones emitidas y realizar las correcciones que se le indiquen.",\n      "tipo_hecho": "NORMATIVA",\n      "fecha_ocurrencia_inicio": "2025-04-14T00:00:00+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "exacta",\n      "paises": [\n        "DO"\n      ],\n      "ubicaciones_especificas": [],\n      "importancia": 6,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "responsabilidad",\n        "propietario",\n        "administrador",\n        "inspeccion",\n        "recomendaciones",\n        "correcciones"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "El art√≠culo 22 del proyecto de ley establece el r√©gimen de los servidores p√∫blicos, el cual precisa que los funcionarios o servidores asignados para realizar las evaluaciones t√©cnicas, informes o certificaciones deber√°n actuar con responsabilidad y √©tica profesional. En caso de negligencia, omisi√≥n o falsificaci√≥n de informes, estar√°n sujetos al r√©gimen disciplinario establecido en la Ley n√∫m. 41-08 de Funci√≥n P√∫blica y dem√°s normas aplicables. Adem√°s, a sanciones administrativas, civiles y penales, seg√∫n corresponda.",\n      "tipo_hecho": "NORMATIVA",\n      "fecha_ocurrencia_inicio": "2025-04-14T00:00:00+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "exacta",\n      "paises": [\n        "DO"\n      ],\n      "ubicaciones_especificas": [],\n      "importancia": 6,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "funcionarios",\n        "evaluaciones",\n        "informes",\n        "certificaciones",\n        "responsabilidad",\n        "sanciones",\n        "administrativas",\n        "civiles",\n        "penales"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "El art√≠culo 23 del proyecto de ley establece que constituye falta grave negarse a permitir la inspecci√≥n; ocultar informaci√≥n relevante durante el proceso de supervisi√≥n; no cumplir las recomendaciones emitidas por el Sinasco; falsificar certificados o informes t√©cnicos y exponer a terceros al uso de estructuras clasificadas como inhabilitadas.",\n      "tipo_hecho": "NORMATIVA",\n      "fecha_ocurrencia_inicio": "2025-04-14T00:00:00+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "exacta",\n      "paises": [\n        "DO"\n      ],\n      "ubicaciones_especificas": [],\n      "importancia": 6,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "falta",\n        "inspeccion",\n        "informacion",\n        "recomendaciones",\n        "certificados",\n        "informes",\n        "tecnicos",\n        "estructuras",\n        "inhabilitadas"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "El proyecto de ley establece multas administrativas desde cincuenta hasta mil salarios m√≠nimos del sector p√∫blico; clausura temporal o definitiva de la edificaci√≥n; suspensi√≥n de licencias de operaci√≥n y remisi√≥n al Ministerio P√∫blico en casos de dolo o negligencia temeraria.",\n      "tipo_hecho": "NORMATIVA",\n      "fecha_ocurrencia_inicio": "2025-04-14T00:00:00+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "exacta",\n      "paises": [\n        "DO"\n      ],\n      "ubicaciones_especificas": [],\n      "importancia": 6,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "multas",\n        "clausura",\n        "licencias",\n        "ministerio",\n        "public"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "Rep√∫blica Dominicana se encuentra geogr√°ficamente situada en una zona de alta exposici√≥n a fen√≥menos naturales, tales como huracanes, tormentas tropicales y movimientos tel√∫ricos, debido a su ubicaci√≥n en el trayecto habitual de fen√≥menos atmosf√©ricos del Caribe y su proximidad a fallas tect√≥nicas activas.",\n      "tipo_hecho": "CONCEPTO",\n      "fecha_ocurrencia_inicio": "2025-04-14T00:00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "exacta",\n      "paises": [\n        "DO"\n      "ubicaciones_especificas": [],\n      "importancia": 8,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "fen√≥menos",\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    }\n  ]\n  }'}}




[test_001] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:41<00:00,  5.11s/it][A[A[A[A



                                                                         [A[A[A[A2025-04-21 15:16:31,660 - INFO - --- Art√≠culo test_001 completado ---
2025-04-21 15:16:31,660 - INFO - --- Procesando Art√≠culo: test_039 ---
2025-04-21 15:16:31,664 - INFO - [test_039] Lanzando 25 llamadas a Groq...




[test_039] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[AProgreso General Art√≠culos:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 34/72 [03:11<02:24,  3.80s/it]2025-04-21 15:16:31,723 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:31,726 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_020] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:06<00:01,  2.77it/s][A[A[A[A[A2025-04-21 15:16:31,818 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_057] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:03,  5.59it/s][A[A[A2025-04-21 15:16:31,909 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:31,910 - INFO - Retrying request to /openai/v1/chat/completions in 26.000000 seconds
2025-04-21 15:16:31,932 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:31,933 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:16:32,013 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:32,015 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:32,016 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"



[test_057] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:03,  5.49it/s][A[A[A2025-04-21 15:16:32,017 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:16:32,018 - ERROR - [test_037][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n  "resultados": [\n    {\n      "contenido": "El gobierno de Hait√≠ aprob√≥ un presupuesto especial de 275.000 d√≥lares para combatir la violencia de pandillas.",\n      "tipo_hecho": "ANUNCIO",\n      "fecha_ocurrencia_inicio": "2025-04-15T00:16:47.612000+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "exacta",\n      "paises": [\n        "HT"\n      ],\n      "ubicaciones_especificas": [],\n      "importancia": 10,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "haiti",\n        "pandillas",\n        "violencia",\n        "presupuesto",\n        "seguridad"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "Aproximadamente el 40% del presupuesto se destinar√° a la polic√≠a y al ej√©rcito de Hait√≠ para combatir a los grupos armados.",\n      "tipo_hecho": "SUCESO",\n      "fecha_ocurrencia_inicio": "2025-04-15T00:16:47.612000+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "exacta",\n      "paises": [\n        "HT"\n      ],\n      "ubicaciones_especificas": [],\n      "importancia": 8,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "haiti",\n        "policia",\n        "ej√©rcito",\n        "pandillas",\n        "seguridad"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "El 20% restante del presupuesto se destinar√° a fortalecer la frontera que Hait√≠ comparte con la Rep√∫blica Dominicana.",\n      "tipo_hecho": "SUCESO",\n      "fecha_ocurrencia_inicio": "2025-04-15T00:16:47.612000+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "exacta",\n      "paises": [\n        "HT",\n        "DO"\n      ],\n      "ubicaciones_especificas": [],\n      "importancia": 7,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "haiti",\n        "frontera",\n        "republica dominicana",\n        "seguridad"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "El 16% restante del presupuesto se destinar√° a programas sociales, incluyendo educaci√≥n, salud y asistencia humanitaria.",\n      "tipo_hecho": "SUCESO",\n      "fecha_ocurrencia_inicio": "2025-04-15T00:16:47.612000+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "exacta",\n      "paises": [\n        "HT"\n      ],\n      "ubicaciones_especificas": [],\n      "importancia": 6,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "haiti",\n        "programas sociales",\n        "educacion",\n        "salud",\n        "asistencia humanitaria"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "Las pandillas controlan al menos el 85% de la capital, Puerto Pr√≠ncipe.",\n      "tipo_hecho": "SUCESO",\n      "fecha_ocurrencia_inicio": "2025-04-15T00:16:47.612000+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "exacta",\n      "paises": [\n        "HT"\n      ],\n      "ubicaciones_especificas": [\n        "Puerto Pr√≠ncipe"\n      ],\n      "importancia": 9,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "haiti",\n        "pandillas",\n        "puerto principe",\n        "violencia"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "Recientemente, una poderosa coalici√≥n de pandillas conocida como Viv Ansanm tom√≥ el control de las localidades de Mirebalais y Saut‚Äôd‚ÄôEau.",\n      "tipo_hecho": "SUCESO",\n      "fecha_ocurrencia_inicio": "2025-04-15T00:16:47.612000+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "semana",\n      "paises": [\n        "HT"\n      ],\n      "ubicaciones_especificas": [\n        "Mirebalais",\n        "Saut‚Äôd‚ÄôEau"\n      ],\n      "importancia": 8,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "haiti",\n        "pandillas",\n        "mirebalais",\n        "saut\'d\'eau",\n        "violencia"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "Durante los ataques en Mirebalais, agentes de polic√≠a de la comisar√≠a local y de la prisi√≥n huyeron.",\n      "tipo_hecho": "SUCESO",\n      "fecha_ocurrencia_inicio": "2025-04-15T00:16:47.612000+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "semana",\n      "paises": [\n        "HT"\n      ],\n      "ubicaciones_especificas": [\n        "Mirebalais"\n      ],\n      "importancia": 7,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "haiti",\n        "pandillas",\n        "mirebalais",\n        "policia",\n        "violencia"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "Bandas armadas incendiaron la comisar√≠a y tomaron el control de la prisi√≥n de Mirebalais, orquestando una fuga masiva de reclusos.",\n      "tipo_hecho": "SUCESO",\n      "fecha_ocurrencia_inicio": "2025-04-15T00:16:47.612000+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "semana",\n      "paises": [\n        "HT"\n      ],\n      "ubicaciones_especificas": [\n        "Mirebalais"\n      ],\n      "importancia": 8,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "haiti",\n        "pandillas",\n        "mirebalais",\n        "prision",\n        "violencia"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "Al menos 60 personas murieron durante los ataques en Mirebalais y Saut‚Äôd‚ÄôEau, incluyendo pandilleros y reclusos fugados.",\n      "tipo_hecho": "SUCESO",\n      "fecha_ocurrencia_inicio": "2023-03-30T00:00:00+00:00",\n      "fecha_ocurrencia_fin": "2023-03-31T00:00:00+00:00",\n      "precision_temporal": "exacta",\n      "paises": [\n        "HT"\n      ],\n      "ubicaciones_especificas": [\n        "Mirebalais",\n        "Saut‚Äôd‚ÄôEau"\n      ],\n      "importancia": 9,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "haiti",\n        "pandillas",\n        "mirebalais",\n        "saut\'d\'eau",\n        "violencia",\n        "muertes"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "El personal y los pacientes del Hospital Universitario Mirebalais tambi√©n fueron evacuados durante los ataques.",\n      "tipo_hecho": "SUCESO",\n      "fecha_ocurrencia_inicio": "2023-03-30T00:00:00+00:00",\n      "fecha_ocurrencia_fin": "2023-03-31T00:00:00+00:00",\n      "precision_temporal": "exacta",\n      "paises": [\n        "HT"\n      ],\n      "ubicaciones_especificas": [\n        "Mirebalais"\n      ],\n      "importancia": 7,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "haiti",\n        "pandillas",\n        "mirebalais",\n        "hospital",\n        "violencia"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "Dos monjas y un polic√≠a murieron durante los ataques, mientras que dos periodistas siguen desaparecidos.",\n      "tipo_hecho": "SUCESO",\n      "fecha_ocurrencia_inicio": "2023-03-30T00:00:00+00:00",\n      "fecha_ocurrencia_fin": "2023-03-31T00:00:00+00:00",\n      "precision_temporal": "exacta",\n      "paises": [\n        "HT"\n      ],\n      "ubicaciones_especificas": [],\n      "importancia": 8,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "haiti",\n        "pandillas",\n        "violencia",\n        "muertes",\n        "desaparecidos"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "La misi√≥n pol√≠tica de la ONU en Hait√≠ cuestion√≥ la demora en la respuesta de las autoridades a los ataques de pandillas en Kenscoff y Carrefour a fines de enero.",\n      "tipo_hecho": "SUCESO",\n      "fecha_ocurrencia_inicio": "2023-01-31T00:00:00+00:00",\n      "fecha_ocurrencia_fin": null,\n      "precision_temporal": "mes",\n      "paises": [\n        "HT"\n      ],\n      "ubicaciones_especificas": [\n        "Kenscoff",\n        "Carrefour"\n      ],\n      "importancia": 7,\n      "confiabilidad": 4,\n      "etiquetas": [\n        "haiti",\n        "pandillas",\n        "onu",\n        "violencia",\n        "respuesta"\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    },\n    {\n      "contenido": "M√°s de 1500 personas murieron en Hait√≠ y otras 572 resultaron heridas entre el 1 de enero y el 27 de marzo.",\n      "tipo_hecho": "SUCESO",\n      "fecha_ocurrencia_inicio": "2023-01-01T00:00:00+00:00",\n      "fecha_ocurrencia_fin": "2023-03-27T00:00:00+00:00",\n      "precision_temporal": "mes",\n      "paises": [\n        "HT"\n      ],\n      "ubicaciones_especificas": [],\n      "importancia": 9,\n      "confiabilidad": 5,\n      "etiquetas": [\n        "haiti",\n        "violencia",\n      ],\n      "es_evento_futuro": false,\n      "estado_programacion": null\n    }\n  ]\n}'}}
2025-04-21 15:16:32,019 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[test_037] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:51<00:00,  9.24s/it][A
                                                                         [A2025-04-21 15:16:32,030 - INFO - --- Art√≠culo test_037 completado ---
2025-04-21 15:16:32,030 - INFO - Retrying request to /openai/v1/chat/completions in 26.000000 seconds
2025-04-21 15:16:32,030 - INFO - --- Procesando Art√≠culo: test_021 ---
2025-04-21 15:16:32,031 - INFO - [test_021] Lanzando 25 llamadas a Groq...

[test_021] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][AProgreso General Art√≠culos:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 35/72 [03:12<01:42,  2.77s/it]2025-04-21 15:16:32,138 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:32,140 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:32,143 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:32,146 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:16:32,148 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds



[test_057] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:03,  5.93it/s][A[A[A2025-04-21 15:16:32,323 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:32,323 - INFO - Retrying request to /openai/v1/chat/completions in 24.000000 seconds
2025-04-21 15:16:32,342 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:32,343 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:16:32,344 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:32,345 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:32,346 - INFO - Retrying request to /openai/v1/chat/completions in 25.000000 seconds
2025-04-21 15:16:32,348 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:32,349 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"



[test_057] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:03,  5.64it/s][A[A[A2025-04-21 15:16:32,349 - INFO - Retrying request to /openai/v1/chat/completions in 25.000000 seconds
2025-04-21 15:16:32,350 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:16:32,350 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_039] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:16,  1.45it/s][A[A[A[A2025-04-21 15:16:32,356 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:32,356 - INFO - Retrying request to /openai/v1/chat/completions in 25.000000 seconds
2025-04-21 15:16:32,357 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:32,358 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:16:32,372 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:16:32,373 - ERROR - [test_057][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""En la CELAC todos fingen que no pasa nada. As√≠ no se construye esa integraci√≥n de la que hablan"",\n         "emisor_nombre": "Salvador Nasralla",\n         "contexto": "Comentarios sobre la CELAC y su inefectividad",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Definitivamente es un mar de incoherencias lleno de pira√±as alcahuetas"",\n         "emisor_nombre": "Salvador Nasralla",\n         "contexto": "Comentarios sobre la CELAC y su inefectividad",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lo m√°s grave es su silencio c√≥mplice ante el drama de Venezuela. En la CELAC todos fingen que no pasa nada. As√≠ no se construye esa..."",\n         "emisor_nombre": "Salvador Nasralla",\n         "contexto": "Comentarios sobre la CELAC y su inefectividad",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Es incre√≠ble que todos estos pa√≠ses, ante una tragedia may√∫scula como la que vive Venezuela, hagan ol√≠mpicamente como que no pasa absolutamente nada"",\n         "emisor_nombre": "Washington Abdala",\n         "contexto": "Comentarios sobre la falta de voluntad pol√≠tica de la CELAC para condenar la situaci√≥n en Venezuela",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Definitivamente es un mar de incoherencias lleno de pira√±as alcahuetas"",\n         "emisor_nombre": "Salvador Nasralla",\n         "contexto": "Comentarios sobre la CELAC y su inefectividad",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lo m√°s grave es su silencio c√≥mplice ante el drama de Venezuela. En la CELAC todos fingen que no pasa nada. As√≠ no se construye esa..."",\n         "emisor_nombre": "Salvador Nasralla",\n         "contexto": "Comentarios sobre la CELAC y su inefectividad",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""En la CELAC todos fingen que no pasa nada. As√≠ no se construye esa integraci√≥n de la que hablan"",\n         "emisor_nombre": "Salvador Nasralla",\n         "contexto": "Comentarios sobre la CELAC y su inefectividad",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Definitivamente es un mar de incoherencias lleno de pira√±as alcahuetas"",\n         "emisor_nombre": "Salvador Nasralla",\n         "contexto": "Comentarios sobre la CELAC y su inefectividad",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Es incre√≠ble que todos estos pa√≠ses, ante una tragedia may√∫scula como la que vive Venezuela, hagan ol√≠mpicamente como que no pasa absolutamente nada"",\n         "emisor_nombre": "Washington Abdala",\n         "contexto": "Comentarios sobre la falta de voluntad pol√≠tica de la CELAC para condenar la situaci√≥n en Venezuela",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}
2025-04-21 15:16:32,374 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:32,388 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:32,443 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:32,444 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:16:32,489 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_057] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:01,  9.45it/s][A[A[A2025-04-21 15:16:32,502 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_002] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:04<00:03,  2.02it/s][A[A2025-04-21 15:16:32,538 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_039] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:05,  4.03it/s][A[A[A[A2025-04-21 15:16:32,550 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:32,560 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:32,701 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_021] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:16,  1.49it/s][A2025-04-21 15:16:32,771 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_039] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:05,  4.12it/s][A[A[A[A2025-04-21 15:16:32,895 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:32,896 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:16:32,939 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_021] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:09,  2.40it/s][A2025-04-21 15:16:32,981 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_039] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:04,  4.31it/s][A[A[A[A2025-04-21 15:16:33,024 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:33,167 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_039] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:02,  6.09it/s][A[A[A[A2025-04-21 15:16:33,178 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:33,208 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:33,288 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_039] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01,  9.88it/s][A[A[A[A2025-04-21 15:16:33,418 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_021] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:01<00:09,  2.25it/s][A2025-04-21 15:16:33,424 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_057] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:02<00:02,  4.35it/s][A[A[A2025-04-21 15:16:33,450 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:33,476 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:33,504 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_039] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:01<00:01,  9.67it/s][A[A[A[A2025-04-21 15:16:33,559 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_057] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:02<00:02,  4.73it/s][A[A[A2025-04-21 15:16:33,588 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_021] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:04,  4.14it/s][A2025-04-21 15:16:33,615 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:33,622 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:33,693 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_057] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:03<00:01,  5.15it/s][A[A[A2025-04-21 15:16:33,787 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_021] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  6.88it/s][A2025-04-21 15:16:33,831 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:33,858 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_039] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:02<00:01,  7.89it/s][A[A[A[A2025-04-21 15:16:33,886 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:16:33,888 - ERROR - [test_002][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Desde entonces hemos tenido en el centro de nuestro horizonte estrat√©gico y en el quehacer pol√≠tico cotidiano la b√∫squeda y la construcci√≥n de la unidad y un sentido com√∫n para el cambio profundo de nuestro pa√≠s y las desigualdades que lo atraviesan"",\n         "emisor_nombre": "La direcci√≥n del partido",\n         "contexto": "Comunicado oficial emitido tras la reuni√≥n del Congreso Extraordinario Nacional del Polo",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Desde entonces hemos tenido en el centro de nuestro horizonte estrat√©gico y en el quehacer pol√≠tico cotidiano la b√∫squeda y la construcci√≥n de la unidad y un sentido com√∫n para el cambio profundo de nuestro pa√≠s y las desigualdades que lo atraviesan"",\n         "emisor_nombre": "La direcci√≥n del partido",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": "Publicaci√≥n en X",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Esta es una decisi√≥n trascendental que tiene una implicaci√≥n para el grupo de las fuerzas que queremos la transformaci√≥n progresista y social en Colombia, puesto que el Polo Democr√°tico es un partido que ha tenido una larga historia en las √∫ltimas d√©cadas de trabajo por la unidad de todas las corrientes de izquierda"",\n         "emisor_nombre": "Iv√°n Cepeda",\n         "contexto": null,\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }}'}}


[test_002] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:05<00:02,  1.76it/s][A[A2025-04-21 15:16:33,946 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:33,990 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_021] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:02,  6.36it/s][A2025-04-21 15:16:33,998 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:34,165 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_002] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:06<00:02,  1.97it/s][A[A2025-04-21 15:16:34,200 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_021] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:02<00:01,  7.25it/s][A2025-04-21 15:16:34,804 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_039] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:03<00:02,  4.25it/s][A[A[A[A2025-04-21 15:16:35,304 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_021] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:03<00:04,  2.94it/s][A2025-04-21 15:16:35,500 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_057] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:04<00:05,  1.73it/s][A[A[A2025-04-21 15:16:35,606 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_039] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:03<00:02,  2.95it/s][A[A[A[A2025-04-21 15:16:35,642 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_057] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:04<00:03,  2.14it/s][A[A[A2025-04-21 15:16:37,134 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:37,135 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:16:37,255 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_039] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:05<00:04,  1.64it/s][A[A[A[A2025-04-21 15:16:37,460 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:37,461 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:16:37,601 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:16:37,604 - ERROR - [test_039][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Se quedaron sin dinero porque les trancamos su mercado petrolero. Saben qu√© es lo que tienen que hacer"",\n         "emisor_nombre": "Donald Trump",\n         "contexto": "Reuni√≥n con Nayib Bukele en la Casa Blanca",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Por supuesto que no voy a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No vamos a hacerlo. ¬øC√≥mo voy a enviar de contrabando a un terrorista a Estados Unidos?"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No nos gusta mucho liberar terroristas en nuestro pa√≠s"",\n         "emisor_nombre": "Nayib Bukele",\n         "contexto": "Preguntas de periodistas",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }}'}}




[test_039] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:05<00:03,  1.82it/s][A[A[A[A2025-04-21 15:16:37,950 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:37,951 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:16:37,990 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_021] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:05<00:10,  1.13it/s][A2025-04-21 15:16:38,027 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:38,028 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:16:38,096 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_021] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:06<00:07,  1.45it/s][A2025-04-21 15:16:38,250 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:38,252 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:16:38,252 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:38,253 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:16:38,347 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:16:38,349 - ERROR - [test_021][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": "Santiago" y se fue caminando, cuando este estaba saliendo empez√≥ a sonar la marcha de fondo mientras el venerado se alejaba.",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": "vivida como un sue√±o",\n         "emisor_nombre": "Santiago Coronado",\n         "contexto": "Relato del sue√±o que inspir√≥ la composici√≥n de la marcha f√∫nebre",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }}'}}

[test_021] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:06<00:05,  1.74it/s][A2025-04-21 15:16:38,435 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:38,439 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:16:38,463 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:38,464 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:16:38,550 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:38,551 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:16:38,751 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_039] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:07<00:03,  1.43it/s][A[A[A[A2025-04-21 15:16:39,035 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:39,037 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:16:39,119 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:39,120 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:16:40,635 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_021] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:08<00:09,  1.04s/it][A2025-04-21 15:16:40,797 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_021] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:08<00:06,  1.26it/s][A2025-04-21 15:16:41,325 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:41,326 - ERROR - [test_057][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30891, Requested 1341. Please try again in 4.464s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_057] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:10<00:13,  1.86s/it][A[A[A2025-04-21 15:16:42,411 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:42,412 - INFO - Retrying request to /openai/v1/chat/completions in 11.000000 seconds
2025-04-21 15:16:42,639 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:42,640 - INFO - Retrying request to /openai/v1/chat/completions in 11.000000 seconds
2025-04-21 15:16:42,891 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_057] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:12<00:10,  1.78s/it][A[A[A2025-04-21 15:16:43,400 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:43,401 - INFO - Retrying request to /openai/v1/chat/completions in 11.000000 seconds
2025-04-21 15:16:44,170 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:44,171 - ERROR - [test_057][relevancia][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32587, Requested 1018. Please try again in 7.21s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_057] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:13<00:08,  1.64s/it][A[A[A2025-04-21 15:16:44,456 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:44,457 - ERROR - [test_039][relevancia][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32439, Requested 1023. Please try again in 6.924s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_039] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:12<00:07,  2.00s/it][A[A[A[A2025-04-21 15:16:44,657 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:44,657 - ERROR - [test_021][relevancia][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32340, Requested 1011. Please try again in 6.703s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_021] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:12<00:11,  1.67s/it][A2025-04-21 15:16:44,759 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:44,760 - ERROR - [test_021][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32287, Requested 1152. Please try again in 6.879s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_021] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:12<00:07,  1.22s/it][A2025-04-21 15:16:45,229 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:45,230 - ERROR - [test_039][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32052, Requested 1437. Please try again in 6.978s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_039] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:13<00:04,  1.67s/it][A[A[A[A2025-04-21 15:16:45,235 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:45,236 - ERROR - [test_057][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32050, Requested 1080. Please try again in 6.26s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_057] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:14<00:05,  1.47s/it][A[A[A2025-04-21 15:16:45,374 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:45,375 - ERROR - [test_057][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31982, Requested 1228. Please try again in 6.421s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_057] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:14<00:03,  1.08s/it][A[A[A2025-04-21 15:16:45,456 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:45,457 - ERROR - [test_039][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31938, Requested 1549. Please try again in 6.975s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_039] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:13<00:02,  1.27s/it][A[A[A[A2025-04-21 15:16:45,634 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:45,635 - ERROR - [test_021][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31850, Requested 1413. Please try again in 6.527s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_021] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:13<00:05,  1.12s/it][A2025-04-21 15:16:45,682 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:45,683 - ERROR - [test_021][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31826, Requested 1301. Please try again in 6.254s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:16:46,362 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:46,363 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:16:46,840 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:46,841 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:16:47,282 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:47,282 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:16:47,368 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:47,369 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:16:51,820 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_002] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:23<00:13,  4.49s/it][A[A2025-04-21 15:16:52,052 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:52,053 - ERROR - [test_002][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29373, Requested 1314. Please try again in 1.373s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_002] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:24<00:06,  3.43s/it][A[A2025-04-21 15:16:52,473 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:52,474 - ERROR - [test_002][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29163, Requested 1463. Please try again in 1.252s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_002] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:24<00:02,  2.64s/it][A[A2025-04-21 15:16:52,580 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:52,581 - ERROR - [test_002][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29110, Requested 1575. Please try again in 1.369s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_002] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:24<00:00,  1.95s/it][A[A

                                                                         [A[A2025-04-21 15:16:52,597 - INFO - --- Art√≠culo test_002 completado ---
2025-04-21 15:16:52,597 - INFO - --- Procesando Art√≠culo: test_003 ---
2025-04-21 15:16:52,598 - INFO - [test_003] Lanzando 25 llamadas a Groq...


[test_003] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[AProgreso General Art√≠culos:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 36/72 [03:32<04:51,  8.11s/it]2025-04-21 15:16:52,836 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:52,836 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:16:52,841 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:52,842 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:16:52,845 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:52,846 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:16:52,862 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:52,863 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:16:53,059 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_003] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:11,  2.16it/s][A[A2025-04-21 15:16:53,090 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:53,322 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_003] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:04,  4.61it/s][A[A2025-04-21 15:16:53,394 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:53,489 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_003] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:00<00:02,  6.74it/s][A[A2025-04-21 15:16:53,492 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:53,521 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:53,567 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:53,632 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_003] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:01, 12.29it/s][A[A2025-04-21 15:16:53,644 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:53,645 - ERROR - [test_020][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 28582, Requested 2149. Please try again in 1.461s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_020] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:28<00:11,  5.52s/it][A[A[A[A[A2025-04-21 15:16:53,653 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:53,829 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_003] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:01, 11.56it/s][A[A2025-04-21 15:16:53,839 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:53,842 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:53,843 - ERROR - [test_020][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 28479, Requested 2298. Please try again in 1.553s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_020] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:28<00:04,  4.16s/it][A[A[A[A[A2025-04-21 15:16:53,886 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:54,048 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_003] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:01<00:00, 12.30it/s][A[A2025-04-21 15:16:54,082 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:54,144 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:16:54,145 - ERROR - [test_003][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Felicitamos al nuevo presidente de la Rep√∫blica del Ecuador, Daniel Noboa. El hermano pueblo de Ecuador puede siempre contar con Colombia para trabajar juntos por una Am√©rica Latina libre, soberana y en paz"",\n         "emisor_nombre": "Laura Sarabia",\n         "contexto": "Comentarios sobre los resultados de las elecciones en Ecuador",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}
2025-04-21 15:16:54,506 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_003] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:01<00:00,  9.36it/s][A[A2025-04-21 15:16:54,593 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:54,600 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:54,627 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:54,628 - ERROR - [test_020][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29385, Requested 2523. Please try again in 3.816s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_020] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:29<00:00,  3.26s/it][A[A[A[A[A




                                                                         [A[A[A[A[A2025-04-21 15:16:54,640 - INFO - --- Art√≠culo test_020 completado ---
2025-04-21 15:16:54,640 - INFO - --- Procesando Art√≠culo: test_058 ---
2025-04-21 15:16:54,642 - INFO - [test_058] Lanzando 25 llamadas a Groq...





[test_058] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[A[AProgreso General Art√≠culos:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 37/72 [03:34<03:40,  6.29s/it]2025-04-21 15:16:54,844 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:54,845 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:16:54,904 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:54,905 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:16:54,911 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:54,912 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:16:54,918 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:54,919 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:16:54,931 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_003] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:02<00:00,  8.43it/s][A[A2025-04-21 15:16:54,941 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:54,941 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:16:54,946 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:54,946 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:16:54,954 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:54,954 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:16:54,975 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:54,976 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:16:54,987 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:54,988 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:16:54,991 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:54,992 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:16:55,214 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_058] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:13,  1.75it/s][A[A[A[A[A2025-04-21 15:16:55,252 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:55,412 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:55,572 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_058] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:06,  3.56it/s][A[A[A[A[A2025-04-21 15:16:55,587 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:55,708 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_058] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:03,  5.78it/s][A[A[A[A[A2025-04-21 15:16:55,832 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_058] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:03,  6.32it/s][A[A[A[A[A2025-04-21 15:16:56,082 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:56,083 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:16:56,098 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_058] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:03,  5.31it/s][A[A[A[A[A2025-04-21 15:16:56,189 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_003] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:03<00:00,  4.12it/s][A[A2025-04-21 15:16:56,363 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_058] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:03,  4.77it/s][A[A[A[A[A2025-04-21 15:16:56,455 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:56,558 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:56,559 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:16:56,681 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:56,683 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_003] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:04<00:00,  3.57it/s][A[A2025-04-21 15:16:56,715 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_058] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:02<00:02,  5.13it/s][A[A[A[A[A2025-04-21 15:16:56,863 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_058] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:02<00:02,  5.45it/s][A[A[A[A[A2025-04-21 15:16:56,909 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:56,910 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:16:56,927 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:56,928 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:16:56,974 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_058] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:02,  6.07it/s][A[A[A[A[A2025-04-21 15:16:57,038 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:57,039 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:16:57,054 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:57,055 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:16:57,084 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:57,086 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:16:57,109 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:57,110 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:16:57,186 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:57,188 - ERROR - [test_058][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29778, Requested 1282. Please try again in 2.119s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_058] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:02<00:02,  5.63it/s][A[A[A[A[A2025-04-21 15:16:57,377 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_058] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:02<00:01,  5.52it/s][A[A[A[A[A2025-04-21 15:16:57,438 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:57,439 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:16:57,453 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:57,454 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:16:57,578 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:57,579 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:16:57,661 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:57,662 - ERROR - [test_021][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29540, Requested 1152. Please try again in 1.383s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_021] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:25<00:10,  3.35s/it][A2025-04-21 15:16:57,712 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:57,714 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_003] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:05<00:00,  2.86it/s][A[A

                                                                         [A[A2025-04-21 15:16:57,728 - INFO - --- Art√≠culo test_003 completado ---
2025-04-21 15:16:57,730 - INFO - --- Procesando Art√≠culo: test_040 ---
2025-04-21 15:16:57,732 - INFO - [test_040] Lanzando 25 llamadas a Groq...


[test_040] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[AProgreso General Art√≠culos:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 38/72 [03:37<03:01,  5.33s/it]




[test_058] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:03<00:02,  4.01it/s][A[A[A[A[A2025-04-21 15:16:57,901 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:57,902 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:16:57,963 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:57,963 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:16:57,995 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_058] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:03<00:02,  4.27it/s][A[A[A[A[A2025-04-21 15:16:58,040 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:58,041 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:16:58,073 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:58,074 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:16:58,155 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:58,156 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:16:58,161 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:58,162 - INFO - Retrying request to /openai/v1/chat/completions in 12.000000 seconds
2025-04-21 15:16:58,166 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:58,167 - ERROR - [test_058][relevancia][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29288, Requested 1014. Please try again in 603ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_058] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:03<00:01,  4.64it/s][A[A[A[A[A2025-04-21 15:16:58,269 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:58,271 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"


[test_040] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:12,  1.85it/s][A[A2025-04-21 15:16:58,272 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:16:58,366 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:16:58,508 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:58,509 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:16:58,633 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_040] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:06,  3.65it/s][A[A2025-04-21 15:16:58,734 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_040] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:04,  4.66it/s][A[A2025-04-21 15:16:59,262 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:59,263 - ERROR - [test_057][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31181, Requested 1080. Please try again in 4.522s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_057] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:28<00:09,  4.85s/it][A[A[A2025-04-21 15:16:59,310 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:16:59,311 - ERROR - [test_058][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 28715, Requested 1504. Please try again in 438ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_058] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:04<00:03,  2.05it/s][A[A[A[A[A2025-04-21 15:16:59,314 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_040] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:06,  2.98it/s][A[A2025-04-21 15:16:59,968 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_058] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:05<00:03,  1.85it/s][A[A[A[A[A2025-04-21 15:17:00,102 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_040] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:02<00:09,  2.08it/s][A[A2025-04-21 15:17:00,124 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:00,125 - ERROR - [test_057][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30747, Requested 1228. Please try again in 3.951s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_057] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:29<00:03,  3.67s/it][A[A[A2025-04-21 15:17:00,159 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:00,160 - ERROR - [test_057][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30729, Requested 1341. Please try again in 4.141s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



                                                                         [A[A[A2025-04-21 15:17:00,174 - INFO - --- Art√≠culo test_057 completado ---
2025-04-21 15:17:00,174 - INFO - --- Procesando Art√≠culo: test_022 ---
2025-04-21 15:17:00,175 - INFO - [test_022] Lanzando 25 llamadas a Groq...



[test_022] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[AProgreso General Art√≠culos:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 39/72 [03:40<02:27,  4.46s/it]2025-04-21 15:17:00,434 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:00,435 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:17:00,523 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:00,524 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:17:00,537 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:00,538 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:00,538 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:17:00,539 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:17:00,557 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:00,558 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:17:00,594 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:17:00,595 - ERROR - [test_040][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Creo que necesitamos una respuesta firme de los gobiernos de la regi√≥n, para oponerse a estas iniciativas de crear espacios por fuera de la protecci√≥n de la ley"",\n         "emisor_nombre": "Juan Pappier",\n         "contexto": "En entrevista con El Diario de Hoy, Pappier vaticina una crisis constitucional en Estados Unidos por el incumplimiento del gobierno Trump a las sentencias de la Corte Suprema y los tribunales inferiores.",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Aqu√≠ hay una orden que dice que el Gobierno de Estados Unidos s√≠ tiene que tomar medidas decisivas para lograr el retorno de esta persona (Kilmar √Åbrego) y esa orden judicial hay que cumplirla"",\n         "emisor_nombre": "Juan Pappier",\n         "contexto": "En entrevista con El Diario de Hoy, Pappier vaticina una crisis constitucional en Estados Unidos por el incumplimiento del gobierno Trump a las sentencias de la Corte Suprema y los tribunales inferiores.",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Creo que necesitamos una respuesta firme de los gobiernos de la regi√≥n, para oponerse a estas iniciativas de crear espacios por fuera de la protecci√≥n de la ley"",\n         "emisor_nombre": "Juan Pappier",\n         "contexto": "Creo que necesitamos una respuesta firme de los gobiernos de la regi√≥n, para oponerse a estas iniciativas de crear espacios por fuera de la protecci√≥n de la ley.",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Es decir, que estas personas est√©n completamente por fuera de la protecci√≥n de la ley y para eso utilizan el CECOT, sabiendo que el CECOT est√° fuera del territorio de los Estados Unidos y en un pa√≠s donde no hay separaci√≥n de poderes y donde no hay Estado de Derecho como El Salvador"",\n         "emisor_nombre": "Juan Pappier",\n         "contexto": "Es decir, que estas personas est√©n completamente por fuera de la protecci√≥n de la ley y para eso utilizan el CECOT, sabiendo que el CECOT est√° fuera del territorio de los Estados Unidos y en un pa√≠s donde no hay separaci√≥n de poderes y donde no hay Estado de Derecho como El Salvador.",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Bueno, son preocupantes las declaraciones de Eric Prince por el r√©cord de su compa√±√≠a a nivel global. Y por lo que vemos, un fen√≥meno de expansi√≥n de su trabajo en Am√©rica Latina"",\n         "emisor_nombre": "Juan Pappier",\n         "contexto": "Este fin de semana, Eric Prince dijo que hab√≠a propuesto al gobierno de los Estados Unidos convertir un √°rea del CECOT donde est√°n recluyendo a los venezolanos en un mini-territorio estadounidense, un segundo Guant√°namo.",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Creo que si el presidente Trump no cumple con la sentencia de la Corte Suprema, Estados Unidos queda al borde de una crisis constitucional y es un mensaje muy preocupante que apenas en menos de 3 meses de la toma de posesi√≥n de Trump"",\n         "emisor_nombre": "Juan Pappier",\n         "contexto": "El presidente Trump dijo esta ma√±ana en la visita del presidente Bukele que son millones de personas las que calificar√≠an para ser deportadas y que le ha pedido a El Salvador que reciba cuantas le sean posibles.",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Porque llegar√≠amos a un punto de desacato del presidente, un abierto desacato del presidente de una sentencia de la Corte Suprema, es decir, uno de los principios fundamentales de la separaci√≥n de poderes es que aqu√≠ hay que respetar las √≥rdenes judiciales"",\n         "emisor_nombre": "Juan Pappier",\n         "contexto": "Porque llegar√≠amos a un punto de desacato del presidente, un abierto desacato del presidente de una sentencia de la Corte Suprema, es decir, uno de los principios fundamentales de la separaci√≥n de poderes es que aqu√≠ hay que respetar las √≥rdenes judiciales.",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""S√≠, pero aqu√≠ hay una orden que dice que s√≠ que s√≠ puede, que el Gobierno de Estados Unidos s√≠ tiene que tomar medidas decisivas para lograr el retorno de esta persona y esa orden judicial hay que cumplirla"",\n         "emisor_nombre": "Juan Pappier",\n         "contexto": "¬øPero el presidente Trump puede alegar que el presidente Bukele no quiere enviar a esta persona y que es salvadore√±o y que no puede obligarlo?",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lo que nosotros hemos documentado es que en varios casos estas personas estaban detenidas en centros migratorios de los Estados Unidos en Texas o en California desde la administraci√≥n Biden"",\n         "emisor_nombre": "Juan Pappier",\n         "contexto": "A varios de los deportados se les hab√≠a dicho. incluso hasta la √∫ltima noche, que ser√≠an deportados a Venezuela. ¬øHubo un enga√±o consciente para ellos? ¬øQu√© le dijo el gobierno Trump a estas personas antes de ser deportadas?",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Hab√≠a varios, hay varios casos que hemos documentado donde ten√≠an audiencias pendientes de asilo eh programadas incluso para los pr√≥ximos d√≠as de su deportaci√≥n y las autoridades migratorias hicieron caso omiso a esas audiencias que estaban programadas y deportaron a estas personas"",\n         "emisor_nombre": "Juan Pappier",\n         "contexto": "¬øSe sabe de personas que estaban siguiendo procesos legales facilitados por el gobierno de Estados Unidos y que fueron enviados al CECOT aun as√≠?",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}


[test_040] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:02<00:08,  2.07it/s][A[A2025-04-21 15:17:00,679 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:00,680 - ERROR - [test_021][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30472, Requested 1413. Please try again in 3.771s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_021] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:28<00:06,  3.27s/it][A2025-04-21 15:17:00,759 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_022] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:14,  1.71it/s][A[A[A2025-04-21 15:17:00,802 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_040] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:03<00:06,  2.51it/s][A[A2025-04-21 15:17:00,910 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_022] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:07,  3.03it/s][A[A[A2025-04-21 15:17:00,989 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_040] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:03<00:05,  3.00it/s][A[A2025-04-21 15:17:01,130 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_058] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:06<00:03,  1.38it/s][A[A[A[A[A2025-04-21 15:17:01,157 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_022] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:06,  3.43it/s][A[A[A2025-04-21 15:17:01,193 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:01,205 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_040] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:03<00:04,  3.36it/s][A[A2025-04-21 15:17:01,254 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:01,282 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_022] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:03,  6.17it/s][A[A[A2025-04-21 15:17:01,322 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_040] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:03<00:03,  4.11it/s][A[A2025-04-21 15:17:01,388 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:01,434 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_022] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:03,  6.28it/s][A[A[A2025-04-21 15:17:01,648 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_022] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:03,  5.71it/s][A[A[A2025-04-21 15:17:01,768 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_022] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  6.29it/s][A[A[A2025-04-21 15:17:01,773 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:17:01,774 - ERROR - [test_022][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Nadie me lo pidi√≥, inventan"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "Respuesta a versiones de un pedido de Scott Bessent para que la Argentina abandone el swap chino",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Es porque no tenes pesos (circulando). Todos los factores monetarios de la Argentina llevan al tipo de cambio a la baja"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "Explicaci√≥n sobre la baja del tipo de cambio",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Yo hubiera puesto la banda m√°s abajo"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "Comentario sobre la decisi√≥n de fijar el piso del tipo de cambio en 1.000 pesos",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Puedo sacar todos lo pesos de la econom√≠a a 911. La gente decidi√≥ seguir con los pesos, pero las posibilidades est√°n abiertas"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "Comentario sobre la dolarizaci√≥n",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""El tipo mas buscando en el planeta (por el secretario del Tesoro norteamericano, Scott Bessent) sale de su pa√≠s. ¬øA ver a quien? A'}}
2025-04-21 15:17:01,799 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:01,800 - ERROR - [test_021][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29910, Requested 1301. Please try again in 2.421s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_021] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:29<00:02,  2.71s/it][A2025-04-21 15:17:01,829 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_040] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:04<00:02,  4.03it/s][A[A2025-04-21 15:17:01,890 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 500 Internal Server Error"
2025-04-21 15:17:01,892 - INFO - Retrying request to /openai/v1/chat/completions in 0.488147 seconds
2025-04-21 15:17:01,923 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_022] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01,  8.21it/s][A[A[A2025-04-21 15:17:02,151 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_022] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:02,  6.76it/s][A[A[A2025-04-21 15:17:02,310 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_022] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:01,  6.63it/s][A[A[A2025-04-21 15:17:02,343 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_040] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:04<00:03,  3.18it/s][A[A2025-04-21 15:17:02,384 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:02,529 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_040] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:04<00:02,  3.56it/s][A[A2025-04-21 15:17:02,668 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_022] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:02<00:01,  6.14it/s][A[A[A2025-04-21 15:17:02,694 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:02,750 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_021] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:30<00:00,  2.23s/it][A
                                                                         [A2025-04-21 15:17:02,767 - INFO - --- Art√≠culo test_021 completado ---
2025-04-21 15:17:02,767 - INFO - --- Procesando Art√≠culo: test_004 ---
2025-04-21 15:17:02,768 - INFO - [test_004] Lanzando 25 llamadas a Groq...

[test_004] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][AProgreso General Art√≠culos:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 40/72 [03:42<02:04,  3.90s/it]2025-04-21 15:17:02,958 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_022] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:01,  6.38it/s][A[A[A2025-04-21 15:17:02,980 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_040] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:05<00:02,  3.06it/s][A[A2025-04-21 15:17:03,011 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:03,012 - INFO - Retrying request to /openai/v1/chat/completions in 11.000000 seconds
2025-04-21 15:17:03,015 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:03,016 - INFO - Retrying request to /openai/v1/chat/completions in 11.000000 seconds
2025-04-21 15:17:03,021 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:03,021 - INFO - Retrying request to /openai/v1/chat/completions in 31.000000 seconds
2025-04-21 15:17:03,029 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:03,030 - INFO - Retrying request to /openai/v1/chat/completions in 31.000000 seconds
2025-04-21 15:17:03,041 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:03,042 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:17:03,060 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:03,061 - INFO - Retrying request to /openai/v1/chat/completions in 31.000000 seconds
2025-04-21 15:17:03,061 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:03,062 - INFO - Retrying request to /openai/v1/chat/completions in 31.000000 seconds
2025-04-21 15:17:03,094 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:03,094 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:17:03,111 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:03,112 - INFO - Retrying request to /openai/v1/chat/completions in 30.000000 seconds
2025-04-21 15:17:03,114 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:03,115 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:17:03,120 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:03,121 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:17:03,123 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_022] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:02<00:01,  6.34it/s][A[A[A2025-04-21 15:17:03,164 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:03,165 - INFO - Retrying request to /openai/v1/chat/completions in 30.000000 seconds
2025-04-21 15:17:03,296 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_004] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:12,  1.89it/s][A2025-04-21 15:17:03,325 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:03,337 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:03,554 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_004] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:00<00:03,  5.89it/s][A2025-04-21 15:17:03,679 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:03,680 - INFO - Retrying request to /openai/v1/chat/completions in 30.000000 seconds
2025-04-21 15:17:03,705 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_004] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:00<00:03,  6.07it/s][A2025-04-21 15:17:03,780 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:03,859 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_004] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:02,  7.95it/s][A2025-04-21 15:17:03,881 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:17:03,892 - ERROR - [test_040][extraccion_datos][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "indicador": "N√∫mero de personas deportadas a El Salvador",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "40",\n         "unidad": "personas",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido enviadas a El Salvador",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "millones",\n         "unidad": "personas",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Presidente Trump",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "40",\n         "unidad": "personas",\n         "ambito_geografico": ["Estados Unidos"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido deportadas a El Salvador a pesar de tener audiencias pendientes de asilo",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "varios",\n         "unidad": "personas",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por tener tatuajes",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "1",\n         "unidad": "persona",\n         "ambito_geografico": ["Estados Unidos"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por tener expedientes penales",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "20",\n         "unidad": "personas",\n         "ambito_geografico": ["Estados Unidos"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por no tener expedientes penales",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "20",\n         "unidad": "personas",\n         "ambito_geografico": ["Estados Unidos"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido deportadas a El Salvador por no tener expedientes penales",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "20",\n         "unidad": "personas",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por tener expedientes penales y han sido deportadas a El Salvador",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "20",\n         "unidad": "personas",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por no tener expedientes penales y han sido deportadas a El Salvador",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "20",\n         "unidad": "personas",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por tener tatuajes y han sido deportadas a El Salvador",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "1",\n         "unidad": "persona",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por tener expedientes penales y han sido deportadas a El Salvador a pesar de tener audiencias pendientes de asilo",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "varios",\n         "unidad": "personas",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por no tener expedientes penales y han sido deportadas a El Salvador a pesar de tener audiencias pendientes de asilo",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "varios",\n         "unidad": "personas",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por tener tatuajes y han sido deportadas a El Salvador a pesar de tener audiencias pendientes de asilo",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "1",\n         "unidad": "persona",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por tener expedientes penales y han sido deportadas a El Salvador a pesar de tener audiencias pendientes de asilo y tener tatuajes",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "varios",\n         "unidad": "personas",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por no tener expedientes penales y han sido deportadas a El Salvador a pesar de tener audiencias pendientes de asilo y tener tatuajes",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "varios",\n         "unidad": "personas",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por tener tatuajes y han sido deportadas a El Salvador a pesar de tener audiencias pendientes de asilo y tener tatuajes",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "1",\n         "unidad": "persona",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por tener expedientes penales y han sido deportadas a El Salvador a pesar de tener audiencias pendientes de asilo y tener tatuajes",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "varios",\n         "unidad": "personas",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por no tener expedientes penales y han sido deportadas a El Salvador a pesar de tener audiencias pendientes de asilo y tener tatuajes",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "varios",\n         "unidad": "personas",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por tener tatuajes y han sido deportadas a El Salvador a pesar de tener audiencias pendientes de asilo y tener tatuajes",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "1",\n         "unidad": "persona",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por tener expedientes penales y han sido deportadas a El Salvador a pesar de tener audiencias pendientes de asilo y tener tatuajes",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "varios",\n         "unidad": "personas",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por no tener expedientes penales y han sido deportadas a El Salvador a pesar de tener audiencias pendientes de asilo y tener tatuajes",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "varios",\n         "unidad": "personas",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por tener tatuajes y han sido deportadas a El Salvador a pesar de tener audiencias pendientes de asilo y tener tatuajes",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "1",\n         "unidad": "persona",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por tener expedientes penales y han sido deportadas a El Salvador a pesar de tener audiencias pendientes de asilo y tener tatuajes",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "varios",\n         "unidad": "personas",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por no tener expedientes penales y han sido deportadas a El Salvador a pesar de tener audiencias pendientes de asilo y tener tatuajes",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "varios",\n         "unidad": "personas",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por tener tatuajes y han sido deportadas a El Salvador a pesar de tener audiencias pendientes de asilo y tener tatuajes",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "1",\n         "unidad": "persona",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por tener expedientes penales y han sido deportadas a El Salvador a pesar de tener audiencias pendientes de asilo y tener tatuajes",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "varios",\n         "unidad": "personas",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por no tener expedientes penales y han sido deportadas a El Salvador a pesar de tener audiencias pendientes de asilo y tener tatuajes",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "varios",\n         "unidad": "personas",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      },\n      {\n         "indicador": "N√∫mero de personas que han sido detenidas en centros migratorios de los Estados Unidos por tener tatuajes y han sido deportadas a El Salvador a pesar de tener audiencias pendientes de asilo y tener tatuajes",\n         "categoria": "demogr√°fico",\n         "valor_numerico": "1",\n         "unidad": "persona",\n         "ambito_geografico": ["El Salvador"],\n         "periodo_referencia_inicio": null,\n         "periodo_referencia_fin": null,\n         "tipo_periodo": null,\n         "fuente_especifica": "Human Rights Watch",\n         "notas_contexto": null\n      }}'}}


[test_040] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:06<00:03,  2.04it/s][A[A2025-04-21 15:17:03,941 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_022] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:03<00:02,  3.21it/s][A[A[A2025-04-21 15:17:04,129 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_004] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  6.23it/s][A2025-04-21 15:17:04,237 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:04,237 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:17:04,335 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:04,335 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:17:04,361 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_040] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:06<00:03,  2.06it/s][A[A2025-04-21 15:17:04,436 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_004] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:03,  5.04it/s][A2025-04-21 15:17:04,525 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:04,528 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:04,528 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:17:04,535 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_040] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:06<00:02,  2.53it/s][A[A2025-04-21 15:17:04,541 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:04,589 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_004] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:02,  6.82it/s][A2025-04-21 15:17:04,629 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:04,630 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:17:04,641 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_058] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:09<00:03,  1.20s/it][A[A[A[A[A2025-04-21 15:17:04,854 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_004] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:02,  5.75it/s][A2025-04-21 15:17:05,079 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_022] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:04<00:03,  1.93it/s][A[A[A2025-04-21 15:17:05,189 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:05,190 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:17:05,196 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_004] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:02<00:02,  4.63it/s][A2025-04-21 15:17:05,373 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:05,374 - ERROR - [test_039][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32657, Requested 1664. Please try again in 8.643s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_039] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:33<00:06,  6.58s/it][A[A[A[A2025-04-21 15:17:05,380 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:05,383 - ERROR - [test_039][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29191, Requested 1549. Please try again in 1.48s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




                                                                         [A[A[A[A2025-04-21 15:17:05,396 - INFO - --- Art√≠culo test_039 completado ---
2025-04-21 15:17:05,396 - INFO - --- Procesando Art√≠culo: test_059 ---
2025-04-21 15:17:05,397 - INFO - [test_059] Lanzando 25 llamadas a Groq...




[test_059] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[AProgreso General Art√≠culos:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 41/72 [03:45<01:49,  3.52s/it]2025-04-21 15:17:05,575 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:05,577 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:17:05,577 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:05,578 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:17:05,583 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:05,583 - INFO - Retrying request to /openai/v1/chat/completions in 33.000000 seconds
2025-04-21 15:17:05,590 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:05,591 - INFO - Retrying request to /openai/v1/chat/completions in 35.000000 seconds
2025-04-21 15:17:05,603 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:05,604 - INFO - Retrying request to /openai/v1/chat/completions in 34.000000 seconds
2025-04-21 15:17:05,664 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:05,665 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:17:05,690 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:05,691 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:17:05,692 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:05,692 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:17:05,706 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:05,707 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:17:05,713 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:05,714 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:17:05,780 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:05,781 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:17:05,796 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_022] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:05<00:02,  1.75it/s][A[A[A2025-04-21 15:17:05,917 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_059] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:12,  1.92it/s][A[A[A[A2025-04-21 15:17:06,010 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:06,016 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:06,146 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:06,147 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:17:06,247 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_059] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:00<00:03,  5.32it/s][A[A[A[A2025-04-21 15:17:06,380 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_059] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:00<00:03,  5.80it/s][A[A[A[A2025-04-21 15:17:06,803 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_059] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:04,  4.10it/s][A[A[A[A2025-04-21 15:17:06,828 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_022] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:06<00:02,  1.44it/s][A[A[A2025-04-21 15:17:06,904 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_004] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:04<00:06,  1.65it/s][A2025-04-21 15:17:06,923 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_059] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:03,  4.81it/s][A[A[A[A2025-04-21 15:17:07,001 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:07,002 - INFO - Retrying request to /openai/v1/chat/completions in 14.000000 seconds
2025-04-21 15:17:07,072 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:07,073 - INFO - Retrying request to /openai/v1/chat/completions in 14.000000 seconds
2025-04-21 15:17:07,079 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:07,081 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_004] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:04<00:04,  2.04it/s][A



[test_059] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:03,  5.17it/s][A[A[A[A2025-04-21 15:17:07,752 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:07,753 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:17:07,803 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:07,804 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:17:07,876 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:07,877 - ERROR - [test_022][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31400, Requested 1631. Please try again in 6.062s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_022] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:07<00:02,  1.26it/s][A[A[A2025-04-21 15:17:08,096 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_059] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:02<00:06,  2.30it/s][A[A[A[A2025-04-21 15:17:08,432 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:08,434 - ERROR - [test_004][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 47592, Requested 1667. Please try again in 38.518s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_004] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:05<00:06,  1.37it/s][A2025-04-21 15:17:08,585 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_059] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:03<00:06,  2.22it/s][A[A[A[A2025-04-21 15:17:08,792 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:08,794 - INFO - Retrying request to /openai/v1/chat/completions in 39.000000 seconds
2025-04-21 15:17:08,794 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:08,795 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:17:09,344 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_004] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:06<00:06,  1.28it/s][A2025-04-21 15:17:10,181 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_059] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:04<00:11,  1.26it/s][A[A[A[A2025-04-21 15:17:10,260 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:10,261 - INFO - Retrying request to /openai/v1/chat/completions in 43.000000 seconds
2025-04-21 15:17:10,956 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_059] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:05<00:10,  1.27it/s][A[A[A[A2025-04-21 15:17:11,168 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:11,169 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:17:11,493 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:17:11,507 - ERROR - [test_059][extraccion_entidades][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "nombre": "Banco Central",\n         "tipo": "ORGANIZACION",\n         "alias": ["Banco Central"],\n         "descripcion_contextual": "Instituci√≥n financiera argentina",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Javier Milei",\n         "tipo": "PERSONA",\n         "alias": ["Javier Milei"],\n         "descripcion_contextual": "Presidente de Argentina",\n         "relevancia_articulo": 9\n      },\n      {\n         "nombre": "Banco Naci√≥n",\n         "tipo": "ORGANIZACION",\n         "alias": ["Banco Naci√≥n"],\n         "descripcion_contextual": "Banco estatal argentino",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Gobierno de Javier Milei",\n         "tipo": "ORGANIZACION",\n         "alias": ["Gobierno de Javier Milei"],\n         "descripcion_contextual": "Administraci√≥n p√∫blica argentina",\n         "relevancia_articulo": 9\n      },\n      {\n         "nombre": "Banco Galicia",\n         "tipo": "ORGANIZACION",\n         "alias": ["Banco Galicia"],\n         "descripcion_contextual": "Banco privado argentino",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Banco Credicoop",\n         "tipo": "ORGANIZACION",\n         "alias": ["Banco Credicoop"],\n         "descripcion_contextual": "Banco cooperativo argentino",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Banco Macro",\n         "tipo": "ORGANIZACION",\n         "alias": ["Banco Macro"],\n         "descripcion_contextual": "Banco privado argentino",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "ICBC",\n         "tipo": "ORGANIZACION",\n         "alias": ["ICBC"],\n         "descripcion_contextual": "Banco estatal argentino",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "BBVA",\n         "tipo": "ORGANIZACION",\n         "alias": ["BBVA"],\n         "descripcion_contextual": "Banco privado argentino",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Banco Provincia",\n         "tipo": "ORGANIZACION",\n         "alias": ["Banco Provincia"],\n         "descripcion_contextual": "Banco estatal argentino",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Donald Trump",\n         "tipo": "PERSONA",\n         "alias": ["Donald Trump"],\n         "descripcion_contextual": "Presidente de Estados Unidos",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "OPEP",\n         "tipo": "ORGANIZACION",\n         "alias": ["OPEP"],\n         "descripcion_contextual": "Organizaci√≥n de pa√≠ses productores de petr√≥leo",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Merval",\n         "tipo": "CONCEPTO",\n         "alias": ["Merval"],\n         "descripcion_contextual": "√çndice burs√°til argentino",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Dow Jones",\n         "tipo": "CONCEPTO",\n         "alias": ["Dow Jones"],\n         "descripcion_contextual": "√çndice burs√°til estadounidense",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "S&P 500",\n         "tipo": "CONCEPTO",\n         "alias": ["S&P 500"],\n         "descripcion_contextual": "√çndice burs√°til estadounidense",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Nasdaq",\n         "tipo": "CONCEPTO",\n         "alias": ["Nasdaq"],\n         "descripcion_contextual": "√çndice burs√°til estadounidense",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "WTI",\n         "tipo": "CONCEPTO",\n         "alias": ["WTI"],\n         "descripcion_contextual": "Petr√≥leo intermedio de Texas",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Argentina",\n         "tipo": "LUGAR",\n         "alias": ["Argentina"],\n         "descripcion_contextual": "Pa√≠s sudamericano",\n         "relevancia_articulo": 10\n      },\n      {\n         "nombre": "Estados Unidos",\n         "tipo": "LUGAR",\n         "alias": ["Estados Unidos"],\n         "descripcion_contextual": "Pa√≠s norteamericano",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Texas",\n         "tipo": "LUGAR",\n         "alias": ["Texas"],\n         "descripcion_contextual": "Estado estadounidense",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Bolsa de Buenos Aires",\n         "tipo": "LUGAR",\n         "alias": ["Bolsa de Buenos Aires"],\n         "descripcion_contextual": "Mercado burs√°til argentino",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Wall Street",\n         "tipo": "LUGAR",\n         "alias": ["Wall Street"],\n         "descripcion_contextual": "Mercado burs√°til estadounidense",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Plaza neoyorquina",\n         "tipo": "LUGAR",\n         "alias": ["Plaza neoyorquina"],\n         "descripcion_contextual": "Mercado burs√°til estadounidense",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Cepo cambiario",\n         "tipo": "CONCEPTO",\n         "alias": ["Cepo cambiario"],\n         "descripcion_contextual": "Pol√≠tica econ√≥mica argentina",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Devaluaci√≥n",\n         "tipo": "CONCEPTO",\n         "alias": ["Devaluaci√≥n"],\n         "descripcion_contextual": "Pol√≠tica econ√≥mica argentina",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Ley de cambio",\n         "tipo": "NORMATIVA",\n         "alias": ["Ley de cambio"],\n         "descripcion_contextual": "Pol√≠tica econ√≥mica argentina",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Tasa de inter√©s",\n         "tipo": "CONCEPTO",\n         "alias": ["Tasa de inter√©s"],\n         "descripcion_contextual": "Pol√≠tica econ√≥mica argentina",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Plazos fijos",\n         "tipo": "CONCEPTO",\n         "alias": ["Plazos fijos"],\n         "descripcion_contextual": "Pol√≠tica econ√≥mica argentina",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Bolsa de valores",\n         "tipo": "CONCEPTO",\n         "alias": ["Bolsa de valores"],\n         "descripcion_contextual": "Mercado burs√°til argentino",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Mercado de divisas",\n         "tipo": "CONCEPTO",\n         "alias": ["Mercado de divisas"],\n         "descripcion_contextual": "Pol√≠tica econ√≥mica argentina",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Reservas internacionales",\n         "tipo": "CONCEPTO",\n         "alias": ["Reservas internacionales"],\n         "descripcion_contextual": "Pol√≠tica econ√≥mica argentina",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "D√≥lar",\n         "tipo": "CONCEPTO",\n         "alias": ["D√≥lar"],\n         "descripcion_contextual": "Moneda estadounidense",\n         "relevancia_articulo": 10\n      },\n      {\n         "nombre": "Peso argentino",\n         "tipo": "CONCEPTO",\n         "alias": ["Peso argentino"],\n         "descripcion_contextual": "Moneda argentina",\n         "relevancia_articulo": 10\n      },\n      {\n         "nombre": "Cepo a la compra de divisas",\n         "tipo": "CONCEPTO",\n         "alias": ["Cepo a la compra de divisas"],\n         "descripcion_contextual": "Pol√≠tica econ√≥mica argentina",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Levantamiento del cepo cambiario",\n         "tipo": "CONCEPTO",\n         "alias": ["Levantamiento del cepo cambiario"],\n         "descripcion_contextual": "Pol√≠tica econ√≥mica argentina",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Tasa nominal anual",\n         "tipo": "CONCEPTO",\n         "alias": ["Tasa nominal anual"],\n         "descripcion_contextual": "Pol√≠tica econ√≥mica argentina",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Banco Naci√≥n (plaza)",\n         "tipo": "LUGAR",\n         "alias": ["Banco Naci√≥n (plaza)"],\n         "descripcion_contextual": "Mercado de divisas argentino",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Casa de cambio",\n         "tipo": "ORGANIZACION",\n         "alias": ["Casa de cambio"],\n         "descripcion_contextual": "Empresa que vende divisas",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Plataforma virtual de bancos",\n         "tipo": "CONCEPTO",\n         "alias": ["Plataforma virtual de bancos"],\n         "descripcion_contextual": "Sistema de compra de divisas en l√≠nea",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Colapso del sistema",\n         "tipo": "CONCEPTO",\n         "alias": ["Colapso del sistema"],\n         "descripcion_contextual": "Problema t√©cnico en la plataforma virtual de bancos",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Falta de actualizaci√≥n de los sistemas",\n         "tipo": "CONCEPTO",\n         "alias": ["Falta de actualizaci√≥n de los sistemas"],\n         "descripcion_contextual": "Problema t√©cnico en la plataforma virtual de bancos",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Mercado formal mayorista",\n         "tipo": "CONCEPTO",\n         "alias": ["Mercado formal mayorista"],\n         "descripcion_contextual": "Mercado de divisas argentino",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "D√≥lar blue",\n         "tipo": "CONCEPTO",\n         "alias": ["D√≥lar blue"],\n         "descripcion_contextual": "Moneda estadounidense en el mercado informal",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "D√≥lar financiero",\n         "tipo": "CONCEPTO",\n         "alias": ["D√≥lar financiero"],\n         "descripcion_contextual": "Moneda estadounidense en el mercado informal",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Caso G√ºrtel",\n         "tipo": "CONCEPTO",\n         "alias": ["Caso G√ºrtel"],\n         "descripcion_contextual": "Caso de corrupci√≥n en Argentina",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Relaciones Argentina-Brasil",\n         "tipo": "CONCEPTO",\n         "alias": ["Relaciones Argentina-Brasil"],\n         "descripcion_contextual": "Relaciones diplom√°ticas entre Argentina y Brasil",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Cumbre",\n         "tipo": "EVENTO",\n         "alias": ["Cumbre"],\n         "descripcion_contextual": "Reuni√≥n de l√≠deres pol√≠ticos",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Protesta",\n         "tipo": "EVENTO",\n         "alias": ["Protesta"],\n         "descripcion_contextual": "Manifestaci√≥n p√∫blica",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Elecciones Generales Espa√±a 2023",\n         "tipo": "EVENTO",\n         "alias": ["Elecciones Generales Espa√±a 2023"],\n         "descripcion_contextual": "Elecciones generales en Espa√±a",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Ley Org√°nica 3/2018",\n         "tipo": "NORMATIVA",\n         "alias": ["Ley Org√°nica 3/2018"],\n         "descripcion_contextual": "Ley org√°nica espa√±ola",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Organizaci√≥n de las Naciones Unidas (ONU)",\n         "tipo": "ORGANIZACION",\n         "alias": ["ONU"],\n         "descripcion_contextual": "Organizaci√≥n internacional",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Pedro S√°nchez P√©rez-Castej√≥n",\n         "tipo": "PERSONA",\n         "alias": ["Pedro S√°nchez P√©rez-Castej√≥n"],\n         "descripcion_contextual": "L√≠der pol√≠tico espa√±ol",\n         "relevancia_articulo": 4\n      },\n      {\n         "nombre": "Banco Central (Argentina)",\n         "tipo": "ORGANIZACION",\n         "alias": ["Banco Central (Argentina)"],\n         "descripcion_contextual": "Instituci√≥n financiera argentina",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Jornada sin restricciones",\n         "tipo": "EVENTO",\n         "alias": ["Jornada sin restricciones"],\n         "descripcion_contextual": "D√≠a sin restricciones para comprar d√≥lares",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Colapso",\n         "tipo": "CONCEPTO",\n         "alias": ["Colapso"],\n         "descripcion_contextual": "Problema t√©cnico en la plataforma virtual de bancos",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Falta de actualizaci√≥n",\n         "tipo": "CONCEPTO",\n         "alias": ["Falta de actualizaci√≥n"],\n         "descripcion_contextual": "Problema t√©cnico en la plataforma virtual de bancos",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Mercado de divisas",\n         "tipo": "CONCEPTO",\n         "alias": ["Mercado de divisas"],\n         "descripcion_contextual": "Pol√≠tica econ√≥mica argentina",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Reservas internacionales",\n         "tipo": "CONCEPTO",\n         "alias": ["Reservas internacionales"],\n         "descripcion_contextual": "Pol√≠tica econ√≥mica argentina",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "D√≥lar",\n         "tipo": "CONCEPTO",\n         "alias": ["D√≥lar"],\n         "descripcion_contextual": "Moneda estadounidense",\n         "relevancia_articulo": 10\n      },\n      {\n         "nombre": "Peso argentino",\n         "tipo": "CONCEPTO",\n         "alias": ["Peso argentino"],\n         "descripcion_contextual": "Moneda argentina",\n         "relevancia_articulo": 10\n      },\n      {\n         "nombre": "Cepo a la compra de divisas",\n         "tipo": "CONCEPTO",\n         "alias": ["Cepo a la compra de divisas"],\n         "descripcion_contextual": "Pol√≠tica econ√≥mica argentina",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Levantamiento del cepo cambiario",\n         "tipo": "CONCEPTO",\n         "alias": ["Levantamiento del cepo cambiario"],\n         "descripcion_contextual": "Pol√≠tica econ√≥mica argentina",\n         "relevancia_articulo": 8\n      },\n      {\n         "nombre": "Tasa nominal anual",\n         "tipo": "CONCEPTO",\n         "alias": ["Tasa nominal anual"],\n         "descripcion_contextual": "Pol√≠tica econ√≥mica argentina",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Banco Naci√≥n (plaza)",\n         "tipo": "LUGAR",\n         "alias": ["Banco Naci√≥n (plaza)"],\n         "descripcion_contextual": "Mercado de divisas argentino",\n         "relevancia_articulo": 6\n      },\n      {\n         "nombre": "Casa de cambio",\n         "tipo": "ORGANIZACION",\n         "alias": ["Casa de cambio"],\n         "descripcion_contextual": "Empresa que vende divisas",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Plataforma virtual de bancos",\n         "tipo": "CONCEPTO",\n         "alias": ["Plataforma virtual de bancos"],\n         "descripcion_contextual": "Sistema de compra de divisas en l√≠nea",\n         "relevancia_articulo": 5\n      },\n      {\n         "nombre": "Colapso del sistema",\n         "tipo": "CONCEPTO",\n         "alias": ["Colapso del sistema"],\n         "descripcion_contextual": "Problema t√©cnico en la plataforma virtual de bancos",\n         "relevancia_articulo": 5\n      }}'}}




[test_059] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:06<00:08,  1.40it/s][A[A[A[A2025-04-21 15:17:11,701 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:11,702 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:17:13,493 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_059] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:08<00:12,  1.10s/it][A[A[A[A2025-04-21 15:17:14,011 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_004] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:11<00:13,  1.91s/it][A2025-04-21 15:17:14,103 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:14,103 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:17:14,120 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_059] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:08<00:09,  1.05it/s][A[A[A[A2025-04-21 15:17:14,289 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:14,290 - ERROR - [test_004][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29214, Requested 1406. Please try again in 1.24s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_004] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:11<00:08,  1.43s/it][A2025-04-21 15:17:14,808 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:14,809 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:17:14,809 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_004] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:12<00:05,  1.16s/it][A2025-04-21 15:17:14,904 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:14,905 - ERROR - [test_059][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 28909, Requested 1652. Please try again in 1.122s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_059] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:09<00:08,  1.11it/s][A[A[A[A2025-04-21 15:17:15,065 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_059] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:09<00:05,  1.47it/s][A[A[A[A2025-04-21 15:17:15,231 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_022] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:15<00:05,  2.67s/it][A[A[A2025-04-21 15:17:15,238 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:15,291 - ERROR - [test_004][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30857, Requested 1777. Please try again in 5.268s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_004] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:12<00:03,  1.04it/s][A2025-04-21 15:17:16,060 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_022] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:15<00:02,  2.14s/it][A[A[A2025-04-21 15:17:16,194 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:16,195 - ERROR - [test_004][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32739, Requested 1555. Please try again in 8.587999999s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_004] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:13<00:02,  1.06it/s][A2025-04-21 15:17:16,769 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_059] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:11<00:06,  1.01it/s][A[A[A[A2025-04-21 15:17:16,898 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:16,899 - ERROR - [test_059][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32388, Requested 1801. Please try again in 8.379s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_059] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:11<00:04,  1.37it/s][A[A[A[A2025-04-21 15:17:19,461 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_059] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:14<00:06,  1.28s/it][A[A[A[A2025-04-21 15:17:19,788 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_059] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:14<00:03,  1.01it/s][A[A[A[A2025-04-21 15:17:20,256 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:20,257 - ERROR - [test_040][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30709, Requested 4477. Please try again in 10.373s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_040] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:22<00:15,  3.78s/it][A[A2025-04-21 15:17:20,894 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:20,895 - ERROR - [test_040][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30389, Requested 4626. Please try again in 10.03s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_040] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:23<00:09,  3.01s/it][A[A2025-04-21 15:17:21,212 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:21,213 - ERROR - [test_040][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30231, Requested 4738. Please try again in 9.938s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_040] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:23<00:04,  2.31s/it][A[A2025-04-21 15:17:21,348 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:21,349 - ERROR - [test_040][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 33153, Requested 4851. Please try again in 16.008s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_040] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:23<00:01,  1.73s/it][A[A2025-04-21 15:17:33,239 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:33,240 - ERROR - [test_058][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 35187, Requested 1134. Please try again in 12.643s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_058] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:38<00:15,  7.96s/it][A[A[A[A[A2025-04-21 15:17:33,377 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:33,377 - ERROR - [test_058][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 35118, Requested 1282. Please try again in 12.801s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_058] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:38<00:05,  5.92s/it][A[A[A[A[A2025-04-21 15:17:33,777 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:33,778 - ERROR - [test_022][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 34918, Requested 1518. Please try again in 12.873s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_022] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:33<00:00,  6.70s/it][A[A[A


                                                                         [A[A[A2025-04-21 15:17:33,793 - INFO - --- Art√≠culo test_022 completado ---
2025-04-21 15:17:33,793 - INFO - --- Procesando Art√≠culo: test_041 ---
2025-04-21 15:17:33,794 - INFO - [test_041] Lanzando 25 llamadas a Groq...



[test_041] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[AProgreso General Art√≠culos:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 42/72 [04:13<05:29, 10.98s/it]2025-04-21 15:17:34,042 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:34,042 - INFO - Retrying request to /openai/v1/chat/completions in 12.000000 seconds
2025-04-21 15:17:34,047 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:34,048 - INFO - Retrying request to /openai/v1/chat/completions in 12.000000 seconds
2025-04-21 15:17:34,122 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:34,123 - INFO - Retrying request to /openai/v1/chat/completions in 14.000000 seconds
2025-04-21 15:17:34,150 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:34,150 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:17:34,196 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:34,196 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:17:34,198 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:34,199 - ERROR - [test_058][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 34708, Requested 1395. Please try again in 12.207s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_058] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:39<00:00,  4.54s/it][A[A[A[A[A




                                                                         [A[A[A[A[A2025-04-21 15:17:34,210 - INFO - --- Art√≠culo test_058 completado ---
2025-04-21 15:17:34,211 - INFO - --- Procesando Art√≠culo: test_023 ---
2025-04-21 15:17:34,212 - INFO - [test_023] Lanzando 25 llamadas a Groq...





[test_023] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[A[AProgreso General Art√≠culos:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 43/72 [04:14<03:46,  7.81s/it]2025-04-21 15:17:34,412 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_041] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:14,  1.62it/s][A[A[A2025-04-21 15:17:34,449 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:34,454 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:34,473 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:34,474 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:17:34,474 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:34,475 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:34,476 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:17:34,476 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:17:34,488 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:34,489 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:17:34,491 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:34,568 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_041] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:00<00:02,  7.97it/s][A[A[A2025-04-21 15:17:34,588 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:34,589 - INFO - Retrying request to /openai/v1/chat/completions in 12.000000 seconds
2025-04-21 15:17:34,687 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:34,827 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_041] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:02,  7.88it/s][A[A[A2025-04-21 15:17:34,838 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_023] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:15,  1.59it/s][A[A[A[A[A2025-04-21 15:17:34,892 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:34,894 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:35,063 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_041] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:01,  8.08it/s][A[A[A2025-04-21 15:17:35,173 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:35,222 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_041] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:01,  9.17it/s][A[A[A2025-04-21 15:17:35,285 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_023] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:01<00:07,  3.05it/s][A[A[A[A[A2025-04-21 15:17:35,341 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:35,379 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:35,381 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_041] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:01<00:01, 10.07it/s][A[A[A2025-04-21 15:17:35,399 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_023] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:05,  3.93it/s][A[A[A[A[A2025-04-21 15:17:35,461 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:35,496 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_041] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:01<00:00, 13.42it/s][A[A[A2025-04-21 15:17:35,500 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_023] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:04,  4.91it/s][A[A[A[A[A2025-04-21 15:17:35,623 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:35,836 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_023] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:04,  4.07it/s][A[A[A[A[A2025-04-21 15:17:35,887 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_041] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:02<00:00,  9.23it/s][A[A[A2025-04-21 15:17:35,926 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:35,942 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:17:35,943 - ERROR - [test_023][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Esta ley tambi√©n velar√° por el supremo inter√©s de la democracia, la unidad nacional y poner bajo una revisi√≥n exhaustiva a una minor√≠a de ONG que act√∫an en contra de los intereses de nuestro pa√≠s, sembrando odio y atacando nuestro sistema"",\n         "emisor_nombre": "Dina Boluarte",\n         "contexto": "Discurso de la presidenta en la ceremonia de promulgaci√≥n de la ley",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Organizaciones que no est√°n comprometidas con el bienestar de la naci√≥n, sino que buscan desestabilizar y promover la divisi√≥n, utilizando recursos de la cooperaci√≥n internacional para avanzar su propia agenda ideol√≥gica. Sigamos trabajando juntos sin permitir que utilicen a la democracia para lucrar en nombre de la libertad, utilizando el libertinaje para introducir agendas internacionales que buscan quebrar nuestra unidad nacional, sembrando el odio entre peruanos"",\n         "emisor_nombre": "Dina Boluarte",\n         "contexto": "Discurso de la presidenta en la ceremonia de promulgaci√≥n de la ley",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Hemos dado un paso firme y decidido en favor de la transparencia"",\n         "emisor_nombre": "Dina Boluarte",\n         "contexto": "Discurso de la presidenta en la ceremonia de promulgaci√≥n de la ley",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Hoy hemos dado un paso firme y decidido en favor de la transparencia, de la buena gesti√≥n p√∫blica y del fortalecimiento de nuestra democracia"",\n         "emisor_nombre": "Dina Boluarte",\n         "contexto": "Discurso de la presidenta en la ceremonia de promulgaci√≥n de la ley",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""No se trata de control, se trata de claridad, no se trata de fiscalizaci√≥n arbitraria, sino de rendici√≥n de cuentas"",\n         "emisor_nombre": "Dina Boluarte",\n         "contexto": "Discurso de la presidenta en la ceremonia de promulgaci√≥n de la ley",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Es un medio importante para que la cooperaci√≥n internacional siga siendo un aliado estrat√©gico del desarrollo del pa√≠s, con reglas claras, mecanismos eficaces de supervisi√≥n y la confianza que s√≥lo se logra con total transparencia"",\n         "emisor_nombre": "Dina Boluarte",\n         "contexto": "Discurso de la presidenta en la ceremonia de promulgaci√≥n de la ley",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}





[test_023] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  6.51it/s][A[A[A[A[A2025-04-21 15:17:35,946 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:36,087 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_023] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01,  8.28it/s][A[A[A[A[A2025-04-21 15:17:36,139 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:36,148 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:36,253 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_023] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:01,  9.35it/s][A[A[A[A[A2025-04-21 15:17:36,303 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:36,672 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_023] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:02<00:01,  7.03it/s][A[A[A[A[A2025-04-21 15:17:36,683 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_041] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:02<00:00,  5.23it/s][A[A[A2025-04-21 15:17:36,717 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:36,752 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:37,636 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_041] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:03<00:01,  3.12it/s][A[A[A2025-04-21 15:17:37,665 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:37,693 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_023] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:03<00:01,  4.42it/s][A[A[A[A[A2025-04-21 15:17:38,197 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_023] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:03<00:01,  3.66it/s][A[A[A[A[A2025-04-21 15:17:38,983 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_023] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:04<00:02,  2.69it/s][A[A[A[A[A2025-04-21 15:17:39,146 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_059] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:33<00:19,  6.50s/it][A[A[A[A2025-04-21 15:17:39,617 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_023] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:05<00:02,  2.33it/s][A[A[A[A[A2025-04-21 15:17:39,708 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:17:39,710 - ERROR - [test_041][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad, tomemos decisiones acertadas, decisiones responsables, no pongamos en riesgo lo m√°s importante, nuestra vida y de la vida de los dem√°s"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Los operativos de seguridad est√°n desplegados en todo el pa√≠s como cada a√±o, pero la verdadera prevenci√≥n comienza con cada uno de nosotros, y con cada uno, recuerden, no hay m√°s prueba de amor que cuidarnos, no hay m√°s gesto de amor que cuidar a los nuestros, ese es el mensaje que le queremos dejar para esta Semana Santa"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Cuid√©monos, cuid√©monos de verdad"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Mensaje del presidente durante su encuentro con la prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }}'}}



[test_041] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:05<00:01,  1.80it/s][A[A[A2025-04-21 15:17:40,161 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_059] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:34<00:09,  4.86s/it][A[A[A[A2025-04-21 15:17:45,064 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_059] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:39<00:04,  4.87s/it][A[A[A[A2025-04-21 15:17:47,044 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_023] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:12<00:08,  2.08s/it][A[A[A[A[A2025-04-21 15:17:47,281 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:47,282 - ERROR - [test_004][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29322, Requested 1555. Please try again in 1.754s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_004] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:44<00:19,  9.93s/it][A2025-04-21 15:17:47,289 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_041] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:13<00:01,  1.88s/it][A[A[A2025-04-21 15:17:47,407 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_041] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:13<00:00,  1.51s/it][A[A[A


                                                                         [A[A[A2025-04-21 15:17:47,426 - INFO - --- Art√≠culo test_041 completado ---
2025-04-21 15:17:47,426 - INFO - --- Procesando Art√≠culo: test_005 ---
2025-04-21 15:17:47,427 - INFO - [test_005] Lanzando 25 llamadas a Groq...



[test_005] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[AProgreso General Art√≠culos:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 44/72 [04:27<04:24,  9.43s/it]2025-04-21 15:17:47,590 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:47,595 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:17:47,676 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:47,677 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:17:47,680 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:47,681 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:17:47,682 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:47,682 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:17:47,683 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:47,683 - INFO - Retrying request to /openai/v1/chat/completions in 11.000000 seconds
2025-04-21 15:17:47,689 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:47,689 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:17:47,690 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:47,691 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:17:47,691 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:47,692 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:17:47,699 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:47,700 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:17:47,797 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:47,798 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:17:47,798 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:47,799 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:17:47,809 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:47,810 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:17:48,034 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_005] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:14,  1.64it/s][A[A[A2025-04-21 15:17:48,134 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:48,209 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:48,210 - ERROR - [test_004][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30568, Requested 1777. Please try again in 4.691s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_004] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:45<00:07,  7.24s/it][A2025-04-21 15:17:48,336 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_004] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:45<00:00,  5.11s/it][A
                                                                         [A2025-04-21 15:17:48,349 - INFO - --- Art√≠culo test_004 completado ---
2025-04-21 15:17:48,349 - INFO - --- Procesando Art√≠culo: test_060 ---
2025-04-21 15:17:48,350 - INFO - [test_060] Lanzando 25 llamadas a Groq...

[test_060] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][AProgreso General Art√≠culos:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 45/72 [04:28<03:05,  6.88s/it]2025-04-21 15:17:48,503 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_005] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:01<00:07,  3.02it/s][A[A[A2025-04-21 15:17:48,593 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:48,594 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:17:48,595 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:48,596 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:17:48,597 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:48,598 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:17:48,602 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:48,603 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:17:48,621 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:48,622 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:17:48,648 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:48,650 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_005] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:05,  3.74it/s][A[A[A2025-04-21 15:17:48,697 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:48,697 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:17:48,843 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_060] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:11,  2.02it/s][A2025-04-21 15:17:48,937 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:48,974 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_005] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:04,  4.65it/s][A[A[A2025-04-21 15:17:49,027 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:49,046 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_060] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:04,  4.92it/s][A2025-04-21 15:17:49,091 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:49,234 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_060] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:00<00:02,  6.79it/s][A2025-04-21 15:17:49,289 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_005] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:03,  5.23it/s][A[A[A2025-04-21 15:17:49,297 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:49,341 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:49,404 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_060] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:02,  6.52it/s][A2025-04-21 15:17:49,444 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:17:49,446 - ERROR - [test_005][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Gano la Presidencia, cierro el Congreso y convoco a una constituyente para resetear este pa√≠s, porque, as√≠ como est√°, el pa√≠s no funciona. No hay que tenerlo miedo a esta generaci√≥n. Esta generaci√≥n est√° lista para plantear una nueva institucionalidad"",\n         "emisor_nombre": "Daniel Quintero Calle",\n         "contexto": "En una entrevista con la revista Cambio",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Pues lo primero es que hay que cerrar el Congreso. Este Congreso no cambia ni deja que el pa√≠s cambie. Es un Congreso que solo se une para lo malo. Cuando hay que aprobar algo malo para la gente, piden 3.000 millones de pesos. Y para algo que es bueno para la gente, piden el doble. Es un Congreso que no representa al pa√≠s. Gano la Presidencia, cierro el Congreso y convoco a una constituyente para resetear este pa√≠s, porque, as√≠ como est√°, el pa√≠s no funciona. No hay que tenerle miedo a esta generaci√≥n. Esta generaci√≥n est√° lista para plantear una nueva institucionalidad"",\n         "emisor_nombre": "Daniel Quintero Calle",\n         "contexto": "En una entrevista con la revista Cambio",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Puede gustarnos o no. Podemos criticarlo las veces que queramos y estar en desacuerdo con las pr√°cticas corruptas de muchos de sus miembros, pero el Congreso de la Rep√∫blica, pilar de la democracia, nunca se cierra. Nunca. Hacerlo es de dictadores"",\n         "emisor_nombre": "Gustavo Bol√≠var",\n         "contexto": "En su cuenta oficial de X (antes Twitter)",\n         "fecha_cita": "2025-04-14",\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Puede gustarnos o no. Podemos criticarlo las veces que queramos y estar en desacuerdo con las pr√°cticas corruptas de muchos de sus miembros‚Ä¶ pero el Congreso de la Rep√∫blica, pilar de la democracia, nunca se cierra. Nunca."",\n         "emisor_nombre": "Gustavo Bol√≠var",\n         "contexto": "En su cuenta oficial de X (antes Twitter)",\n         "fecha_cita": "2025-04-14",\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Hacerlo es de dictadores."",\n         "emisor_nombre": "Gustavo Bol√≠var",\n         "contexto": "En su cuenta oficial de X (antes Twitter)",\n         "fecha_cita": "2025-04-14",\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""El Congreso no tiene la culpa de lo que pasa. La culpa es de los congresistas, que es distinto. Entonces, lo que toca es cambiar a los congresistas. El √∫nico camino democr√°tico posible es tener mayor√≠as: 55/86""",\n         "emisor_nombre": "Gustavo Bol√≠var",\n         "contexto": "En su cuenta oficial de X (antes Twitter)",\n         "fecha_cita": "2025-04-14",\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Respeto a Bol√≠var. Lo llamo a la unidad. Juntos a resetear la pol√≠tica, a cerrar el congreso, a darle Control+Alt+Suprimir a lo que no sirva (sic)""",\\n         "emisor_nombre": "Daniel Quintero Calle",\\n         "contexto": "En respuesta a Gustavo Bol√≠var",\\n         "fecha_cita": null,\\n         "relevancia_cita": 5\\n      },\\n      {\\n         "cita": ""Qu√© miserable hay que ser para amenazar tan abierta y c√≥modamente las bases de la democracia. Lo de @QuinteroCalle es un descaro y una burla institucional. Es una de las muchas evidencias de por qu√© el petrismo no sirve para nada"",\\n         "emisor_nombre": "Wilson Ruiz",\\n         "contexto": "En respuesta a Daniel Quintero Calle",\\n         "fecha_cita": null,\\n         "relevancia_cita": 5\\n      },\\n      {\\n         "cita": ""Este cree que con m√°s amenazas y m√°s caos, al estilo Petro, va a lograr ganar votos. Es Claudia L√≥pez en hombre. Peligrosos. En el pa√≠s hay que ‚Äòresetear‚Äô la pol√≠tica, pero de personajes como usted"",\\n         "emisor_nombre": "Vicky D√°vila",\\n         "contexto": "En respuesta a Daniel Quintero Calle",\\n         "fecha_cita": null,\\n         "relevancia_cita": 4\\n      }\\n   ]\\n}'}}
2025-04-21 15:17:49,447 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_005] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:02<00:01,  7.94it/s][A[A[A2025-04-21 15:17:49,724 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:49,730 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:17:49,732 - ERROR - [test_060][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Los funcionarios citados que participaron en esta operaci√≥n no ten√≠an ninguna excusa, porque no pueden andar guiados, coachings o dirigidos por otra persona"",\n         "emisor_nombre": "Andr√©s Longton",\n         "contexto": "Durante la comisi√≥n investigadora por la fallida compra de la casa de Allende",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""esto no es una citaci√≥n institucional. Ya no estamos en el jard√≠n infantil y no se necesita la supervisi√≥n del ministro que ten√≠a, por supuesto, una excusa muy atendible"",\n         "emisor_nombre": "Paula Labra",\n         "contexto": "Durante la comisi√≥n investigadora por la fallida compra de la casa de Allende",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""eran determinantes las declaraciones que pod√≠an dar los funcionarios citados ac√° en la comisi√≥n investigadora y que lamentablemente terminan retrasando esta investigaci√≥n"",\n         "emisor_nombre": "Andr√©s Longton",\n         "contexto": "Durante la comisi√≥n investigadora por la fallida compra de la casa de Allende",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""los funcionarios p√∫blicos ten√≠an la responsabilidad y el deber de asistir"",\n         "emisor_nombre": "Paula Labra",\n         "contexto": "Durante la comisi√≥n investigadora por la fallida compra de la casa de Allende",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""ya confirm√≥ que va a venir. Tenemos que reagendar la fecha porque tambi√©n tuvo un problema de salud"",\n         "emisor_nombre": "Andr√©s Longton",\n         "contexto": "Respecto de la exjefa jur√≠dica de BB.NN que particip√≥ en el proceso de la fallida compra de la casa del expresidente Allende",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""no teniendo la obligaci√≥n, manifest√≥ su disposici√≥n. Lo mismo la exministra Marcela Sandoval, que est√° invitada y ya confirm√≥ para el pr√≥ximo d√≠a lunes"",\n         "emisor_nombre": "Andr√©s Longton",\n         "contexto": "Respecto de la pr√≥ximas sesiones de la comisi√≥n investigadora",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      }\n   ]\n}'}}

[test_060] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  6.35it/s][A2025-04-21 15:17:49,834 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_060] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:02,  6.91it/s][A2025-04-21 15:17:49,845 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:50,004 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_060] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:01,  8.29it/s][A2025-04-21 15:17:50,093 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:50,301 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_005] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:02<00:02,  4.56it/s][A[A[A2025-04-21 15:17:50,503 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_060] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:02<00:02,  5.96it/s][A2025-04-21 15:17:50,822 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_060] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:02<00:02,  5.02it/s][A2025-04-21 15:17:50,923 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_060] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:02<00:01,  5.65it/s][A2025-04-21 15:17:51,321 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_005] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:03<00:04,  2.75it/s][A[A[A2025-04-21 15:17:51,383 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_060] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:03<00:02,  4.06it/s][A2025-04-21 15:17:51,612 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_060] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:03<00:01,  4.13it/s][A2025-04-21 15:17:52,177 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_059] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:46<00:00,  5.54s/it][A[A[A[A



                                                                         [A[A[A[A2025-04-21 15:17:52,196 - INFO - --- Art√≠culo test_059 completado ---
2025-04-21 15:17:52,196 - INFO - --- Procesando Art√≠culo: test_042 ---
2025-04-21 15:17:52,197 - INFO - [test_042] Lanzando 25 llamadas a Groq...




[test_042] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[AProgreso General Art√≠culos:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 46/72 [04:32<02:35,  5.97s/it]2025-04-21 15:17:52,262 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_005] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:04<00:04,  2.07it/s][A[A[A2025-04-21 15:17:52,382 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:52,383 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:17:52,480 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:52,481 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:17:52,484 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:52,485 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:17:52,499 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:52,500 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:17:52,527 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:52,528 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:17:52,551 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:52,552 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:17:52,558 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:52,559 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:17:52,668 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_060] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:04<00:03,  2.16it/s][A2025-04-21 15:17:52,787 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_042] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:14,  1.69it/s][A[A[A[A2025-04-21 15:17:52,791 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:52,810 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:52,811 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:52,812 - ERROR - [test_023][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29002, Requested 1499. Please try again in 1.002s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:17:52,813 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds





[test_023] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:18<00:09,  3.01s/it][A[A[A[A[A2025-04-21 15:17:52,826 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:52,827 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:17:52,878 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:52,882 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:52,883 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_005] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:05<00:04,  1.95it/s][A[A[A2025-04-21 15:17:52,902 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:52,903 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:17:52,905 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:52,906 - ERROR - [test_023][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 28955, Requested 1648. Please try again in 1.205s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:17:52,955 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:52,956 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:17:52,978 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:52,999 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:53,000 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:17:53,035 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:53,035 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:17:53,066 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_042] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:00<00:02,  6.78it/s][A[A[A[A2025-04-21 15:17:53,094 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:53,096 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:53,179 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_060] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:04<00:02,  2.10it/s][A2025-04-21 15:17:53,256 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_042] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:01,  9.32it/s][A[A[A[A2025-04-21 15:17:53,390 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:53,398 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:53,399 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:17:53,402 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_042] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01, 10.36it/s][A[A[A[A2025-04-21 15:17:53,447 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:53,496 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:53,497 - ERROR - [test_040][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31256, Requested 4738. Please try again in 11.989s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_040] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:55<00:00, 10.19s/it][A[A

                                                                         [A[A2025-04-21 15:17:53,510 - INFO - --- Art√≠culo test_040 completado ---
2025-04-21 15:17:53,510 - INFO - --- Procesando Art√≠culo: test_024 ---
2025-04-21 15:17:53,511 - INFO - [test_024] Lanzando 25 llamadas a Groq...


[test_024] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[AProgreso General Art√≠culos:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 47/72 [04:33<01:54,  4.57s/it]2025-04-21 15:17:53,570 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_042] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:01<00:01, 10.78it/s][A[A[A[A2025-04-21 15:17:53,644 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_060] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:05<00:02,  2.10it/s][A2025-04-21 15:17:53,686 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:53,689 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_005] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:06<00:03,  2.13it/s][A[A[A2025-04-21 15:17:53,732 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_042] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:01<00:00, 11.23it/s][A[A[A[A2025-04-21 15:17:53,747 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:53,748 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:17:53,754 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:53,755 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:17:53,756 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:53,757 - ERROR - [test_023][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30222, Requested 1760. Please try again in 3.964s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_023] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:19<00:01,  1.95s/it][A[A[A[A[A2025-04-21 15:17:53,760 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:53,761 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:17:53,773 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:53,775 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"


[test_024] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:06,  3.78it/s][A[A2025-04-21 15:17:53,776 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:17:53,782 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:53,784 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:53,785 - ERROR - [test_023][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30207, Requested 1881. Please try again in 4.176s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





                                                                         [A[A[A[A[A2025-04-21 15:17:53,799 - INFO - --- Art√≠culo test_023 completado ---
2025-04-21 15:17:53,800 - INFO - --- Procesando Art√≠culo: test_006 ---
2025-04-21 15:17:53,800 - INFO - [test_006] Lanzando 25 llamadas a Groq...





[test_006] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[A[AProgreso General Art√≠culos:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 48/72 [04:33<01:18,  3.29s/it]2025-04-21 15:17:53,856 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:53,862 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:17:53,863 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:53,864 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:53,865 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:53,869 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:17:53,870 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:17:53,975 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:53,990 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:53,991 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_024] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:03,  6.70it/s][A[A2025-04-21 15:17:54,045 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:54,050 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:54,051 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:17:54,057 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:54,058 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:17:54,069 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:54,070 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:17:54,071 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:54,072 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:17:54,078 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:54,079 - ERROR - [test_060][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30059, Requested 1333. Please try again in 2.784s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_060] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:05<00:01,  2.17it/s][A2025-04-21 15:17:54,083 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:54,084 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:17:54,085 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:54,086 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:17:54,088 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:54,088 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:17:54,090 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:54,169 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:54,172 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_024] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:00<00:01, 14.94it/s][A[A2025-04-21 15:17:54,185 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:54,186 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:17:54,191 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:54,192 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:17:54,209 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:54,210 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:17:54,219 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:54,220 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:17:54,251 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:54,325 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_024] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:00<00:00, 16.39it/s][A[A2025-04-21 15:17:54,329 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:54,330 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:17:54,449 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_006] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:15,  1.54it/s][A[A[A[A[A2025-04-21 15:17:54,476 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:54,520 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_024] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:01<00:00, 14.13it/s][A[A2025-04-21 15:17:54,595 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:54,596 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:17:54,614 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:54,615 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:17:54,628 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:54,652 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_006] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:08,  2.58it/s][A[A[A[A[A2025-04-21 15:17:54,724 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:54,797 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:54,798 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:17:54,834 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_060] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:06<00:01,  1.83it/s][A2025-04-21 15:17:54,839 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_024] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:01<00:00, 10.48it/s][A[A2025-04-21 15:17:54,948 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_042] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:02,  4.05it/s][A[A[A[A2025-04-21 15:17:55,010 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:55,011 - ERROR - [test_005][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30498, Requested 1581. Please try again in 4.158s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_005] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:07<00:03,  1.52it/s][A[A[A2025-04-21 15:17:55,013 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_006] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:05,  3.88it/s][A[A[A[A[A2025-04-21 15:17:55,126 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_006] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:04,  4.69it/s][A[A[A[A[A2025-04-21 15:17:55,164 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:55,309 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:55,371 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_006] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:03,  5.87it/s][A[A[A[A[A2025-04-21 15:17:55,528 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:17:55,530 - ERROR - [test_006][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Pretenden imponer por la fuerza una hegemon√≠a pol√≠tica, como hicieron en Ecuador con un fraude inaudible para instalar un proyecto colonialista"",\n         "emisor_nombre": "Nicol√°s Maduro",\n         "contexto": "Durante un acto con candidatos oficialistas transmitido por Venezolana de Televisi√≥n (VTV)",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""dictador"",\n         "emisor_nombre": "Nicol√°s Maduro",\n         "contexto": "Se refiri√≥ al presidente de Ecuador, Daniel Noboa",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""el mundo es otro"",\n         "emisor_nombre": "Nicol√°s Maduro",\n         "contexto": "Afirma que el mundo ha cambiado y que la causa de los pueblos del sur global triunfar√°",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""la causa de los pueblos del sur global"",\n         "emisor_nombre": "Nicol√°s Maduro",\n         "contexto": "Afirma que esta causa triunfar√°",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""la hegemon√≠a absoluta de Estados Unidos"",\n         "emisor_nombre": "Nicol√°s Maduro",\n         "contexto": "Afirma que el mundo enfrenta una gran amenaza geopol√≠tica por esta hegemon√≠a",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""un fraude horroroso"",\n         "emisor_nombre": "Nicol√°s Maduro",\n         "contexto": "Se refiere a los comicios del domingo en Ecuador",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un fraude inaudible"",\n         "emisor_nombre": "Nicol√°s Maduro",\n         "contexto": "Se refiere a los comicios del domingo en Ecuador",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""apoyo y financiamiento del imperialismo"",\n         "emisor_nombre": "Nicol√°s Maduro",\n         "contexto": "Afirma que el supuesto fraude cont√≥ con este apoyo",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Gan√≥ Ecuador, las Am√©ricas, la libertad y la democracia"",\n         "emisor_nombre": "Mar√≠a Corina Machado",\n         "contexto": "Celebr√≥ la victoria de Daniel Noboa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""transparente y participativo"",\n         "emisor_nombre": "Edmundo Gonz√°lez Urrutia",\n         "contexto": "Elogi√≥ el proceso electoral en Ecuador",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}





[test_006] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  5.98it/s][A[A[A[A[A2025-04-21 15:17:55,538 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:55,555 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:56,003 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_006] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:02<00:02,  6.15it/s][A[A[A[A[A2025-04-21 15:17:56,022 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:56,182 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_060] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:07<00:01,  1.28it/s][A2025-04-21 15:17:56,196 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:56,197 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:17:56,616 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_006] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:02<00:02,  4.76it/s][A[A[A[A[A2025-04-21 15:17:56,798 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_024] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:03<00:02,  2.89it/s][A[A2025-04-21 15:17:57,046 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_006] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:03<00:02,  3.95it/s][A[A[A[A[A2025-04-21 15:17:57,142 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_042] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:04<00:04,  1.68it/s][A[A[A[A2025-04-21 15:17:57,145 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:57,146 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:17:57,147 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:57,148 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:17:57,252 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_024] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:03<00:02,  2.75it/s][A[A2025-04-21 15:17:57,288 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:57,289 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:17:57,327 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:57,328 - ERROR - [test_042][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30159, Requested 493. Please try again in 1.305s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_042] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:05<00:03,  1.96it/s][A[A[A[A2025-04-21 15:17:57,329 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:57,419 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:57,420 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:17:57,468 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:57,470 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:17:57,618 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:57,619 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:17:57,655 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:57,656 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:17:57,689 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:57,690 - ERROR - [test_042][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30492, Requested 876. Please try again in 2.736s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_042] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:05<00:02,  2.09it/s][A[A[A[A2025-04-21 15:17:57,699 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:57,700 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:17:57,781 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:57,783 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:17:57,860 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:57,861 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:17:58,910 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:58,911 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:58,912 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:58,912 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:58,913 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:58,914 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:17:58,925 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:17:58,926 - ERROR - [test_042][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30387, Requested 754. Please try again in 2.283s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:17:58,927 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds




[test_042] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:06<00:03,  1.51it/s][A[A[A[A

[test_024] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:05<00:02,  1.93it/s][A[A




[test_006] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:05<00:06,  1.66it/s][A[A[A[A[A2025-04-21 15:17:59,004 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:59,005 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:17:59,015 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:59,016 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:17:59,022 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:59,023 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:17:59,024 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:59,024 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:17:59,026 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:59,027 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:17:59,030 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:59,031 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:17:59,041 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:59,041 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:17:59,047 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:59,048 - ERROR - [test_005][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32431, Requested 1364. Please try again in 7.59s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_005] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:11<00:07,  1.46s/it][A[A[A2025-04-21 15:17:59,055 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:59,057 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:17:59,065 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:59,066 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:17:59,135 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:59,136 - ERROR - [test_005][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32386, Requested 1477. Please try again in 7.727s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:17:59,140 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:59,141 - ERROR - [test_006][relevancia][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29665, Requested 937. Please try again in 1.203s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_006] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:05<00:03,  2.42it/s][A[A[A[A[A2025-04-21 15:17:59,311 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:59,312 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:17:59,487 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:17:59,489 - ERROR - [test_005][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32212, Requested 1216. Please try again in 6.856s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_005] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:12<00:02,  1.04it/s][A[A[A2025-04-21 15:18:00,641 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:00,642 - ERROR - [test_042][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30447, Requested 642. Please try again in 2.179s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_042] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:08<00:03,  1.07it/s][A[A[A[A2025-04-21 15:18:00,870 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:00,871 - ERROR - [test_005][relevancia][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30290, Requested 1006. Please try again in 2.593s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_005] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:13<00:02,  1.05s/it][A[A[A2025-04-21 15:18:01,413 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_042] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:09<00:02,  1.12it/s][A[A[A[A2025-04-21 15:18:01,791 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:01,792 - ERROR - [test_060][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29832, Requested 1185. Please try again in 2.033999999s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_060] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:13<00:02,  2.21s/it][A2025-04-21 15:18:03,029 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:03,030 - ERROR - [test_005][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29212, Requested 1216. Please try again in 855ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_005] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:15<00:01,  1.32s/it][A[A[A2025-04-21 15:18:05,021 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_006] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:11<00:11,  1.58s/it][A[A[A[A[A2025-04-21 15:18:05,597 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_024] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:12<00:06,  1.68s/it][A[A2025-04-21 15:18:05,893 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_006] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:12<00:08,  1.41s/it][A[A[A[A[A2025-04-21 15:18:05,975 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_042] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:13<00:03,  1.91s/it][A[A[A[A2025-04-21 15:18:06,141 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_024] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:12<00:04,  1.44s/it][A[A2025-04-21 15:18:06,177 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:06,178 - ERROR - [test_042][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29408, Requested 754. Please try again in 323ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_042] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:13<00:01,  1.42s/it][A[A[A[A2025-04-21 15:18:06,220 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:06,227 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:06,228 - ERROR - [test_006][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29381, Requested 1022. Please try again in 805ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_006] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:12<00:05,  1.14s/it][A[A[A[A[A2025-04-21 15:18:06,232 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:06,233 - ERROR - [test_006][relevancia][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29379, Requested 937. Please try again in 631ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:06,290 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:06,291 - ERROR - [test_006][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29352, Requested 874. Please try again in 451ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:06,296 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_024] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:12<00:00,  1.08it/s][A[A2025-04-21 15:18:06,789 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_042] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:14<00:00,  1.19s/it][A[A[A[A



                                                                         [A[A[A[A2025-04-21 15:18:06,801 - INFO - --- Art√≠culo test_042 completado ---
2025-04-21 15:18:06,801 - INFO - --- Procesando Art√≠culo: test_061 ---
2025-04-21 15:18:06,802 - INFO - [test_061] Lanzando 25 llamadas a Groq...




[test_061] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[AProgreso General Art√≠culos:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 49/72 [04:46<02:22,  6.20s/it]2025-04-21 15:18:06,858 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_006] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:13<00:01,  1.51it/s][A[A[A[A[A2025-04-21 15:18:07,030 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:07,031 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:07,068 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:07,069 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:07,072 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:07,072 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:18:07,120 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:07,121 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:07,144 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:07,144 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:07,157 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:07,158 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:07,231 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_061] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:10,  2.32it/s][A[A[A[A2025-04-21 15:18:07,306 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:07,333 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_061] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:03,  6.70it/s][A[A[A[A2025-04-21 15:18:07,383 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:07,384 - ERROR - [test_006][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30015, Requested 1135. Please try again in 2.3s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_006] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:13<00:00,  1.58it/s][A[A[A[A[A2025-04-21 15:18:07,452 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:07,452 - ERROR - [test_006][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29834, Requested 1235. Please try again in 2.137s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





                                                                         [A[A[A[A[A2025-04-21 15:18:07,465 - INFO - --- Art√≠culo test_006 completado ---
2025-04-21 15:18:07,465 - INFO - --- Procesando Art√≠culo: test_043 ---
2025-04-21 15:18:07,465 - INFO - [test_043] Lanzando 25 llamadas a Groq...





[test_043] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[A[AProgreso General Art√≠culos:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 50/72 [04:47<01:39,  4.54s/it]2025-04-21 15:18:07,520 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:07,521 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_060] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:19<00:00,  3.26s/it][A
                                                                         [A2025-04-21 15:18:07,536 - INFO - --- Art√≠culo test_060 completado ---
2025-04-21 15:18:07,538 - INFO - --- Procesando Art√≠culo: test_025 ---
2025-04-21 15:18:07,540 - INFO - [test_025] Lanzando 25 llamadas a Groq...

[test_025] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A2025-04-21 15:18:07,762 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:07,772 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:07,790 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:07,794 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_061] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:00<00:03,  5.23it/s][A[A[A[A2025-04-21 15:18:07,798 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:07,802 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:18:07,807 - ERROR - [test_061][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Gano la Presidencia, cierro el Congreso y convoco a una constituyente para resetear este pa√≠s, porque, as√≠ como est√°, el pa√≠s no funciona. No hay que tenerlo miedo a esta generaci√≥n. Esta generaci√≥n est√° lista para plantear una nueva institucionalidad"",\n         "emisor_nombre": "Daniel Quintero Calle",\n         "contexto": "Entrevista en la revista Cambio",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Puede gustarnos o no. Podemos criticarlo las veces que queramos y estar en desacuerdo con las pr√°cticas corruptas de muchos de sus miembros, pero el Congreso de la Rep√∫blica, pilar de la democracia, nunca se cierra. Nunca. Hacerlo es de dictadores"",\n         "emisor_nombre": "Gustavo Bol√≠var",\n         "contexto": "Respuesta a Daniel Quintero Calle en redes sociales",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}
2025-04-21 15:18:07,837 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:07,838 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:07,847 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:07,848 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:07,872 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:07,873 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:18:07,873 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:07,874 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:18:07,875 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:07,875 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:07,880 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:07,880 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:18:07,895 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:07,896 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:07,927 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:07,928 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:07,952 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_005] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:20<00:00,  2.25s/it][A[A[A


                                                                         [A[A[A2025-04-21 15:18:07,965 - INFO - --- Art√≠culo test_005 completado ---
2025-04-21 15:18:07,965 - INFO - --- Procesando Art√≠culo: test_007 ---
2025-04-21 15:18:07,966 - INFO - [test_007] Lanzando 25 llamadas a Groq...



[test_007] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[AProgreso General Art√≠culos:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 52/72 [04:48<00:51,  2.56s/it]2025-04-21 15:18:08,027 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,031 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:08,032 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,034 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,035 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,036 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,037 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,038 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,039 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:08,040 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,041 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,044 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:18:08,044 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:08,045 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:08,045 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:08,046 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:08,046 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:08,047 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:18:08,047 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:08,048 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,049 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:08,052 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"




[test_061] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:01,  8.65it/s][A[A[A[A2025-04-21 15:18:08,053 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:18:08,054 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:18:08,055 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:18:08,057 - ERROR - [test_043][relevancia][llama-3.3-70b-versatile] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "puntuacion_relevancia": 8,\n   "justificacion_relevancia": "Detenci√≥n de l√≠der criminal",\n   "categorias_asignadas": [\n       "Conflicto/Seguridad",\n       "Justicia/Legal"\n   ],\n   "resumen_breve": "Detienen a "El Gangoso", l√≠der de c√©lula delictiva"\n}'}}





[test_043] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:14,  1.67it/s][A[A[A[A[A2025-04-21 15:18:08,065 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:08,130 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:08,195 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_061] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:01<00:00, 12.64it/s][A[A[A[A2025-04-21 15:18:08,215 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,216 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:18:08,217 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,217 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:08,225 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_043] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:07,  2.92it/s][A[A[A[A[A2025-04-21 15:18:08,229 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,230 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:18:08,261 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:08,266 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:08,271 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,272 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:18:08,274 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,274 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:18:08,331 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,332 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:08,338 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,338 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:08,345 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,346 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:18:08,347 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,347 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:08,364 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:08,365 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:08,425 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_061] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:01<00:00, 12.77it/s][A[A[A[A2025-04-21 15:18:08,560 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_043] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:01<00:07,  2.95it/s][A[A[A[A[A2025-04-21 15:18:08,585 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:08,601 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_025] Llamadas Groq:   4%|‚ñç         | 1/25 [00:01<00:25,  1.06s/it][A2025-04-21 15:18:08,613 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:08,663 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_043] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:03,  5.67it/s][A[A[A[A[A2025-04-21 15:18:08,756 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_061] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:01<00:00, 10.09it/s][A[A[A[A2025-04-21 15:18:09,027 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_025] Llamadas Groq:   8%|‚ñä         | 2/25 [00:01<00:15,  1.45it/s][A2025-04-21 15:18:09,074 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:09,077 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_007] Llamadas Groq:   4%|‚ñç         | 1/25 [00:01<00:26,  1.11s/it][A[A[A2025-04-21 15:18:09,225 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_007] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:01<00:07,  2.91it/s][A[A[A2025-04-21 15:18:09,261 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:09,262 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:09,292 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:18:09,293 - ERROR - [test_007][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Estas personas fueron detenidas por el usurpador y sus cuerpos de seguridad √∫nicamente por pensar diferente. Ellos son el ejemplo de democracia, libertad y de una manera distinta de ver el pa√≠s. Su √∫nico ‚Äòdelito‚Äô fue ser testigos electorales"",\n         "emisor_nombre": "Yandir Loggiodice",\n         "contexto": "Comunicado del secretario general nacional del Partido Centro Democr√°tico (PCD)",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Como partido, recordamos a la comunidad internacional la solicitud que hicimos hace exactamente tres meses a la Corte Penal Internacional. En ella exigimos que, como parte del proceso de investigaci√≥n que se lleva a cabo sobre Venezuela, se designe un especialista que pueda ingresar a los centros de reclusi√≥n para evaluar el estado f√≠sico y mental de los detenidos"",\n         "emisor_nombre": "Yandir Loggiodice",\n         "contexto": "Comunicado del secretario general nacional del Partido Centro Democr√°tico (PCD)",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Reiteramos a la Corte Penal Internacional que tienen la potestad de exigir, como parte del proceso de investigaci√≥n en curso, el ingreso de personal especializado que pueda evaluar a los m√°s de 900 detenidos por el usurpador. ¬°Basta de indolencia!"",\n         "emisor_nombre": "Yandir Loggiodice",\n         "contexto": "Comunicado del secretario general nacional del Partido Centro Democr√°tico (PCD)",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}
2025-04-21 15:18:09,503 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_025] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:01<00:13,  1.69it/s][A2025-04-21 15:18:09,551 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:09,562 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:09,576 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_007] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:05,  3.89it/s][A[A[A2025-04-21 15:18:09,653 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_043] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:02<00:07,  2.44it/s][A[A[A[A[A2025-04-21 15:18:09,714 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_007] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:04,  4.44it/s][A[A[A2025-04-21 15:18:09,787 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:09,823 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_025] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:02<00:05,  3.70it/s][A2025-04-21 15:18:09,826 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_007] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  6.59it/s][A[A[A2025-04-21 15:18:09,829 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:09,865 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:09,952 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_043] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:02<00:06,  2.64it/s][A[A[A[A[A2025-04-21 15:18:09,960 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:10,066 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:10,069 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"



[test_007] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:02<00:02,  7.14it/s][A[A[A2025-04-21 15:18:10,070 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:10,071 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:10,088 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_043] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:02<00:05,  3.26it/s][A[A[A[A[A2025-04-21 15:18:10,167 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:10,167 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:10,194 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:10,195 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:10,196 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_007] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:01,  8.85it/s][A[A[A2025-04-21 15:18:10,205 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_061] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:03<00:01,  3.87it/s][A[A[A[A2025-04-21 15:18:10,225 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:10,265 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:10,265 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:10,284 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:10,285 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:10,329 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_043] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:02<00:04,  3.48it/s][A[A[A[A[A2025-04-21 15:18:10,415 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:18:10,416 - ERROR - [test_043][relevancia][llama3-70b-8192] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "puntuacion_relevancia": 7,\n   "justificacion_relevancia": "Captura de l√≠der criminal con v√≠nculos con cartel del Pac√≠fico",\n   "categorias_asignadas": ["Conflicto/Seguridad", "Justicia/Legal"],\n   "resumen_breve": "Autoridades detienen a "El Gangoso", l√≠der de c√©lula criminal del "C√°rtel del Pac√≠fico" en CDMX y Puebla."\n}'}}
2025-04-21 15:18:10,438 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:10,439 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:10,456 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:10,457 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:10,457 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:10,458 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:10,589 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_025] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:03<00:05,  3.19it/s][A2025-04-21 15:18:10,637 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_043] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:03<00:03,  4.42it/s][A[A[A[A[A2025-04-21 15:18:10,649 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:10,650 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:10,841 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_043] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:03<00:02,  4.53it/s][A[A[A[A[A2025-04-21 15:18:10,882 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_025] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:03<00:04,  3.23it/s][A2025-04-21 15:18:11,137 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:11,138 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:11,246 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:11,247 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:11,308 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_025] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:03<00:05,  2.97it/s][A2025-04-21 15:18:11,512 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:18:11,514 - ERROR - [test_025][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""No est√° cerrada"",\n         "emisor_nombre": "Mauricio Macri",\n         "contexto": "Sobre la alianza electoral con dirigentes del PRO en la provincia de Buenos Aires",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""Ha habido dos fotos y mucha conversaci√≥n en los diarios"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "Sobre el acuerdo electoral entre La Libertad Avanza y el PRO en la Provincia de Buenos Aires",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""Hasta ahora no he escuchado, y menos a la hermana y menos al tri√°ngulo de hierro o al que sea, decir \'Queremos un acuerdo con el PRO en la provincia\'"",\n         "emisor_nombre": "Mauricio Macri",\n         "contexto": "Sobre la falta de acuerdo con La Libertad Avanza",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""La vuelta del kirchnerismo no va a pasar"" en el distrito bonaerense,\n         "emisor_nombre": "Javier Milei",\n         "contexto": "En una entrevista a FM El Observador",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""En la provincia de Buenos Aires vamos juntos"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "Sobre la alianza con el PRO en la provincia de Buenos Aires",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""¬øUsted no vio la √∫ltima foto de mi hermana, Ritondo, Santilli, Lule (Menem), (Sebasti√°n) Pareja...? ¬øEso no muestra que tenemos una voluntad de ir a ganar la Provincia todos juntos? ¬øUsted cree que la gente se sienta en esa foto de manera inocua? Estamos para ir y ganarles a los kukas en la provincia de Buenos Aires. Nuestra intenci√≥n es ganarles y sacarles el basti√≥n kirchnerista por antonomasia"",\n         "emisor_nombre": "Javier Milei",\n         "contexto": "Sobre la alianza con el PRO en la provincia de Buenos Aires",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""√âl dijo hoy que culpa de que la Ciudad adelant√≥ la elecci√≥n no hubo un acuerdo en la Ciudad. La Ciudad adelant√≥ la elecci√≥n el 27 de diciembre del a√±o pasado; el 8 de enero el Presidente dijo p√∫blicamente \'quiero un acuerdo por el todo\' y el 9 de enero yo saqu√© un comunicado diciendo \'javier estamos listos\'",\\n         "emisor_nombre": "Mauricio Macri",\\n         "contexto": "Sobre las acusaciones de \'traici√≥n por la espalda\' y de \'cuidar los negocios\' de Javier Milei",\\n         "fecha_cita": null,\\n         "relevancia_cita": 4\\n      },\\n      {\\n         "cita": ""Silencio de radio. En off en la Rosada dec√≠an \'no tenemos apuro, no tenemos inter√©s\'",\n         "emisor_nombre": "Mauricio Macri",\n         "contexto": "Sobre la respuesta que recibi√≥ su propuesta de alianza con La Libertad Avanza",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""Todav√≠a ni siquiera han aceptado que esto es un acuerdo entre partidos y tiene que haber un frente"",\n         "emisor_nombre": "Mauricio Macri",\n         "contexto": "Sobre la falta de acuerdo con La Libertad Avanza",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Con la mesa ejecutiva del PRO delegamos en (Cristian) Ritondo, (Diego) Santilli que vayan a sentarse a conversar, para ver c√≥mo en cada distrito unimos fuerzas"",\n         "emisor_nombre": "Mauricio Macri",\n         "contexto": "Sobre la alianza con La Libertad Avanza",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""Cuidemos lo que hemos logrado porque administrar una ciudad como Buenos Aires es muy complejo y hay que tener equipo y el √∫nico que lo tiene (...) que tiene las herramientas para solucionar estos problemas es el PRO"",\n         "emisor_nombre": "Mauricio Macri",\n         "contexto": "Sobre la importancia de votar a los candidatos amarillos en la Ciudad de Buenos Aires",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""Un candidato no es la play station, videojuegos; hay que estudiar para ir a la Legislatura, hay que saber de la ciudad, hay que conocer"",\n         "emisor_nombre": "Mauricio Macri",\n         "contexto": "Sobre la supuesta escasa preparaci√≥n del funcionario de La Libertad Avanza, Manuel Adorni",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""No veo mucha televisi√≥n, pero las cosas que vi habla de temas nacionales, no habla de temas de la ciudad. Gobernar la ciudad. el ciudadano porte√±o es exigente, que demanda realmente respuestas y el PRO se las ha dado"",\n         "emisor_nombre": "Mauricio Macri",\n         "contexto": "Sobre la supuesta escasa preparaci√≥n del funcionario de La Libertad Avanza, Manuel Adorni",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No hay ninguno que est√© preparado, ni La Libertad Avanza, ni (Leandro) Santoro, ni La C√°mpora idolatrando a Alberto Fern√°ndez"",\n         "emisor_nombre": "Mauricio Macri",\n         "contexto": "Sobre la falta de preparaci√≥n de los candidatos de La Libertad Avanza y La C√°mpora",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}

[test_025] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:03<00:04,  3.29it/s][A2025-04-21 15:18:11,616 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_007] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:03<00:03,  3.19it/s][A[A[A2025-04-21 15:18:11,687 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_043] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:04<00:04,  2.61it/s][A[A[A[A[A2025-04-21 15:18:11,817 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_007] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:03<00:02,  3.43it/s][A[A[A2025-04-21 15:18:12,101 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:12,101 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:12,154 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_025] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:04<00:05,  2.54it/s][A2025-04-21 15:18:12,241 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:12,242 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:12,349 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_043] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:04<00:05,  2.18it/s][A[A[A[A[A2025-04-21 15:18:12,365 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:12,366 - ERROR - [test_043][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29807, Requested 1093. Please try again in 1.799s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:12,389 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:12,390 - ERROR - [test_043][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29793, Requested 1205. Please try again in 1.996s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:12,546 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:12,547 - ERROR - [test_007][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29715, Requested 1201. Please try again in 1.831s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_007] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:04<00:03,  2.59it/s][A[A[A2025-04-21 15:18:12,552 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:12,553 - ERROR - [test_007][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29713, Requested 1052. Please try again in 1.529s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:12,556 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:12,557 - ERROR - [test_007][relevancia][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29710, Requested 1016. Please try again in 1.452s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:12,591 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_061] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:05<00:02,  1.71it/s][A[A[A[A2025-04-21 15:18:12,595 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_024] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:19<00:00,  2.06s/it][A[A

                                                                         [A[A2025-04-21 15:18:12,606 - INFO - --- Art√≠culo test_024 completado ---
2025-04-21 15:18:12,606 - INFO - --- Procesando Art√≠culo: test_062 ---
2025-04-21 15:18:12,607 - INFO - [test_062] Lanzando 25 llamadas a Groq...


[test_062] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[AProgreso General Art√≠culos:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 53/72 [04:52<00:58,  3.08s/it]2025-04-21 15:18:12,741 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_025] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:05<00:05,  2.23it/s][A2025-04-21 15:18:12,765 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:12,766 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:12,813 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_061] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:06<00:01,  1.92it/s][A[A[A[A2025-04-21 15:18:12,834 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:12,835 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:12,837 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:12,838 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:12,854 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:12,855 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:12,856 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:12,856 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:12,858 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:12,859 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:12,879 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:12,880 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:12,951 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:12,952 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:12,958 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:12,959 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:18:12,979 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:12,980 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:13,093 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:13,093 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:13,098 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_007] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:05<00:01,  3.46it/s][A[A[A2025-04-21 15:18:13,121 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:13,121 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:13,133 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:13,134 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:13,172 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_025] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:05<00:04,  2.27it/s][A2025-04-21 15:18:13,340 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:13,341 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:13,363 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:13,364 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:13,373 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:13,374 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:13,375 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:13,375 - ERROR - [test_025][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29311, Requested 1809. Please try again in 2.239s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_025] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:05<00:03,  2.68it/s][A2025-04-21 15:18:13,445 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:13,445 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:13,472 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:13,473 - ERROR - [test_025][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30067, Requested 1548. Please try again in 3.231s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:13,500 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_062] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:21,  1.12it/s][A[A2025-04-21 15:18:13,504 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:13,505 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:13,604 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_062] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:09,  2.33it/s][A[A2025-04-21 15:18:13,659 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:13,793 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_062] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:04,  4.56it/s][A[A2025-04-21 15:18:13,906 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:13,907 - ERROR - [test_007][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29852, Requested 1425. Please try again in 2.553s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_007] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:05<00:01,  2.59it/s][A[A[A2025-04-21 15:18:13,915 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_062] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:03,  5.28it/s][A[A2025-04-21 15:18:13,945 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:13,946 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:13,964 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:13,965 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:13,966 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:18:13,967 - ERROR - [test_062][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Este ha sido un golpe muy duro para m√≠"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Sobre la tragedia en el Jet Set",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""siente el mismo dolor que siente cada uno de ustedes"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "En referencia a la poblaci√≥n dominicana",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un dolor muy fuerte"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Sobre la tragedia del Jet Set",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""A√∫n no haya conocido a muchos, como obviamente no haya conocido a muchos, pero personalmente y tambi√©n como presidente, ha sido un golpe muy duro, emocionalmente muy fuerte"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Respuesta a si hab√≠a sido tocado de manera personal por el hecho",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Yo tuve muchos amigos, yo fui el padrino de la boda de Eduardo Estrella y somos familias, familia lejana, tercer primo, somos familia. Ah√≠ hab√≠a siete u ocho personas conocidas, muy cercanas, amigos, que nos hab√≠amos reunidos dos o tres d√≠as antes, puedo mencionarte once o doce personas"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Sobre las v√≠ctimas que hab√≠a conocido",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""estos 231 dominicanos y dominicanas que han fallecidos"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Sobre las v√≠ctimas de la tragedia",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}
2025-04-21 15:18:14,078 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:14,079 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:18:14,146 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:14,147 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:14,192 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_062] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:02,  6.05it/s][A[A2025-04-21 15:18:14,228 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:14,229 - ERROR - [test_025][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 28874, Requested 1696. Please try again in 1.139s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_025] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:06<00:03,  2.52it/s][A2025-04-21 15:18:14,291 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:14,292 - ERROR - [test_025][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29659, Requested 1931. Please try again in 3.18s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:14,295 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_062] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  6.68it/s][A[A2025-04-21 15:18:14,299 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_061] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:07<00:01,  1.39it/s][A[A[A[A2025-04-21 15:18:14,380 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:14,382 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_025] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:06<00:01,  3.68it/s][A2025-04-21 15:18:14,424 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_062] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01,  8.76it/s][A[A2025-04-21 15:18:14,623 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_043] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:07<00:04,  1.61it/s][A[A[A[A[A2025-04-21 15:18:14,641 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:14,676 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:14,852 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:14,853 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:14,913 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_043] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:07<00:02,  2.18it/s][A[A[A[A[A2025-04-21 15:18:14,930 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:14,931 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:14,939 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:14,940 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:14,964 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:14,965 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:14,983 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:14,984 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:15,031 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:15,032 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:15,105 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_062] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:02,  5.03it/s][A[A2025-04-21 15:18:15,289 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_025] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:07<00:02,  2.43it/s][A2025-04-21 15:18:15,464 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:15,465 - ERROR - [test_007][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30128, Requested 1313. Please try again in 2.882s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_007] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:07<00:02,  1.58it/s][A[A[A2025-04-21 15:18:16,037 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:16,038 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:16,526 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_043] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:09<00:03,  1.46it/s][A[A[A[A[A2025-04-21 15:18:16,558 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:16,559 - ERROR - [test_007][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30100, Requested 1052. Please try again in 2.305s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_007] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:08<00:02,  1.35it/s][A[A[A2025-04-21 15:18:16,679 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_061] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:09<00:01,  1.09s/it][A[A[A[A2025-04-21 15:18:16,710 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_043] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:09<00:02,  1.74it/s][A[A[A[A[A2025-04-21 15:18:16,844 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_043] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:09<00:01,  2.13it/s][A[A[A[A[A2025-04-21 15:18:17,035 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:17,036 - ERROR - [test_043][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31542, Requested 1307. Please try again in 5.699s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_043] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:09<00:00,  2.50it/s][A[A[A[A[A2025-04-21 15:18:17,066 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:17,067 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:17,081 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:17,082 - ERROR - [test_062][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31521, Requested 1353. Please try again in 5.748s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_062] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:04<00:06,  1.74it/s][A[A2025-04-21 15:18:17,157 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:17,158 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:17,243 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:17,244 - ERROR - [test_025][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31438, Requested 1548. Please try again in 5.972s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_025] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:09<00:03,  1.29it/s][A2025-04-21 15:18:17,254 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:17,256 - ERROR - [test_062][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29750, Requested 1247. Please try again in 1.993s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_062] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:04<00:05,  2.08it/s][A[A2025-04-21 15:18:17,434 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:17,435 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:17,579 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_062] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:04<00:04,  2.26it/s][A[A2025-04-21 15:18:17,829 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_062] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:05<00:03,  2.55it/s][A[A2025-04-21 15:18:17,835 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_061] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:11<00:00,  1.11s/it][A[A[A[A



                                                                         [A[A[A[A2025-04-21 15:18:17,852 - INFO - --- Art√≠culo test_061 completado ---
2025-04-21 15:18:17,852 - INFO - --- Procesando Art√≠culo: test_044 ---
2025-04-21 15:18:17,853 - INFO - [test_044] Lanzando 25 llamadas a Groq...




[test_044] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[AProgreso General Art√≠culos:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 54/72 [04:58<01:05,  3.65s/it]2025-04-21 15:18:18,028 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:18,029 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:18:18,035 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:18,036 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:18:18,065 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:18,065 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:18,095 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:18,096 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:18:18,097 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:18,097 - ERROR - [test_025][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32755, Requested 1696. Please try again in 8.902s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_025] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:10<00:02,  1.25it/s][A2025-04-21 15:18:18,110 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:18,111 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:18,111 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:18,112 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:18,113 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:18:18,113 - ERROR - [test_025][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32748, Requested 1931. Please try again in 9.359s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:18,140 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:18,141 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:18,146 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:18,146 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:18,155 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:18,156 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:18,161 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:18,162 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:18:18,173 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:18,173 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:18:18,277 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:18,278 - ERROR - [test_062][relevancia][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30697, Requested 1005. Please try again in 3.405s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_062] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:05<00:03,  2.46it/s][A[A2025-04-21 15:18:18,306 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_044] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:10,  2.20it/s][A[A[A[A2025-04-21 15:18:18,506 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:18:18,508 - ERROR - [test_062][extraccion_hechos][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "contenido": "El presidente de la Rep√∫blica Dominicana, Luis Abinader, habl√≥ sobre la tragedia en el Jet Set, que caus√≥ 231 muertos.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-08T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 10,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "Jet Set", "tragedia"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader confes√≥ que perdi√≥ a 11 personas cercanas, algunas familias lejanas, en la tragedia.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-08T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "Jet Set", "tragedia"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader habl√≥ del tema durante LA Semanal con la Prensa.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-14T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "LA Semanal con la Prensa"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader visit√≥ la zona cero y expres√≥ su dolor y consternaci√≥n de manera p√∫blica.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-08T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "zona cero"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader expres√≥ que siente el mismo dolor que siente cada uno de los dominicanos.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-08T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "dolor"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader confes√≥ que la tragedia del Jet Set lo ha tocado y causado un dolor muy fuerte.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-08T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "dolor"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader habl√≥ del tema durante LA Semanal con la Prensa.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-14T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "LA Semanal con la Prensa"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader visit√≥ la zona cero y expres√≥ su dolor y consternaci√≥n de manera p√∫blica.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-08T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "zona cero"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader expres√≥ que siente el mismo dolor que siente cada uno de los dominicanos.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-08T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "dolor"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader confes√≥ que la tragedia del Jet Set lo ha tocado y causado un dolor muy fuerte.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-08T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "dolor"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader habl√≥ del tema durante LA Semanal con la Prensa.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-14T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "LA Semanal con la Prensa"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader visit√≥ la zona cero y expres√≥ su dolor y consternaci√≥n de manera p√∫blica.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-08T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "zona cero"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader expres√≥ que siente el mismo dolor que siente cada uno de los dominicanos.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-08T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "dolor"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader confes√≥ que la tragedia del Jet Set lo ha tocado y causado un dolor muy fuerte.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-08T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "dolor"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader habl√≥ del tema durante LA Semanal con la Prensa.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-14T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "LA Semanal con la Prensa"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader visit√≥ la zona cero y expres√≥ su dolor y consternaci√≥n de manera p√∫blica.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-08T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "zona cero"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader expres√≥ que siente el mismo dolor que siente cada uno de los dominicanos.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-08T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "dolor"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader confes√≥ que la tragedia del Jet Set lo ha tocado y causado un dolor muy fuerte.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-08T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "dolor"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader habl√≥ del tema durante LA Semanal con la Prensa.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-14T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "LA Semanal con la Prensa"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader visit√≥ la zona cero y expres√≥ su dolor y consternaci√≥n de manera p√∫blica.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-08T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "zona cero"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader expres√≥ que siente el mismo dolor que siente cada uno de los dominicanos.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-08T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "dolor"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader confes√≥ que la tragedia del Jet Set lo ha tocado y causado un dolor muy fuerte.",\n         "tipo_hecho": "DECLARACION",\n         "fecha_ocurrencia_inicio": "2025-04-08T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "dolor"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El presidente Abinader habl√≥ del tema durante LA Semanal con la Prensa.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-14T00:00:00+00:00",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "dia",\n         "paises": ["DO"],\n         "ubicaciones_especificas": ["Rep√∫blica Dominicana"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["Luis Abinader", "Rep√∫blica Dominicana", "LA Semanal con la Prensa"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      }}'}}


[test_062] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:05<00:02,  2.80it/s][A[A2025-04-21 15:18:18,552 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_044] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:07,  3.01it/s][A[A[A[A2025-04-21 15:18:18,592 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:18:18,593 - ERROR - [test_044][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""La semana pasada, de hecho, el propio presidente Gustavo Petro anunci√≥ y pidi√≥ que el siguiente Consejo de Ministros, es decir, el de este lunes, estuviera dedicado a la seguridad. Esto a ra√≠z de que los homicidios tuvieron un leve incremento en el primer trimestre de este a√±o y que en varias zonas del pa√≠s persiste la crisis de orden p√∫blico. Luego se plane√≥ que el tema ser√≠a transporte, pero no se concret√≥"",\n         "emisor_nombre": "El Colombiano",\n         "contexto": "El presidente Gustavo Petro anunci√≥ que el siguiente Consejo de Ministros se dedicar√≠a a la seguridad.",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""el derecho a la informaci√≥n es igualmente vulnerado, cuando la informaci√≥n difundida es √∫nica, sin la posibilidad de tener acceso, en paralelo y en las mismas condiciones, a otras fuentes de informaci√≥n, a otros enfoques o interpretaciones de la realidad y la √∫nica opci√≥n informativa es la informaci√≥n oficial del gobierno, difundida en todos los canales televisivos de acceso abierto"",\n         "emisor_nombre": "Consejo de Estado",\n         "contexto": "El Consejo de Estado explica por qu√© considera que la transmisi√≥n de los Consejos de Ministros en canales privados vulnera la pluralidad informativa.",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}
2025-04-21 15:18:18,681 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_044] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:00<00:03,  6.09it/s][A[A[A[A2025-04-21 15:18:18,831 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_044] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:00<00:03,  6.25it/s][A[A[A[A2025-04-21 15:18:18,853 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:18,950 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_044] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:02,  8.88it/s][A[A[A[A2025-04-21 15:18:18,967 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:18,968 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:18:19,172 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:19,187 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:19,188 - ERROR - [test_043][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32209, Requested 1093. Please try again in 6.604s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_043] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:11<00:00,  1.16it/s][A[A[A[A[A2025-04-21 15:18:19,191 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_044] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:01,  8.64it/s][A[A[A[A2025-04-21 15:18:19,203 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:19,204 - ERROR - [test_025][relevancia][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32199, Requested 1026. Please try again in 6.451s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_025] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:11<00:00,  1.44it/s][A2025-04-21 15:18:19,466 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:19,561 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:19,562 - ERROR - [test_007][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32028, Requested 1201. Please try again in 6.458s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_007] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:11<00:02,  1.30s/it][A[A[A2025-04-21 15:18:19,632 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:19,635 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_044] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:02,  6.47it/s][A[A[A[A2025-04-21 15:18:19,694 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:19,702 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:19,703 - ERROR - [test_007][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31950, Requested 1313. Please try again in 6.527s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_007] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:11<00:00,  1.00it/s][A[A[A2025-04-21 15:18:19,804 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_062] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:07<00:03,  1.60it/s][A[A2025-04-21 15:18:19,899 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_044] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:02<00:01,  7.97it/s][A[A[A[A2025-04-21 15:18:19,928 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_062] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:07<00:02,  2.08it/s][A[A2025-04-21 15:18:19,999 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_044] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:02<00:01,  8.26it/s][A[A[A[A2025-04-21 15:18:20,080 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:20,081 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:20,412 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_062] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:07<00:01,  2.08it/s][A[A2025-04-21 15:18:20,420 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_044] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:01,  5.54it/s][A[A[A[A2025-04-21 15:18:20,789 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_062] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:08<00:01,  2.22it/s][A[A2025-04-21 15:18:22,172 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_062] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:09<00:01,  1.38it/s][A[A2025-04-21 15:18:22,247 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:22,248 - INFO - Retrying request to /openai/v1/chat/completions in 18.000000 seconds
2025-04-21 15:18:22,249 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:22,250 - INFO - Retrying request to /openai/v1/chat/completions in 18.000000 seconds
2025-04-21 15:18:22,377 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_044] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:04<00:04,  1.75it/s][A[A[A[A2025-04-21 15:18:22,386 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:23,263 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:23,264 - ERROR - [test_043][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30174, Requested 1205. Please try again in 2.758s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_043] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:15<00:00,  1.75s/it][A[A[A[A[A




                                                                         [A[A[A[A[A2025-04-21 15:18:23,277 - INFO - --- Art√≠culo test_043 completado ---
2025-04-21 15:18:23,277 - INFO - --- Procesando Art√≠culo: test_026 ---
2025-04-21 15:18:23,278 - INFO - [test_026] Lanzando 25 llamadas a Groq...





[test_026] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[A[AProgreso General Art√≠culos:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 55/72 [05:03<01:10,  4.13s/it]2025-04-21 15:18:23,440 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:23,440 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:23,452 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:23,453 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:23,468 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:23,469 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:23,482 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:23,483 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:23,486 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:23,487 - INFO - Retrying request to /openai/v1/chat/completions in 22.000000 seconds
2025-04-21 15:18:23,541 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:23,541 - INFO - Retrying request to /openai/v1/chat/completions in 22.000000 seconds
2025-04-21 15:18:23,565 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:23,566 - ERROR - [test_007][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30022, Requested 1425. Please try again in 2.894s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_007] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:15<00:00,  1.78s/it][A[A[A


                                                                         [A[A[A2025-04-21 15:18:23,575 - INFO - --- Art√≠culo test_007 completado ---
2025-04-21 15:18:23,575 - INFO - --- Procesando Art√≠culo: test_008 ---
2025-04-21 15:18:23,576 - INFO - [test_008] Lanzando 25 llamadas a Groq...



[test_008] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[AProgreso General Art√≠culos:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 56/72 [05:03<00:48,  3.05s/it]2025-04-21 15:18:23,738 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:23,743 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:23,744 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_026] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:11,  2.14it/s][A[A[A[A[A2025-04-21 15:18:23,820 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:23,821 - INFO - Retrying request to /openai/v1/chat/completions in 22.000000 seconds
2025-04-21 15:18:23,824 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:23,824 - INFO - Retrying request to /openai/v1/chat/completions in 22.000000 seconds
2025-04-21 15:18:23,837 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:23,838 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:23,840 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:23,841 - INFO - Retrying request to /openai/v1/chat/completions in 22.000000 seconds
2025-04-21 15:18:23,842 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:23,843 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:23,844 - INFO - Retrying request to /openai/v1/chat/completions in 21.000000 seconds
2025-04-21 15:18:23,939 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:23,940 - INFO - Retrying request to /openai/v1/chat/completions in 21.000000 seconds
2025-04-21 15:18:23,991 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_026] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:04,  4.70it/s][A[A[A[A[A2025-04-21 15:18:24,251 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_008] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:16,  1.48it/s][A[A[A2025-04-21 15:18:24,316 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:24,324 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_026] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:05,  3.93it/s][A[A[A[A[A2025-04-21 15:18:24,386 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_008] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:04,  4.44it/s][A[A[A2025-04-21 15:18:24,392 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:24,546 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_026] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:03,  5.46it/s][A[A[A[A[A2025-04-21 15:18:24,571 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:24,622 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:24,624 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_008] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:04,  4.36it/s][A[A[A2025-04-21 15:18:24,717 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:24,747 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_026] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  6.72it/s][A[A[A[A[A2025-04-21 15:18:24,758 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:24,854 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_008] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:02,  7.23it/s][A[A[A2025-04-21 15:18:24,903 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_026] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01,  8.16it/s][A[A[A[A[A2025-04-21 15:18:25,086 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_026] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:01,  7.41it/s][A[A[A[A[A2025-04-21 15:18:25,215 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:25,217 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_008] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:03,  5.31it/s][A[A[A




[test_026] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:01<00:01,  7.44it/s][A[A[A[A[A2025-04-21 15:18:25,406 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_008] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:03,  5.31it/s][A[A[A2025-04-21 15:18:25,569 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_008] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:02,  5.50it/s][A[A[A2025-04-21 15:18:25,673 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_026] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:02<00:02,  4.67it/s][A[A[A[A[A2025-04-21 15:18:25,679 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_008] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:02<00:02,  6.15it/s][A[A[A2025-04-21 15:18:25,746 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:25,793 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_026] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:02<00:02,  5.28it/s][A[A[A[A[A2025-04-21 15:18:25,893 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_026] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:02<00:01,  6.06it/s][A[A[A[A[A2025-04-21 15:18:25,912 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_008] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:02<00:01,  7.01it/s][A[A[A2025-04-21 15:18:25,984 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:26,177 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:26,178 - ERROR - [test_062][relevancia][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32562, Requested 1005. Please try again in 7.135s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_062] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:13<00:01,  1.70s/it][A[A2025-04-21 15:18:26,298 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:26,299 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:18:26,315 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:26,316 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:18:26,404 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_008] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:02<00:01,  5.49it/s][A[A[A2025-04-21 15:18:26,411 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_026] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:03<00:02,  3.79it/s][A[A[A[A[A2025-04-21 15:18:26,541 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:26,542 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:26,663 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:26,664 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:18:26,674 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:26,675 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:18:26,771 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_008] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:03<00:01,  4.51it/s][A[A[A2025-04-21 15:18:26,825 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:26,826 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:27,118 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:27,119 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:27,165 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_026] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:03<00:03,  2.48it/s][A[A[A[A[A2025-04-21 15:18:27,250 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:27,251 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:18:27,427 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_044] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:09<00:07,  1.33s/it][A[A[A[A2025-04-21 15:18:27,521 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:27,522 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:18:27,546 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_062] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:14<00:00,  1.60s/it][A[A

                                                                         [A[A2025-04-21 15:18:27,561 - INFO - --- Art√≠culo test_062 completado ---
2025-04-21 15:18:27,561 - INFO - --- Procesando Art√≠culo: test_063 ---
2025-04-21 15:18:27,562 - INFO - [test_063] Lanzando 25 llamadas a Groq...


[test_063] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[AProgreso General Art√≠culos:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 57/72 [05:07<00:49,  3.32s/it]2025-04-21 15:18:27,716 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:27,717 - INFO - Retrying request to /openai/v1/chat/completions in 18.000000 seconds
2025-04-21 15:18:27,798 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:27,799 - INFO - Retrying request to /openai/v1/chat/completions in 17.000000 seconds
2025-04-21 15:18:27,826 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:27,827 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:27,848 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:27,849 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:27,850 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:27,850 - INFO - Retrying request to /openai/v1/chat/completions in 12.000000 seconds
2025-04-21 15:18:27,862 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:27,863 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:18:27,878 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:27,878 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:18:27,912 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:27,913 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:27,918 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:27,919 - INFO - Retrying request to /openai/v1/chat/completions in 12.000000 seconds
2025-04-21 15:18:27,944 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:27,945 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:18:27,964 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_063] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:09,  2.48it/s][A[A2025-04-21 15:18:28,110 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_063] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:05,  3.97it/s][A[A2025-04-21 15:18:28,165 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:18:28,166 - ERROR - [test_063][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""El 23 por ciento de las afiliaciones de mexicanos en el extranjero es por 12 meses. El 16 por ciento lo hace o decide pagar por 6 meses. En su mayor√≠a, que son 7 mil 361 personas, lo hacen de manera mensual, y esto tiene que ver por los ingresos de una persona trabajadora independiente, que son variables"",\n         "emisor_nombre": "dijo",\n         "contexto": "La funcionaria del Seguro Social expuso detalles sobre las afiliaciones de mexicanos en el extranjero",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}
2025-04-21 15:18:28,305 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:28,306 - ERROR - [test_025][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31967, Requested 1809. Please try again in 7.552s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_025] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:20<00:00,  2.64s/it][A
                                                                         [A2025-04-21 15:18:28,318 - INFO - --- Art√≠culo test_025 completado ---
2025-04-21 15:18:28,318 - INFO - --- Procesando Art√≠culo: test_045 ---
2025-04-21 15:18:28,318 - INFO - [test_045] Lanzando 25 llamadas a Groq...

[test_045] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][AProgreso General Art√≠culos:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 58/72 [05:08<00:36,  2.58s/it]2025-04-21 15:18:28,375 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_008] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:04<00:04,  1.83it/s][A[A[A2025-04-21 15:18:28,470 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:28,471 - INFO - Retrying request to /openai/v1/chat/completions in 16.000000 seconds
2025-04-21 15:18:28,518 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_063] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:00<00:04,  4.51it/s][A[A2025-04-21 15:18:28,538 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:28,561 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:28,562 - INFO - Retrying request to /openai/v1/chat/completions in 16.000000 seconds
2025-04-21 15:18:28,564 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:28,568 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:28,569 - INFO - Retrying request to /openai/v1/chat/completions in 16.000000 seconds
2025-04-21 15:18:28,583 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:28,584 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:28,584 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:28,585 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:28,603 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:28,604 - INFO - Retrying request to /openai/v1/chat/completions in 17.000000 seconds
2025-04-21 15:18:28,668 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:28,669 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:28,670 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:28,670 - INFO - Retrying request to /openai/v1/chat/completions in 17.000000 seconds
2025-04-21 15:18:28,675 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:28,675 - INFO - Retrying request to /openai/v1/chat/completions in 12.000000 seconds
2025-04-21 15:18:28,678 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:28,678 - INFO - Retrying request to /openai/v1/chat/completions in 11.000000 seconds
2025-04-21 15:18:28,775 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:28,776 - ERROR - [test_026][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 34330, Requested 1417. Please try again in 11.494s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_026] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:05<00:05,  1.33it/s][A[A[A[A[A2025-04-21 15:18:28,900 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_063] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:03,  5.96it/s][A[A2025-04-21 15:18:28,903 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_045] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:14,  1.71it/s][A2025-04-21 15:18:28,945 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:28,946 - INFO - Retrying request to /openai/v1/chat/completions in 16.000000 seconds
2025-04-21 15:18:28,997 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:29,221 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:29,222 - ERROR - [test_044][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31508, Requested 1391. Please try again in 5.799s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_044] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:11<00:07,  1.43s/it][A[A[A[A2025-04-21 15:18:29,332 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_045] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:01<00:06,  3.22it/s][A2025-04-21 15:18:29,395 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_063] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:04,  4.20it/s][A[A2025-04-21 15:18:29,540 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:29,541 - ERROR - [test_008][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 33944, Requested 1374. Please try again in 10.637s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_008] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:05<00:04,  1.43it/s][A[A[A2025-04-21 15:18:29,558 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_026] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:06<00:04,  1.31it/s][A[A[A[A[A2025-04-21 15:18:29,633 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_063] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:02<00:03,  4.20it/s][A[A2025-04-21 15:18:29,950 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_045] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:08,  2.40it/s][A2025-04-21 15:18:29,988 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:29,988 - INFO - Retrying request to /openai/v1/chat/completions in 15.000000 seconds
2025-04-21 15:18:30,023 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:30,024 - INFO - Retrying request to /openai/v1/chat/completions in 15.000000 seconds
2025-04-21 15:18:30,030 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_063] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:02<00:04,  3.60it/s][A[A2025-04-21 15:18:30,100 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:18:30,102 - ERROR - [test_008][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Lament√≥ profundamente el fallecimiento de un peruano universal. Mario Vargas Llosa se eterniza a trav√©s de su legado literario. Tuve la suerte de haber coincidido con √©l en algunas oportunidades"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""un peruano universal"",\n         "emisor_nombre": "Alfredo Ferrero",\n         "contexto": "En un mensaje de condolencias a la familia de Vargas Llosa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }}'}}



[test_008] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:06<00:03,  1.51it/s][A[A[A2025-04-21 15:18:30,108 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_045] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:06,  3.02it/s][A2025-04-21 15:18:30,263 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_045] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:05,  3.64it/s][A2025-04-21 15:18:30,284 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:18:30,285 - ERROR - [test_045][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Nos dijo p√∫blicamente que, en 15 d√≠as, con la sentencia de la justicia, se realizar√≠a el pago, e incluso se comprometi√≥ a colaborar para agilizar el juicio. Sin embargo, todas las instancias han fallado a nuestro favor y ellos siguen apelando"",\n         "emisor_nombre": "uno de los afectados",\n         "contexto": "Protesta de extrabajadores de Sabsa frente al Ministerio de Obras P√∫blicas",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}
2025-04-21 15:18:30,300 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_008] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:06<00:02,  1.86it/s][A[A[A2025-04-21 15:18:30,308 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_063] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:02<00:03,  3.60it/s][A[A2025-04-21 15:18:30,689 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_045] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:02<00:04,  4.08it/s][A2025-04-21 15:18:30,697 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:30,902 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_045] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:02<00:02,  5.30it/s][A2025-04-21 15:18:31,253 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_045] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:02<00:03,  4.44it/s][A2025-04-21 15:18:31,510 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_063] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:03<00:06,  1.88it/s][A[A2025-04-21 15:18:31,617 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_045] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:03<00:03,  3.86it/s][A2025-04-21 15:18:31,709 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:31,926 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_026] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:08<00:06,  1.24s/it][A[A[A[A[A2025-04-21 15:18:32,336 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_063] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:04<00:07,  1.63it/s][A[A2025-04-21 15:18:32,606 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:32,607 - ERROR - [test_026][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29815, Requested 1522. Please try again in 2.674s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_026] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:09<00:04,  1.07s/it][A[A[A[A[A2025-04-21 15:18:33,080 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_045] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:04<00:04,  2.21it/s][A2025-04-21 15:18:33,779 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:33,780 - ERROR - [test_026][relevancia][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29231, Requested 1002. Please try again in 466ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:33,781 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:33,782 - ERROR - [test_026][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29236, Requested 1156. Please try again in 784ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_026] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:10<00:03,  1.10s/it][A[A[A[A[A2025-04-21 15:18:34,783 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:34,784 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:18:34,844 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_044] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:16<00:09,  2.42s/it][A[A[A[A2025-04-21 15:18:34,885 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:34,886 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:18:34,917 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_045] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:06<00:07,  1.31it/s][A2025-04-21 15:18:34,927 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:34,928 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:18:34,985 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:34,986 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:35,352 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_063] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:07<00:14,  1.30s/it][A[A2025-04-21 15:18:35,383 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_044] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:17<00:05,  1.94s/it][A[A[A[A2025-04-21 15:18:36,029 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_063] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:08<00:11,  1.12s/it][A[A2025-04-21 15:18:37,068 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:37,069 - ERROR - [test_063][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29850, Requested 963. Please try again in 1.625s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_063] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:09<00:09,  1.10s/it][A[A2025-04-21 15:18:40,357 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_045] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:12<00:17,  1.91s/it][A2025-04-21 15:18:40,380 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:40,381 - ERROR - [test_044][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31032, Requested 1026. Please try again in 4.115999999s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_044] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:22<00:05,  2.75s/it][A[A[A[A2025-04-21 15:18:40,392 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:40,393 - ERROR - [test_044][relevancia][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31028, Requested 1005. Please try again in 4.066s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:40,451 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:40,529 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:40,530 - ERROR - [test_044][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29476, Requested 1287. Please try again in 1.525s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_044] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:22<00:00,  1.60s/it][A[A[A[A



                                                                         [A[A[A[A2025-04-21 15:18:40,542 - INFO - --- Art√≠culo test_044 completado ---
2025-04-21 15:18:40,542 - INFO - --- Procesando Art√≠culo: test_027 ---
2025-04-21 15:18:40,543 - INFO - [test_027] Lanzando 25 llamadas a Groq...




[test_027] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[AProgreso General Art√≠culos:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 59/72 [05:20<01:10,  5.40s/it]2025-04-21 15:18:40,754 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:40,755 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:18:40,773 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:40,773 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:40,778 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:40,779 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:40,780 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:40,780 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:18:40,802 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:40,803 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:40,813 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:40,814 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:40,818 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:40,818 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:40,829 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:40,830 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:40,873 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:40,873 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:40,901 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:40,902 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:41,058 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:41,059 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:41,104 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:41,104 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:41,152 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_027] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:14,  1.64it/s][A[A[A[A2025-04-21 15:18:41,203 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_063] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:13<00:15,  1.99s/it][A[A2025-04-21 15:18:41,327 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_027] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:08,  2.82it/s][A[A[A[A2025-04-21 15:18:41,549 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_027] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:01<00:06,  3.41it/s][A[A[A[A2025-04-21 15:18:41,589 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_045] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:13<00:09,  1.38s/it][A2025-04-21 15:18:41,665 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_063] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:14<00:10,  1.54s/it][A[A2025-04-21 15:18:41,703 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_027] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:05,  4.19it/s][A[A[A[A2025-04-21 15:18:41,763 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:41,777 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_045] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:13<00:06,  1.11s/it][A2025-04-21 15:18:41,796 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:18:41,797 - ERROR - [test_027][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""son nuestra √∫nica posibilidad de lograr un cambio real"",\n         "emisor_nombre": "Yaneth del Rosario Cruz G√≥mez",\n         "contexto": "Coment√≥ a La Jornada sobre la importancia de las campa√±as de los candidatos del Consejo Nacional de Pueblos Ind√≠genas",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""a m√°s de 200 a√±os de vida independiente, seguimos excluidos del sistema de justicia de nuestro pa√≠s, caracterizado por ser formalista, elitista, clasista y racista"",\n         "emisor_nombre": "Consejo Nacional de Pueblos Ind√≠genas",\n         "contexto": "En un posicionamiento de seis puntos, le√≠do por Cruz en conferencia de prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""por lo que ahora, la participaci√≥n de nuestros hermanos y hermanas alienta nuestra esperanza de contar con una justicia con pertinencia cultural"",\n         "emisor_nombre": "Consejo Nacional de Pueblos Ind√≠genas",\n         "contexto": "En un posicionamiento de seis puntos, le√≠do por Cruz en conferencia de prensa",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""condena a ser ciudadanos pasivos que no podemos expresar y hacer sentir nuestra solidaridad con los hermanos y hermanas que participan en la contienda"",\n         "emisor_nombre": "Consejo Nacional de Pueblos Ind√≠genas",\n         "contexto": "Acus√≥ al Instituto Nacional Electoral",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""es un momento hist√≥rico para impulsar una justicia que tome en cuenta los diversos contextos sociales y culturales de M√©xico, aspecto que s√≥lo se puede lograr con instituciones que incorporen juzgadores competentes"",\n         "emisor_nombre": "Consejo Nacional de Pueblos Ind√≠genas",\n         "contexto": "Resalt√≥ la importancia de impulsar una justicia que tome en cuenta los diversos contextos sociales y culturales de M√©xico",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}
2025-04-21 15:18:41,892 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:41,893 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:41,944 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:41,945 - ERROR - [test_045][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30162, Requested 1237. Please try again in 2.799s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_045] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:13<00:04,  1.14it/s][A2025-04-21 15:18:41,957 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_027] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:02,  7.05it/s][A[A[A[A2025-04-21 15:18:41,967 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:41,987 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:41,988 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:42,025 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:42,026 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:18:42,087 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:42,088 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:18:42,163 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:42,164 - ERROR - [test_063][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30051, Requested 1328. Please try again in 2.759s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_063] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:14<00:07,  1.23s/it][A[A2025-04-21 15:18:42,295 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_027] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:02,  6.57it/s][A[A[A[A2025-04-21 15:18:42,310 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:42,311 - ERROR - [test_063][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 33159, Requested 1224. Please try again in 8.767s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_063] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:14<00:04,  1.10it/s][A[A2025-04-21 15:18:42,334 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:42,363 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:42,812 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_027] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:02,  6.21it/s][A[A[A[A2025-04-21 15:18:42,898 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:42,899 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:43,245 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_027] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:02<00:02,  4.79it/s][A[A[A[A2025-04-21 15:18:43,348 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_027] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:02<00:02,  5.33it/s][A[A[A[A2025-04-21 15:18:44,394 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_027] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:03<00:03,  2.64it/s][A[A[A[A2025-04-21 15:18:44,901 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_045] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:16<00:05,  1.42s/it][A2025-04-21 15:18:44,931 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:44,932 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:45,031 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:45,032 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:45,116 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:45,117 - ERROR - [test_063][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29791, Requested 1224. Please try again in 2.029s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_063] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:17<00:05,  1.47s/it][A[A2025-04-21 15:18:45,128 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:45,129 - ERROR - [test_063][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29783, Requested 963. Please try again in 1.491s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:45,353 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_045] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:17<00:03,  1.16s/it][A2025-04-21 15:18:45,389 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_027] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:04<00:04,  1.90it/s][A[A[A[A2025-04-21 15:18:45,504 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_063] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:17<00:01,  1.13it/s][A[A2025-04-21 15:18:45,678 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:45,679 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:45,765 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:45,766 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:45,815 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:45,816 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:45,839 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:45,840 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:45,845 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:45,846 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:45,887 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:45,888 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:45,907 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:45,908 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:45,910 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:45,911 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:45,996 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:45,997 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:46,026 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_027] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:05<00:04,  1.80it/s][A[A[A[A2025-04-21 15:18:46,050 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:46,051 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:46,090 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:46,092 - ERROR - [test_027][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31266, Requested 1474. Please try again in 5.48s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:46,093 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:46,621 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_027] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:06<00:01,  2.71it/s][A[A[A[A2025-04-21 15:18:46,732 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_045] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:18<00:02,  1.22s/it][A2025-04-21 15:18:47,040 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:47,041 - ERROR - [test_008][relevancia][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30357, Requested 1012. Please try again in 2.738s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_008] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:23<00:20,  5.09s/it][A[A[A2025-04-21 15:18:47,444 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_027] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:06<00:01,  2.18it/s][A[A[A[A2025-04-21 15:18:47,622 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_063] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:20<00:01,  1.19s/it][A[A2025-04-21 15:18:47,763 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:47,764 - ERROR - [test_026][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29985, Requested 1417. Please try again in 2.804s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_026] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:24<00:03,  3.81s/it][A[A[A[A[A2025-04-21 15:18:47,852 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:47,853 - ERROR - [test_026][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29941, Requested 1156. Please try again in 2.193s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





                                                                         [A[A[A[A[A2025-04-21 15:18:47,864 - INFO - --- Art√≠culo test_026 completado ---
2025-04-21 15:18:47,864 - INFO - --- Procesando Art√≠culo: test_009 ---
2025-04-21 15:18:47,865 - INFO - [test_009] Lanzando 25 llamadas a Groq...





[test_009] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[A[AProgreso General Art√≠culos:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 60/72 [05:28<01:11,  5.97s/it]2025-04-21 15:18:47,944 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:47,946 - ERROR - [test_027][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29896, Requested 1474. Please try again in 2.739s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_027] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:07<00:01,  2.14it/s][A[A[A[A2025-04-21 15:18:48,019 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,022 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,023 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:48,024 - ERROR - [test_063][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32193, Requested 1328. Please try again in 7.043s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_063] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:20<00:00,  1.02it/s][A[A

                                                                         [A[A2025-04-21 15:18:48,036 - INFO - --- Art√≠culo test_063 completado ---
2025-04-21 15:18:48,036 - INFO - --- Procesando Art√≠culo: test_064 ---
2025-04-21 15:18:48,037 - INFO - [test_064] Lanzando 25 llamadas a Groq...


[test_064] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[AProgreso General Art√≠culos:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 61/72 [05:28<00:46,  4.25s/it]2025-04-21 15:18:48,094 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,155 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:48,156 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,158 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,159 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,165 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,166 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,167 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,168 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,169 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,170 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,170 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,171 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,172 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:48,172 - ERROR - [test_045][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32171, Requested 1237. Please try again in 6.816s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:48,173 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:48,177 - ERROR - [test_008][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29814, Requested 1486. Please try again in 2.6s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:48,177 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:48,178 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:48,178 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:48,178 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:48,178 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:48,178 - ERROR - [test_045][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32132, Requested 1130. Please try again in 6.525s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:48,179 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:48,180 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[test_045] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:19<00:01,  1.28s/it][A


[test_008] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:24<00:11,  3.96s/it][A[A[A
                                                                         [A2025-04-21 15:18:48,191 - INFO - --- Art√≠culo test_045 completado ---
2025-04-21 15:18:48,192 - ERROR - [test_008][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32114, Requested 1598. Please try again in 7.424s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:48,196 - INFO - --- Procesando Art√≠culo: test_046 ---
2025-04-21 15:18:48,196 - INFO - [test_046] Lanzando 25 llamadas a Groq...

[test_046] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][AProgreso General Art√≠culos:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 62/72 [05:28<00:30,  3.03s/it]2025-04-21 15:18:48,377 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,390 - ERROR - [test_027][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29692, Requested 1372. Please try again in 2.126999999s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_027] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:07<00:00,  2.16it/s][A[A[A[A2025-04-21 15:18:48,462 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:48,465 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,469 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds





[test_009] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:14,  1.66it/s][A[A[A[A[A2025-04-21 15:18:48,470 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,471 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:48,477 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,478 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:48,486 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,487 - ERROR - [test_008][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29625, Requested 1374. Please try again in 1.997s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_008] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:24<00:02,  2.25s/it][A[A[A2025-04-21 15:18:48,547 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,548 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:48,549 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,550 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:48,551 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,552 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:48,553 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,553 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:48,554 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,554 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:48,562 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,563 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:48,567 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,568 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:48,569 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,570 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:48,575 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,575 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:48,578 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,578 - ERROR - [test_008][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31910, Requested 1225. Please try again in 6.27s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:48,579 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,580 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



                                                                         [A[A[A2025-04-21 15:18:48,591 - INFO - --- Art√≠culo test_008 completado ---
2025-04-21 15:18:48,592 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:48,593 - INFO - --- Procesando Art√≠culo: test_028 ---
2025-04-21 15:18:48,594 - INFO - [test_028] Lanzando 25 llamadas a Groq...



[test_028] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[AProgreso General Art√≠culos:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 63/72 [05:28<00:20,  2.25s/it]




[test_009] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:08,  2.82it/s][A[A[A[A[A2025-04-21 15:18:48,650 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,653 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:48,655 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:48,657 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,661 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:48,667 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,668 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,670 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:48,670 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:48,671 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,676 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:48,842 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,843 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:48,859 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,860 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:48,861 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,861 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:48,870 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,871 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:48,885 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,885 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:48,897 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,898 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:48,927 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_064] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:21,  1.12it/s][A[A2025-04-21 15:18:48,956 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,957 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:48,979 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:48,979 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:48,980 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:48,981 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:18:48,983 - ERROR - [test_009][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""en el coraz√≥n del pueblo dominicano ser√° un duelo eterno"",\n         "emisor_nombre": "Leonel Fern√°ndez",\n         "contexto": "Durante una misa en memoria de las v√≠ctimas del Jet Set",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""El dolor del pueblo dominicano ha sido enorme. El Gobierno decret√≥ tres d√≠as de duelo y tuvo que extenderlo, pero deber√° extenderlo m√°s"",\n         "emisor_nombre": "Leonel Fern√°ndez",\n         "contexto": "Durante una misa en memoria de las v√≠ctimas del Jet Set",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Estaba la representaci√≥n de la sociedad dominicana a todos los niveles"",\n         "emisor_nombre": "Leonel Fern√°ndez",\n         "contexto": "Durante una misa en memoria de las v√≠ctimas del Jet Set",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""en medio del dolor, esta es una herida que tomar√° tiempo para cicatrizar, si es que llega a cicatrizar"",\n         "emisor_nombre": "Leonel Fern√°ndez",\n         "contexto": "Durante una misa en memoria de las v√≠ctimas del Jet Set",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Desde Fuerza del Pueblo entend√≠amos que era necesario reunirnos en la casa de Dios, del Todopoderoso, para pedirle por las almas"",\n         "emisor_nombre": "Leonel Fern√°ndez",\n         "contexto": "Durante una misa en memoria de las v√≠ctimas del Jet Set",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Estamos seguros de que Dios los acoger√° en su santo cielo. Que en paz descansen"",\n         "emisor_nombre": "Leonel Fern√°ndez",\n         "contexto": "Durante una misa en memoria de las v√≠ctimas del Jet Set",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}

[test_046] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:18,  1.27it/s][A




[test_009] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:04,  4.22it/s][A[A[A[A[A2025-04-21 15:18:49,002 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:49,003 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:18:49,027 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:49,028 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:49,096 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_009] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:03,  5.02it/s][A[A[A[A[A2025-04-21 15:18:49,110 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:49,153 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:49,154 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:49,260 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_028] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:16,  1.50it/s][A[A[A2025-04-21 15:18:49,276 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:49,278 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_009] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:02,  6.75it/s][A[A[A[A[A

[test_064] Llamadas Groq:   8%|‚ñä         | 2/25 [00:01<00:13,  1.74it/s][A[A2025-04-21 15:18:49,296 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_046] Llamadas Groq:   8%|‚ñä         | 2/25 [00:01<00:11,  1.96it/s][A2025-04-21 15:18:49,342 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:49,364 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:49,427 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:49,428 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:18:49,433 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:49,436 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_009] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:01,  8.31it/s][A[A[A[A[A2025-04-21 15:18:49,438 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_064] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:05,  3.79it/s][A[A2025-04-21 15:18:49,492 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:49,511 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:49,585 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_046] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:01<00:08,  2.45it/s][A2025-04-21 15:18:49,687 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_009] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:01<00:01,  9.65it/s][A[A[A[A[A2025-04-21 15:18:49,831 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_046] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:07,  2.90it/s][A2025-04-21 15:18:49,834 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:49,864 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_064] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:04,  4.16it/s][A[A2025-04-21 15:18:49,892 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:49,978 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_064] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  6.02it/s][A[A2025-04-21 15:18:49,995 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:49,999 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_046] Llamadas Groq:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:03,  4.85it/s][A2025-04-21 15:18:50,003 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_028] Llamadas Groq:   8%|‚ñä         | 2/25 [00:01<00:16,  1.40it/s][A[A[A2025-04-21 15:18:50,068 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:50,164 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_046] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:03,  5.13it/s][A2025-04-21 15:18:50,273 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_046] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:02<00:02,  5.86it/s][A2025-04-21 15:18:50,290 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:18:50,291 - ERROR - [test_046][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Pareciera que hay 2 versiones: una cuando habla en Panam√° y otra cuando habla en Estados Unidos"",\n         "emisor_nombre": "Jos√© Ra√∫l Mulino",\n         "contexto": "En una entrevista concedida a TVN",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""La reuni√≥n con √©l fue a puerta cerrada, buena, de mucho entendimiento. Me dijo algo muy claro: \'Yo no vine aqu√≠ a enredar tu pol√≠tica\'. Y yo le respond√≠: \'Bueno, hace rato que ya la enredaste\'"",\n         "emisor_nombre": "Jos√© Ra√∫l Mulino",\n         "contexto": "En una entrevista concedida a TVN",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Soy amigo de Estados Unidos, no tengo complejos con el pa√≠s. Me encanta ir a EEUU‚Ä¶ es el Tratado de Neutralidad, en la condici√≥n N¬∞5, que plantea la posibilidad de‚Ä¶"",\n         "emisor_nombre": "Jos√© Ra√∫l Mulino",\n         "contexto": "En una entrevista concedida a TVN",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""¬øQu√© es lo que ustedes saben que no nos dicen sobre China? Porque no se puede simplemente hablar por hablar. Si hay indicios graves o pruebas de injerencia china, yo agradecer√≠a que me lo digan. Pero nunca me dicen nada concreto"",\n         "emisor_nombre": "Jos√© Ra√∫l Mulino",\n         "contexto": "En una entrevista concedida a TVN",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Eso no me lo dijo a m√≠. Hablamos de la presencia china, que data de m√°s de un siglo. Colaboraron en la construcci√≥n del Canal, forman una comunidad significativa. No tenemos problemas con los chinos, ni ellos con nosotros"",\n         "emisor_nombre": "Jos√© Ra√∫l Mulino",\n         "contexto": "En una entrevista concedida a TVN",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""No es que ustedes van a ver aviones‚Ä¶"",\n         "emisor_nombre": "Jos√© Ra√∫l Mulino",\n         "contexto": "En una entrevista concedida a TVN",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      }\n   ]\n}'}}
2025-04-21 15:18:50,394 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_028] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:01<00:12,  1.77it/s][A[A[A2025-04-21 15:18:50,457 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_009] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:02<00:02,  5.28it/s][A[A[A[A[A2025-04-21 15:18:50,480 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:50,520 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_064] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:02<00:03,  4.89it/s][A[A2025-04-21 15:18:50,569 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_009] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:02<00:01,  5.66it/s][A[A[A[A[A2025-04-21 15:18:50,592 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:50,593 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:50,685 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:50,686 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:50,691 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:50,692 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:18:50,708 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:50,709 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:50,756 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:50,757 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:50,797 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:50,798 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:50,857 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_046] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:02<00:03,  4.45it/s][A2025-04-21 15:18:50,872 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:50,878 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_028] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:02<00:07,  2.62it/s][A[A[A2025-04-21 15:18:50,880 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:50,881 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:50,924 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_064] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:02<00:03,  4.07it/s][A[A2025-04-21 15:18:50,956 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:51,005 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_046] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:02,  6.02it/s][A2025-04-21 15:18:51,080 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_028] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:02<00:04,  3.90it/s][A[A[A2025-04-21 15:18:51,145 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:51,145 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:51,205 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:18:51,206 - ERROR - [test_064][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""No ha sido neutralizado. No tenemos la informaci√≥n de que haya sido neutralizado"",\n         "emisor_nombre": "Pedro S√°nchez",\n         "contexto": "Confirmaci√≥n de que N√©stor Gregorio Vera Fern√°ndez, alias \'Iv√°n Mordisco\', no fue abatido en operaciones militares",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Todo fue objeto de an√°lisis en el marco del desarrollo de la actividad judicial. Elementos personales utilizados por estas personas"",\n         "emisor_nombre": "Carlos Triana",\n         "contexto": "Descripci√≥n de los elementos hallados en el campamento de las disidencias",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""Es una zona compleja. Afortunadamente, nuestras Fuerzas Militares en el desarrollo de toda esa operaci√≥n, logran llegar al territorio"",\n         "emisor_nombre": "Carlos Triana",\n         "contexto": "Descripci√≥n de las dificultades de acceso en la regi√≥n",\n         "fecha_cita": null,\n         "relevancia_cita": 2\n      },\n      {\n         "cita": ""La opci√≥n m√°s f√°cil es la que tienen absolutamente todos los miembros de los grupos armados organizados y que no necesitan un proceso de paz. Que es el grupo de atenci√≥n humanitaria al desmovilizado"",\n         "emisor_nombre": "Pedro S√°nchez",\n         "contexto": "Invitaci√≥n a los jefes e integrantes de las disidencias de las Farc para que se entreguen",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}


[test_064] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:03<00:03,  3.94it/s][A[A2025-04-21 15:18:51,219 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_046] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:03<00:02,  5.66it/s][A2025-04-21 15:18:51,233 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:51,234 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:51,273 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:51,274 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:51,372 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_028] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:02<00:04,  3.77it/s][A[A[A2025-04-21 15:18:51,379 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_046] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:03<00:01,  5.80it/s][A2025-04-21 15:18:51,424 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:51,425 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:51,520 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_027] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:10<00:01,  1.14s/it][A[A[A[A2025-04-21 15:18:51,555 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_028] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:02<00:03,  4.09it/s][A[A[A2025-04-21 15:18:51,590 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:51,591 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_009] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:03<00:03,  2.87it/s][A[A[A[A[A2025-04-21 15:18:51,641 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:51,642 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:51,643 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:51,644 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:51,700 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_028] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:03<00:02,  5.83it/s][A[A[A2025-04-21 15:18:51,729 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_009] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:03<00:02,  3.33it/s][A[A[A[A[A2025-04-21 15:18:51,735 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:51,760 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:51,761 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:51,768 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:51,769 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:51,773 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:51,792 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_064] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:03<00:04,  2.98it/s][A[A2025-04-21 15:18:51,803 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:51,804 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:51,820 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:51,820 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:51,930 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:51,930 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:51,985 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:51,986 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:52,043 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,043 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:52,063 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,064 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:18:52,070 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_028] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:03<00:02,  5.66it/s][A[A[A2025-04-21 15:18:52,117 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:52,119 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,120 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:52,174 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_064] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:04<00:03,  2.87it/s][A[A2025-04-21 15:18:52,254 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,255 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:52,268 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,269 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:52,287 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,288 - ERROR - [test_027][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29327, Requested 1372. Please try again in 1.397s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_027] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:11<00:00,  1.04s/it][A[A[A[A



                                                                         [A[A[A[A2025-04-21 15:18:52,302 - INFO - --- Art√≠culo test_027 completado ---
2025-04-21 15:18:52,302 - INFO - --- Procesando Art√≠culo: test_010 ---
2025-04-21 15:18:52,303 - INFO - [test_010] Lanzando 25 llamadas a Groq...




[test_010] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[AProgreso General Art√≠culos:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 64/72 [05:32<00:21,  2.68s/it]2025-04-21 15:18:52,399 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,402 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:52,450 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,452 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:52,468 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:52,474 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[test_046] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:04<00:04,  2.47it/s][A2025-04-21 15:18:52,475 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:18:52,487 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,488 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:52,538 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,538 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:52,562 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_009] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:04<00:02,  2.89it/s][A[A[A[A[A2025-04-21 15:18:52,583 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,584 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:52,591 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,592 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:52,648 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,649 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:52,653 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,654 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:52,668 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,669 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:52,670 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,671 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:52,712 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_009] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:04<00:01,  3.30it/s][A[A[A[A[A2025-04-21 15:18:52,778 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,779 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:18:52,879 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,880 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:52,895 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,896 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:18:52,920 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,921 - ERROR - [test_064][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29741, Requested 1039. Please try again in 1.559s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_064] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:04<00:04,  2.20it/s][A[A2025-04-21 15:18:52,953 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_028] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:04<00:02,  3.72it/s][A[A[A2025-04-21 15:18:52,969 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:52,969 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:18:53,046 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_010] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:17,  1.34it/s][A[A[A[A2025-04-21 15:18:53,075 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:53,076 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:18:53,170 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_064] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:05<00:03,  2.51it/s][A[A2025-04-21 15:18:53,317 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_010] Llamadas Groq:   8%|‚ñä         | 2/25 [00:01<00:10,  2.15it/s][A[A[A[A2025-04-21 15:18:53,360 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:53,361 - ERROR - [test_028][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29522, Requested 1459. Please try again in 1.961s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_028] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:04<00:02,  3.37it/s][A[A[A2025-04-21 15:18:53,376 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:53,377 - ERROR - [test_009][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30103, Requested 1322. Please try again in 2.85s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_009] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:05<00:01,  2.57it/s][A[A[A[A[A2025-04-21 15:18:53,514 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_064] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:05<00:03,  2.61it/s][A[A2025-04-21 15:18:53,560 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_010] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:01<00:08,  2.75it/s][A[A[A[A2025-04-21 15:18:53,641 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:53,739 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:53,740 - ERROR - [test_046][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29919, Requested 1545. Please try again in 2.927s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_046] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:05<00:05,  1.58it/s][A2025-04-21 15:18:53,802 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:53,803 - ERROR - [test_064][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29297, Requested 1300. Please try again in 1.194s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_064] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:05<00:02,  2.81it/s][A[A2025-04-21 15:18:53,817 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_010] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:04,  4.33it/s][A[A[A[A2025-04-21 15:18:53,832 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:53,856 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:53,864 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:53,865 - ERROR - [test_046][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29267, Requested 1432. Please try again in 1.398s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_046] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:05<00:03,  2.02it/s][A2025-04-21 15:18:53,892 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:53,893 - ERROR - [test_064][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29843, Requested 1410. Please try again in 2.505s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:53,942 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:18:53,943 - ERROR - [test_010][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Nosotros vamos a respetar que se haga justicia"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Durante LA Semanal con la Prensa en el Palacio Nacional",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Si hay un gobierno que ha respetado todos los procesos legales es este Gobierno"",\n         "emisor_nombre": "Luis Abinader",\n         "contexto": "Durante LA Semanal con la Prensa en el Palacio Nacional",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""El equipo que fue desde aqu√≠ no sab√≠a andar en la capital ni sab√≠a d√≥nde hab√≠a un vertedero para botar eso, y nosotros le autorizamos que lo trajera para ac√°, para Santiago, porque aqu√≠ es que botamos los desperdicios del monorriel"",\n         "emisor_nombre": "Ram√≥n Rodr√≠guez",\n         "contexto": "Sobre el traslado de escombros de la discoteca Jet Set",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      }\n   ]\n}'}}




[test_010] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  7.87it/s][A[A[A[A2025-04-21 15:18:54,052 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_046] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:05<00:02,  2.45it/s][A2025-04-21 15:18:54,232 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:54,233 - ERROR - [test_028][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29228, Requested 1459. Please try again in 1.374s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_028] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:05<00:03,  2.36it/s][A[A[A2025-04-21 15:18:54,252 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:54,315 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:54,316 - ERROR - [test_064][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 34281, Requested 1300. Please try again in 11.163s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_064] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:06<00:01,  3.22it/s][A[A2025-04-21 15:18:54,468 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:54,469 - ERROR - [test_009][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 34202, Requested 1218. Please try again in 10.84s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_009] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:06<00:01,  1.76it/s][A[A[A[A[A2025-04-21 15:18:54,477 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:54,478 - ERROR - [test_046][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29088, Requested 1432. Please try again in 1.038999999s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_046] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:06<00:02,  2.42it/s][A2025-04-21 15:18:54,491 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:54,492 - ERROR - [test_009][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 34192, Requested 1322. Please try again in 11.028s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:54,524 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:54,525 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:54,662 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_010] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:02<00:03,  4.83it/s][A[A[A[A2025-04-21 15:18:54,673 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:54,674 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:54,779 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:54,780 - ERROR - [test_064][relevancia][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29400, Requested 1016. Please try again in 832ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_064] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:06<00:01,  2.87it/s][A[A2025-04-21 15:18:54,819 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_010] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:02<00:02,  5.07it/s][A[A[A[A2025-04-21 15:18:54,845 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:54,846 - ERROR - [test_046][relevancia][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29365, Requested 1017. Please try again in 764ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_046] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:06<00:01,  2.50it/s][A2025-04-21 15:18:54,869 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:54,870 - ERROR - [test_064][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 34001, Requested 1039. Please try again in 10.08s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:54,925 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:54,926 - ERROR - [test_064][relevancia][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 33979, Requested 1016. Please try again in 9.99s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_064] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:06<00:00,  4.26it/s][A[A2025-04-21 15:18:54,985 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:54,986 - ERROR - [test_009][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29298, Requested 957. Please try again in 510ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_009] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:07<00:00,  2.29it/s][A[A[A[A[A2025-04-21 15:18:55,146 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:55,148 - ERROR - [test_028][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 33863, Requested 1608. Please try again in 10.943s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_028] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:06<00:03,  1.84it/s][A[A[A2025-04-21 15:18:55,158 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_010] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:02,  4.38it/s][A[A[A[A2025-04-21 15:18:55,222 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:55,458 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:55,459 - ERROR - [test_046][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29643, Requested 1284. Please try again in 1.854s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_046] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:07<00:01,  2.16it/s][A2025-04-21 15:18:55,522 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:55,523 - ERROR - [test_009][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29031, Requested 1218. Please try again in 497ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_009] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:07<00:00,  2.17it/s][A[A[A[A[A




                                                                         [A[A[A[A[A2025-04-21 15:18:55,539 - INFO - --- Art√≠culo test_009 completado ---
2025-04-21 15:18:55,539 - INFO - --- Procesando Art√≠culo: test_065 ---
2025-04-21 15:18:55,543 - INFO - [test_065] Lanzando 25 llamadas a Groq...





[test_065] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[A[A[A[AProgreso General Art√≠culos:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 65/72 [05:35<00:19,  2.85s/it]2025-04-21 15:18:55,699 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:55,700 - INFO - Retrying request to /openai/v1/chat/completions in 11.000000 seconds
2025-04-21 15:18:55,716 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:55,716 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:55,741 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:55,742 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:18:55,762 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:55,763 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:55,777 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:55,778 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:18:55,782 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:55,783 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:55,791 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:55,792 - ERROR - [test_064][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 28892, Requested 1188. Please try again in 160ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_064] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:07<00:00,  2.64it/s][A[A2025-04-21 15:18:55,793 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:55,794 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:18:55,809 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:55,810 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:55,817 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:55,818 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:55,895 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:55,896 - ERROR - [test_046][extraccion_citas][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 33490, Requested 1284. Please try again in 9.549s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_046] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:07<00:01,  2.20it/s][A2025-04-21 15:18:55,920 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:55,921 - INFO - Retrying request to /openai/v1/chat/completions in 11.000000 seconds
2025-04-21 15:18:55,927 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:55,928 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:55,993 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:55,994 - ERROR - [test_046][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 33439, Requested 1545. Please try again in 9.968s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:56,109 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_065] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:13,  1.76it/s][A[A[A[A[A2025-04-21 15:18:56,122 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:56,123 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:56,388 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_065] Llamadas Groq:   8%|‚ñä         | 2/25 [00:00<00:09,  2.51it/s][A[A[A[A[A2025-04-21 15:18:56,479 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:56,589 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_065] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:04,  4.73it/s][A[A[A[A[A2025-04-21 15:18:56,615 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_010] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:04<00:04,  2.38it/s][A[A[A[A2025-04-21 15:18:56,689 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:56,689 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:56,691 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds





[test_065] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:03,  5.65it/s][A[A[A[A[A2025-04-21 15:18:56,699 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:56,713 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:56,772 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:56,805 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:56,806 - ERROR - [test_010][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 33033, Requested 1547. Please try again in 9.161s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_010] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:04<00:03,  2.70it/s][A[A[A[A2025-04-21 15:18:56,893 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_065] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:01, 10.37it/s][A[A[A[A[A2025-04-21 15:18:56,980 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:56,981 - ERROR - [test_046][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 32945, Requested 1652. Please try again in 9.194s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_046] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:08<00:00,  2.02it/s][A2025-04-21 15:18:57,014 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:57,015 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:18:57,024 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_028] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:08<00:05,  1.13it/s][A[A[A2025-04-21 15:18:57,166 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:57,167 - ERROR - [test_028][extraccion_datos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29349, Requested 1720. Please try again in 2.138s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_028] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:08<00:03,  1.46it/s][A[A[A2025-04-21 15:18:57,195 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_010] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:04<00:03,  2.66it/s][A[A[A[A2025-04-21 15:18:57,351 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:57,352 - ERROR - [test_028][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 28693, Requested 1608. Please try again in 601ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_028] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:08<00:02,  1.83it/s][A[A[A2025-04-21 15:18:57,379 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:57,603 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"



[test_028] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:09<00:01,  2.16it/s][A[A[A2025-04-21 15:18:57,676 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:57,677 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:18:57,766 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_010] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:05<00:03,  2.35it/s][A[A[A[A2025-04-21 15:18:57,785 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_065] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:02<00:02,  4.85it/s][A[A[A[A[A2025-04-21 15:18:57,874 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_010] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:05<00:02,  2.93it/s][A[A[A[A2025-04-21 15:18:57,918 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:57,919 - ERROR - [test_010][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29605, Requested 1329. Please try again in 1.868s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:18:58,149 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:58,150 - ERROR - [test_028][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29489, Requested 1812. Please try again in 2.601s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_028] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:09<00:00,  2.05it/s][A[A[A2025-04-21 15:18:58,218 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:58,219 - ERROR - [test_065][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 33988, Requested 1432. Please try again in 10.841s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_065] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:02<00:03,  4.04it/s][A[A[A[A[A2025-04-21 15:18:58,459 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:58,460 - ERROR - [test_046][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29334, Requested 1652. Please try again in 1.972s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_046] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:10<00:00,  1.36it/s][A
                                                                         [A2025-04-21 15:18:58,473 - INFO - --- Art√≠culo test_046 completado ---
2025-04-21 15:18:58,473 - INFO - --- Procesando Art√≠culo: test_047 ---
2025-04-21 15:18:58,473 - INFO - [test_047] Lanzando 25 llamadas a Groq...

[test_047] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][AProgreso General Art√≠culos:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 66/72 [05:38<00:17,  2.87s/it]2025-04-21 15:18:58,632 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_065] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:03<00:03,  3.55it/s][A[A[A[A[A2025-04-21 15:18:58,636 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:58,636 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:18:58,643 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:58,644 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:18:58,694 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:58,695 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:58,697 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:58,697 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:58,698 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:58,699 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:58,700 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:58,700 - INFO - Retrying request to /openai/v1/chat/completions in 10.000000 seconds
2025-04-21 15:18:58,708 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:58,709 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:18:58,712 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:58,712 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:58,713 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:58,718 - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-04-21 15:18:58,761 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_065] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:03<00:02,  4.05it/s][A[A[A[A[A2025-04-21 15:18:58,806 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_010] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:06<00:01,  2.53it/s][A[A[A[A2025-04-21 15:18:58,867 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:58,868 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:18:58,925 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_047] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:10,  2.21it/s][A2025-04-21 15:18:58,998 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:59,029 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_047] Llamadas Groq:  12%|‚ñà‚ñè        | 3/25 [00:00<00:03,  6.41it/s][A2025-04-21 15:18:59,094 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_065] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:03<00:02,  3.73it/s][A[A[A[A[A2025-04-21 15:18:59,181 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:18:59,182 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:18:59,252 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_065] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:03<00:02,  4.18it/s][A[A[A[A[A2025-04-21 15:18:59,315 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:59,322 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_047] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:00<00:03,  6.62it/s][A2025-04-21 15:18:59,408 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:18:59,554 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_047] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:02,  7.34it/s][A2025-04-21 15:18:59,695 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_047] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  7.28it/s][A2025-04-21 15:18:59,709 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_065] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:04<00:02,  3.35it/s][A[A[A[A[A2025-04-21 15:19:00,066 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:19:00,067 - ERROR - [test_065][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""Hablamos de un punto medio, se requerir√≠a de cinco n√∫meros gruesos, de Q463 millones adicionales. Estamos partiendo de eso, la b√∫squeda de ese monto, que est√° m√°s o menos por ese rango de Q1 mil 800 de bono. Hay que hacer avisos, por ah√≠ los tenemos detectados, lo tenemos que soportar"",\n         "emisor_nombre": "Walter Figueroa, viceministro de Finanzas",\n         "contexto": "Durante una citaci√≥n este 14 de abril del diputado Jos√© Chic",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""Se contin√∫a el an√°lisis t√©cnico de la propuesta de los distintos sindicatos del sector de salud, como parte de este proceso. Se trabajar√° en la construcci√≥n de una propuesta que sea viable y sostenible, con el objetivo de no afectar la prestaci√≥n de los servicios de salud a la poblaci√≥n"",\n         "emisor_nombre": "Ministerio de Salud",\n         "contexto": "Respondi√≥ el Ministerio",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""Se basa en un punto medio, pero no es definitiva, ya que puede variar por los an√°lisis de la informaci√≥n de los dos ministerios"",\n         "emisor_nombre": "Juan Carlos Oxom, viceministro Financiero de Salud",\n         "contexto": "Respondi√≥ que la propuesta",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""El bono mensual se prev√© que sea para personal de los renglones 011, 021, 022 y 031, mientras que para trabajadores del rengl√≥n 0029 y subgrupo 018 se contempla un bono √∫nico de Q2 mil"",\n         "emisor_nombre": "Ministerio de Salud",\n         "contexto": "Se prev√© que sea",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      },\n      {\n         "cita": ""Chic abog√≥ porque se cuenten con los recursos para el personal de salud, pero sin desatender la red hospitalaria"",\n         "emisor_nombre": "Jos√© Chic, diputado",\n         "contexto": "Abog√≥",\n         "fecha_cita": null,\n         "relevancia_cita": 3\n      }\n   ]\n}'}}





[test_065] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:04<00:02,  3.18it/s][A[A[A[A[A2025-04-21 15:19:00,352 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_047] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:04,  3.75it/s][A2025-04-21 15:19:00,360 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:19:00,404 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_010] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:08<00:02,  1.48it/s][A[A[A[A2025-04-21 15:19:00,653 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_065] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:05<00:02,  2.55it/s][A[A[A[A[A2025-04-21 15:19:00,781 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:00,782 - ERROR - [test_010][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 35399, Requested 1547. Please try again in 13.893s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_010] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:08<00:01,  1.66it/s][A[A[A[A2025-04-21 15:19:00,840 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_065] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:05<00:01,  3.00it/s][A[A[A[A[A2025-04-21 15:19:00,873 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:19:01,296 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:01,297 - ERROR - [test_065][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 35142, Requested 1657. Please try again in 13.599s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_065] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:05<00:00,  3.50it/s][A[A[A[A[A2025-04-21 15:19:01,298 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_047] Llamadas Groq:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:02<00:04,  2.84it/s][A2025-04-21 15:19:02,726 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:19:02,727 - ERROR - [test_047][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""est√°n m√°s armados que nunca"",\n         "emisor_nombre": "Nicol√°s Maduro",\n         "contexto": "Durante un encuentro con la milicia al servicio del chavismo",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""aqu√≠ estamos hoy m√°s dispuestos que nunca, m√°s conscientes que nunca, m√°s armados que nunca para defender el sagrado suelo de nuestra Venezuela heroica"",\n         "emisor_nombre": "Nicol√°s Maduro",\n         "contexto": "Durante un encuentro con la milicia al servicio del chavismo",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""criminal"",\n         "emisor_nombre": "Nicol√°s Maduro",\n         "contexto": "Al referirse a Mar√≠a Corina Machado",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""No volver√°n. Mar√≠a Corina Machado y la oposici√≥n extremista son unos criminales que se dedican a lamerle el trasero a Estados Unidos, un imperialismo que los desprecia y los utiliza"",\n         "emisor_nombre": "Nicol√°s Maduro",\n         "contexto": "Al referirse a Mar√≠a Corina Machado y la oposici√≥n venezolana",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      }\n   ]\n}'}}

[test_047] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:04<00:07,  1.67it/s][A2025-04-21 15:19:02,883 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:02,884 - ERROR - [test_064][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29995, Requested 1410. Please try again in 2.809s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_064] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:14<00:00,  2.02s/it][A[A

                                                                         [A[A2025-04-21 15:19:02,896 - INFO - --- Art√≠culo test_064 completado ---
2025-04-21 15:19:02,896 - INFO - --- Procesando Art√≠culo: test_029 ---
2025-04-21 15:19:02,897 - INFO - [test_029] Lanzando 25 llamadas a Groq...


[test_029] Llamadas Groq:   0%|          | 0/25 [00:00<?, ?it/s][A[AProgreso General Art√≠culos:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 67/72 [05:43<00:16,  3.34s/it]2025-04-21 15:19:03,054 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:03,055 - INFO - Retrying request to /openai/v1/chat/completions in 11.000000 seconds
2025-04-21 15:19:03,060 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:03,061 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:19:03,133 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:03,134 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:19:03,150 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:03,151 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-04-21 15:19:03,196 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:03,197 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-04-21 15:19:03,202 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:03,203 - ERROR - [test_028][extraccion_datos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29838, Requested 1720. Please try again in 3.115s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



[test_028] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:14<00:01,  1.82s/it][A[A[A2025-04-21 15:19:03,225 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:03,226 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:03,226 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:19:03,227 - ERROR - [test_028][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29190, Requested 1812. Please try again in 2.004s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}



                                                                         [A[A[A2025-04-21 15:19:03,237 - INFO - --- Art√≠culo test_028 completado ---
Progreso General Art√≠culos:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 68/72 [05:43<00:09,  2.42s/it]2025-04-21 15:19:03,258 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:03,259 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:19:03,275 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:03,276 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:19:03,279 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:03,280 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:19:03,537 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_029] Llamadas Groq:   4%|‚ñç         | 1/25 [00:00<00:15,  1.56it/s][A[A2025-04-21 15:19:03,622 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:19:03,627 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:19:03,748 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:03,748 - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-04-21 15:19:03,773 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_047] Llamadas Groq:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:05<00:08,  1.41it/s][A2025-04-21 15:19:04,286 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_047] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:05<00:07,  1.52it/s][A2025-04-21 15:19:04,370 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:04,371 - INFO - Retrying request to /openai/v1/chat/completions in 11.000000 seconds
2025-04-21 15:19:04,571 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_047] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:06<00:05,  1.80it/s][A2025-04-21 15:19:04,601 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_029] Llamadas Groq:  16%|‚ñà‚ñå        | 4/25 [00:01<00:08,  2.44it/s][A[A2025-04-21 15:19:04,760 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_047] Llamadas Groq:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:06<00:04,  2.20it/s][A2025-04-21 15:19:04,796 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_029] Llamadas Groq:  20%|‚ñà‚ñà        | 5/25 [00:01<00:06,  2.86it/s][A[A2025-04-21 15:19:04,822 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:19:04,909 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_029] Llamadas Groq:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:02<00:03,  4.56it/s][A[A2025-04-21 15:19:05,132 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_047] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:06<00:03,  2.32it/s][A2025-04-21 15:19:05,522 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_047] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:07<00:02,  2.39it/s][A2025-04-21 15:19:05,765 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_047] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:07<00:02,  2.72it/s][A2025-04-21 15:19:05,776 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_029] Llamadas Groq:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:02<00:06,  2.67it/s][A[A2025-04-21 15:19:05,900 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:05,901 - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-04-21 15:19:05,907 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_029] Llamadas Groq:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:03<00:05,  3.20it/s][A[A2025-04-21 15:19:05,948 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:05,948 - INFO - Retrying request to /openai/v1/chat/completions in 3.000000 seconds
2025-04-21 15:19:05,979 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:05,980 - ERROR - [test_010][relevancia][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30525, Requested 1005. Please try again in 3.06s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}




[test_010] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:13<00:03,  1.82s/it][A[A[A[A2025-04-21 15:19:06,018 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:06,019 - ERROR - [test_010][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29624, Requested 1329. Please try again in 1.905s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-04-21 15:19:06,110 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_047] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:07<00:01,  2.77it/s][A2025-04-21 15:19:06,282 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"




[test_010] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:13<00:00,  1.10s/it][A[A[A[A



                                                                         [A[A[A[A2025-04-21 15:19:06,295 - INFO - --- Art√≠culo test_010 completado ---
Progreso General Art√≠culos:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 69/72 [05:46<00:07,  2.61s/it]2025-04-21 15:19:06,320 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:06,321 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:19:06,346 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:06,347 - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds
2025-04-21 15:19:06,490 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_029] Llamadas Groq:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:03<00:05,  2.60it/s][A[A2025-04-21 15:19:06,506 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:06,507 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:19:06,526 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:19:06,792 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:06,793 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:19:07,028 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:07,029 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:19:07,245 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:07,246 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:19:07,475 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:19:07,476 - ERROR - [test_029][extraccion_citas][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "cita": ""big data\\" y la Inteligencia Artificial un aliado para conocer de manera pormenorizada el detalle sobre los problemas de la sociedad y c√≥mo darles una respuesta eficaz.",\n         "emisor_nombre": "El autor del art√≠culo",\n         "contexto": "Estrategia electoral del PP",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""calle a calle\\"",\n         "emisor_nombre": "El√≠as Bendodo",\n         "contexto": "Monitorizando las preocupaciones y demandas de los ciudadanos",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""big data\\" pueden recopilar informaci√≥n a gran escala sobre el comportamiento de los votantes y as√≠ optimizar el discurso pol√≠tico",\n         "emisor_nombre": "El autor del art√≠culo",\n         "contexto": "Estrategia electoral del PP",\n         "fecha_cita": null,\n         "relevancia_cita": 5\n      },\n      {\n         "cita": ""fake news\\"",\n         "emisor_nombre": "El autor del art√≠culo",\n         "contexto": "Evitar las \\"fake news\\"",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      },\n      {\n         "cita": ""microtargeting\\"",\n         "emisor_nombre": "El autor del art√≠culo",\n         "contexto": "T√©cnica del gabinete",\n         "fecha_cita": null,\n         "relevancia_cita": 4\n      }\n   ]\n}'}}


[test_029] Llamadas Groq:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:04<00:05,  2.32it/s][A[A2025-04-21 15:19:07,526 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:19:07,727 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_029] Llamadas Groq:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:04<00:03,  3.18it/s][A[A2025-04-21 15:19:07,735 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:07,736 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:19:07,808 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:07,809 - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds
2025-04-21 15:19:08,745 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:08,746 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:19:08,789 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:08,790 - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-04-21 15:19:09,044 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:09,046 - ERROR - [test_065][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30384, Requested 1432. Please try again in 3.633s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}





[test_065] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:13<00:04,  2.11s/it][A[A[A[A[A2025-04-21 15:19:09,161 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_029] Llamadas Groq:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:06<00:05,  1.80it/s][A[A2025-04-21 15:19:09,184 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:19:10,007 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:10,008 - ERROR - [test_047][extraccion_hechos][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29904, Requested 1018. Please try again in 1.843s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}

[test_047] Llamadas Groq:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:11<00:05,  1.41s/it][A2025-04-21 15:19:12,084 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-04-21 15:19:12,087 - ERROR - [test_029][extraccion_hechos][llama-3.1-8b-instant] Error final tras reintentos: BadRequestError: Error code: 400 - {'error': {'message': "Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\n   "resultados": [\n      {\n         "contenido": "El PP crea la Unidad de An√°lisis de Datos y Prospectiva para estudiar tendencias electorales y evoluci√≥n del voto.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "Unidad de An√°lisis de Datos y Prospectiva", "tendencias electorales"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP utiliza la Inteligencia Artificial y el \'big data\' para conocer de manera pormenorizada los problemas de la sociedad y dar respuestas eficaces.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "Inteligencia Artificial", "big data"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP crea el Gabinete de Inteligencia y Datos Electorales Avanzados (G-IDEA) para monitorizar las preocupaciones y demandas de los ciudadanos.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "Gabinete de Inteligencia y Datos Electorales Avanzados", "monitorizaci√≥n de preocupaciones ciudadanas"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP utiliza el \'microtargeting\' para dirigir sus mensajes a un electorado concreto.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "microtargeting", "mensajes dirigidos"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP utiliza el \'big data\' para recopilar informaci√≥n a gran escala sobre el comportamiento de los votantes y optimizar el discurso pol√≠tico.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 9,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "big data", "discurso pol√≠tico"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP utiliza el an√°lisis de redes sociales para detectar tendencias y evaluar el impacto de sus mensajes.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "an√°lisis de redes sociales", "tendencias y impacto de mensajes"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP busca evitar las \'fake news\' y detectar las narrativas de desinformaci√≥n para proteger su imagen pol√≠tica.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "fake news", "narrativas de desinformaci√≥n"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP busca llegar al sector del campo y arrebatarle a Vox la voz cantante en este entorno.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "sector del campo", "Vox"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP busca llegar a los j√≥venes y arrebatarle a Vox la voz cantante en este entorno.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "j√≥venes", "Vox"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP busca llegar a los sectores m√°s j√≥venes y arrebatarle a Vox la voz cantante en este entorno.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "sectores m√°s j√≥venes", "Vox"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP busca llegar a los sectores m√°s j√≥venes y arrebatarle a Vox la voz cantante en este entorno.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "sectores m√°s j√≥venes", "Vox"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP busca llegar a los sectores m√°s j√≥venes y arrebatarle a Vox la voz cantante en este entorno.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "sectores m√°s j√≥venes", "Vox"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP busca llegar a los sectores m√°s j√≥venes y arrebatarle a Vox la voz cantante en este entorno.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "sectores m√°s j√≥venes", "Vox"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP busca llegar a los sectores m√°s j√≥venes y arrebatarle a Vox la voz cantante en este entorno.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "sectores m√°s j√≥venes", "Vox"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP busca llegar a los sectores m√°s j√≥venes y arrebatarle a Vox la voz cantante en este entorno.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "sectores m√°s j√≥venes", "Vox"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP busca llegar a los sectores m√°s j√≥venes y arrebatarle a Vox la voz cantante en este entorno.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "sectores m√°s j√≥venes", "Vox"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP busca llegar a los sectores m√°s j√≥venes y arrebatarle a Vox la voz cantante en este entorno.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "sectores m√°s j√≥venes", "Vox"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP busca llegar a los sectores m√°s j√≥venes y arrebatarle a Vox la voz cantante en este entorno.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "sectores m√°s j√≥venes", "Vox"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP busca llegar a los sectores m√°s j√≥venes y arrebatarle a Vox la voz cantante en este entorno.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "sectores m√°s j√≥venes", "Vox"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP busca llegar a los sectores m√°s j√≥venes y arrebatarle a Vox la voz cantante en este entorno.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "sectores m√°s j√≥venes", "Vox"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP busca llegar a los sectores m√°s j√≥venes y arrebatarle a Vox la voz cantante en este entorno.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "sectores m√°s j√≥venes", "Vox"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP busca llegar a los sectores m√°s j√≥venes y arrebatarle a Vox la voz cantante en este entorno.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "sectores m√°s j√≥venes", "Vox"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP busca llegar a los sectores m√°s j√≥venes y arrebatarle a Vox la voz cantante en este entorno.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "sectores m√°s j√≥venes", "Vox"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP busca llegar a los sectores m√°s j√≥venes y arrebatarle a Vox la voz cantante en este entorno.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "sectores m√°s j√≥venes", "Vox"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      },\n      {\n         "contenido": "El PP busca llegar a los sectores m√°s j√≥venes y arrebatarle a Vox la voz cantante en este entorno.",\n         "tipo_hecho": "SUCESO",\n         "fecha_ocurrencia_inicio": "2025-04-01",\n         "fecha_ocurrencia_fin": null,\n         "precision_temporal": "mes",\n         "paises": ["ES"],\n         "ubicaciones_especificas": ["Espa√±a"],\n         "importancia": 8,\n         "confiabilidad": 5,\n         "etiquetas": ["PP", "sectores m√°s j√≥venes", "Vox"],\n         "es_evento_futuro": false,\n         "estado_programacion": null\n      }}'}}


[test_029] Llamadas Groq:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:09<00:07,  1.11it/s][A[A2025-04-21 15:19:12,603 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:12,604 - ERROR - [test_029][extraccion_entidades][gemma2-9b-it] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 28605, Requested 1929. Please try again in 1.068s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_029] Llamadas Groq:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:09<00:05,  1.22it/s][A[A2025-04-21 15:19:14,411 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_047] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:15<00:06,  2.30s/it][A2025-04-21 15:19:14,498 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_029] Llamadas Groq:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:11<00:06,  1.07s/it][A[A2025-04-21 15:19:14,574 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_065] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:19<00:02,  2.99s/it][A[A[A[A[A2025-04-21 15:19:14,645 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_047] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:16<00:03,  1.68s/it][A2025-04-21 15:19:14,753 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_047] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:16<00:01,  1.21s/it][A2025-04-21 15:19:15,288 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_029] Llamadas Groq:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:12<00:04,  1.00it/s][A[A2025-04-21 15:19:15,378 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-21 15:19:15,464 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:15,465 - ERROR - [test_029][extraccion_citas][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 31477, Requested 1780. Please try again in 6.515s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_029] Llamadas Groq:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:12<00:01,  1.61it/s][A[A2025-04-21 15:19:16,227 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"





[test_065] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:20<00:00,  2.63s/it][A[A[A[A[A




                                                                         [A[A[A[A[A2025-04-21 15:19:16,240 - INFO - --- Art√≠culo test_065 completado ---
Progreso General Art√≠culos:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 70/72 [05:56<00:09,  4.81s/it]2025-04-21 15:19:16,241 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:16,241 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:19:16,257 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:16,258 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-04-21 15:19:16,415 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"

[test_047] Llamadas Groq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:17<00:00,  1.35s/it][A
                                                                         [A2025-04-21 15:19:16,429 - INFO - --- Art√≠culo test_047 completado ---
Progreso General Art√≠culos:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 71/72 [05:56<00:03,  3.42s/it]2025-04-21 15:19:17,760 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"


[test_029] Llamadas Groq:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:14<00:02,  1.00s/it][A[A2025-04-21 15:19:23,378 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:23,378 - ERROR - [test_029][extraccion_hechos][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29569, Requested 2145. Please try again in 3.428s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


[test_029] Llamadas Groq:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:20<00:02,  2.14s/it][A[A2025-04-21 15:19:23,388 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-21 15:19:23,389 - ERROR - [test_029][extraccion_entidades][llama3-70b-8192] Error final tras reintentos: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jsay2bafeeht06zsq8qv9mct` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29563, Requested 1929. Please try again in 2.983s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}


                                                                         [A[A2025-04-21 15:19:23,401 - INFO - --- Art√≠culo test_029 completado ---
Progreso General Art√≠culos: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 72/72 [06:03<00:00,  4.49s/it]Progreso General Art√≠culos: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 72/72 [06:03<00:00,  5.05s/it]
2025-04-21 15:19:23,402 - INFO - --- Benchmarking Completado ---
2025-04-21 15:19:23,407 - INFO - Resultados LLM guardados en subdirectorios dentro de: /home/ubuntu/benchmark_utils/benchmark_results
2025-04-21 15:19:23,407 - INFO - M√©tricas agregadas guardadas en: /home/ubuntu/benchmark_utils/benchmark_results/benchmark_metrics.csv
2025-04-21 15:19:23,407 - INFO - Tiempo total de ejecuci√≥n del script: 363.67 segundos
